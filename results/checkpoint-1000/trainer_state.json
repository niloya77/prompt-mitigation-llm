{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.819672131147541,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0,
      "loss_control": 0.6064453125,
      "loss_data": 0.429443359375,
      "loss_total": 0.692333996295929,
      "step": 0
    },
    {
      "epoch": 0.000819672131147541,
      "loss_control": 1.1162109375,
      "loss_data": 0.0,
      "loss_total": 1.1162109375,
      "step": 1
    },
    {
      "epoch": 0.001639344262295082,
      "loss_control": 0.9541015625,
      "loss_data": 0.0,
      "loss_total": 0.9541015625,
      "step": 2
    },
    {
      "epoch": 0.002459016393442623,
      "loss_control": 0.9111328125,
      "loss_data": 0.0,
      "loss_total": 0.9111328125,
      "step": 3
    },
    {
      "epoch": 0.003278688524590164,
      "loss_control": 0.744140625,
      "loss_data": 0.398193359375,
      "loss_total": 0.823779284954071,
      "step": 4
    },
    {
      "epoch": 0.004098360655737705,
      "grad_norm": 0.747503399848938,
      "learning_rate": 4.994535519125683e-05,
      "loss": 0.8995,
      "step": 5
    },
    {
      "epoch": 0.004098360655737705,
      "loss_control": 0.923828125,
      "loss_data": 0.41943359375,
      "loss_total": 1.007714867591858,
      "step": 5
    },
    {
      "epoch": 0.004918032786885246,
      "loss_control": 0.7373046875,
      "loss_data": 0.409912109375,
      "loss_total": 0.819287121295929,
      "step": 6
    },
    {
      "epoch": 0.005737704918032787,
      "loss_control": 0.77490234375,
      "loss_data": 0.345458984375,
      "loss_total": 0.843994140625,
      "step": 7
    },
    {
      "epoch": 0.006557377049180328,
      "loss_control": 0.79833984375,
      "loss_data": 0.854736328125,
      "loss_total": 0.969287097454071,
      "step": 8
    },
    {
      "epoch": 0.007377049180327869,
      "loss_control": 0.755859375,
      "loss_data": 0.4111328125,
      "loss_total": 0.838085949420929,
      "step": 9
    },
    {
      "epoch": 0.00819672131147541,
      "grad_norm": 0.7800788879394531,
      "learning_rate": 4.987704918032787e-05,
      "loss": 0.8957,
      "step": 10
    },
    {
      "epoch": 0.00819672131147541,
      "loss_control": 0.64453125,
      "loss_data": 0.87060546875,
      "loss_total": 0.818652331829071,
      "step": 10
    },
    {
      "epoch": 0.009016393442622951,
      "loss_control": 0.78857421875,
      "loss_data": 0.378173828125,
      "loss_total": 0.864208996295929,
      "step": 11
    },
    {
      "epoch": 0.009836065573770493,
      "loss_control": 0.82666015625,
      "loss_data": 0.0,
      "loss_total": 0.82666015625,
      "step": 12
    },
    {
      "epoch": 0.010655737704918032,
      "loss_control": 0.297119140625,
      "loss_data": 0.0,
      "loss_total": 0.297119140625,
      "step": 13
    },
    {
      "epoch": 0.011475409836065573,
      "loss_control": 1.306640625,
      "loss_data": 0.428466796875,
      "loss_total": 1.392333984375,
      "step": 14
    },
    {
      "epoch": 0.012295081967213115,
      "grad_norm": 1.5012738704681396,
      "learning_rate": 4.9808743169398906e-05,
      "loss": 0.8398,
      "step": 15
    },
    {
      "epoch": 0.012295081967213115,
      "loss_control": 0.63134765625,
      "loss_data": 0.0,
      "loss_total": 0.63134765625,
      "step": 15
    },
    {
      "epoch": 0.013114754098360656,
      "loss_control": 0.82275390625,
      "loss_data": 0.406982421875,
      "loss_total": 0.9041503667831421,
      "step": 16
    },
    {
      "epoch": 0.013934426229508197,
      "loss_control": 0.91650390625,
      "loss_data": 0.428955078125,
      "loss_total": 1.002294898033142,
      "step": 17
    },
    {
      "epoch": 0.014754098360655738,
      "loss_control": 1.0,
      "loss_data": 0.429931640625,
      "loss_total": 1.0859863758087158,
      "step": 18
    },
    {
      "epoch": 0.01557377049180328,
      "loss_control": 0.6083984375,
      "loss_data": 0.77099609375,
      "loss_total": 0.7625976800918579,
      "step": 19
    },
    {
      "epoch": 0.01639344262295082,
      "grad_norm": 1.022336721420288,
      "learning_rate": 4.974043715846995e-05,
      "loss": 0.8773,
      "step": 20
    },
    {
      "epoch": 0.01639344262295082,
      "loss_control": 0.64453125,
      "loss_data": 0.794189453125,
      "loss_total": 0.8033691644668579,
      "step": 20
    },
    {
      "epoch": 0.01721311475409836,
      "loss_control": 0.66796875,
      "loss_data": 0.0,
      "loss_total": 0.66796875,
      "step": 21
    },
    {
      "epoch": 0.018032786885245903,
      "loss_control": 0.482421875,
      "loss_data": 0.439208984375,
      "loss_total": 0.570263683795929,
      "step": 22
    },
    {
      "epoch": 0.018852459016393444,
      "loss_control": 0.759765625,
      "loss_data": 0.80615234375,
      "loss_total": 0.9209960699081421,
      "step": 23
    },
    {
      "epoch": 0.019672131147540985,
      "loss_control": 0.86962890625,
      "loss_data": 0.41796875,
      "loss_total": 0.9532226324081421,
      "step": 24
    },
    {
      "epoch": 0.020491803278688523,
      "grad_norm": 1.037191390991211,
      "learning_rate": 4.967213114754098e-05,
      "loss": 0.7832,
      "step": 25
    },
    {
      "epoch": 0.020491803278688523,
      "loss_control": 0.9443359375,
      "loss_data": 0.44189453125,
      "loss_total": 1.03271484375,
      "step": 25
    },
    {
      "epoch": 0.021311475409836064,
      "loss_control": 0.64111328125,
      "loss_data": 0.0,
      "loss_total": 0.64111328125,
      "step": 26
    },
    {
      "epoch": 0.022131147540983605,
      "loss_control": 0.65625,
      "loss_data": 0.414306640625,
      "loss_total": 0.7391113042831421,
      "step": 27
    },
    {
      "epoch": 0.022950819672131147,
      "loss_control": 0.8095703125,
      "loss_data": 0.41845703125,
      "loss_total": 0.893261730670929,
      "step": 28
    },
    {
      "epoch": 0.023770491803278688,
      "loss_control": 1.1796875,
      "loss_data": 0.0,
      "loss_total": 1.1796875,
      "step": 29
    },
    {
      "epoch": 0.02459016393442623,
      "grad_norm": 2.3259871006011963,
      "learning_rate": 4.9603825136612024e-05,
      "loss": 0.8972,
      "step": 30
    },
    {
      "epoch": 0.02459016393442623,
      "loss_control": 0.63818359375,
      "loss_data": 0.357666015625,
      "loss_total": 0.709716796875,
      "step": 30
    },
    {
      "epoch": 0.02540983606557377,
      "loss_control": 0.48486328125,
      "loss_data": 0.8125,
      "loss_total": 0.6473633050918579,
      "step": 31
    },
    {
      "epoch": 0.02622950819672131,
      "loss_control": 0.5927734375,
      "loss_data": 0.332275390625,
      "loss_total": 0.659228503704071,
      "step": 32
    },
    {
      "epoch": 0.027049180327868853,
      "loss_control": 0.671875,
      "loss_data": 0.39013671875,
      "loss_total": 0.7499023675918579,
      "step": 33
    },
    {
      "epoch": 0.027868852459016394,
      "loss_control": 0.595703125,
      "loss_data": 0.420654296875,
      "loss_total": 0.6798340082168579,
      "step": 34
    },
    {
      "epoch": 0.028688524590163935,
      "grad_norm": 0.6741154193878174,
      "learning_rate": 4.953551912568306e-05,
      "loss": 0.6892,
      "step": 35
    },
    {
      "epoch": 0.028688524590163935,
      "loss_control": 0.252197265625,
      "loss_data": 0.0,
      "loss_total": 0.252197265625,
      "step": 35
    },
    {
      "epoch": 0.029508196721311476,
      "loss_control": 0.853515625,
      "loss_data": 0.399169921875,
      "loss_total": 0.933349609375,
      "step": 36
    },
    {
      "epoch": 0.030327868852459017,
      "loss_control": 0.681640625,
      "loss_data": 0.411376953125,
      "loss_total": 0.763916015625,
      "step": 37
    },
    {
      "epoch": 0.03114754098360656,
      "loss_control": 0.38671875,
      "loss_data": 0.0,
      "loss_total": 0.38671875,
      "step": 38
    },
    {
      "epoch": 0.031967213114754096,
      "loss_control": 0.35693359375,
      "loss_data": 0.0,
      "loss_total": 0.35693359375,
      "step": 39
    },
    {
      "epoch": 0.03278688524590164,
      "grad_norm": 1.2291388511657715,
      "learning_rate": 4.94672131147541e-05,
      "loss": 0.5386,
      "step": 40
    },
    {
      "epoch": 0.03278688524590164,
      "loss_control": 0.6513671875,
      "loss_data": 0.78857421875,
      "loss_total": 0.80908203125,
      "step": 40
    },
    {
      "epoch": 0.03360655737704918,
      "loss_control": 0.374267578125,
      "loss_data": 0.4384765625,
      "loss_total": 0.46196287870407104,
      "step": 41
    },
    {
      "epoch": 0.03442622950819672,
      "loss_control": 0.410888671875,
      "loss_data": 0.45068359375,
      "loss_total": 0.501025378704071,
      "step": 42
    },
    {
      "epoch": 0.03524590163934426,
      "loss_control": 1.0234375,
      "loss_data": 0.0,
      "loss_total": 1.0234375,
      "step": 43
    },
    {
      "epoch": 0.036065573770491806,
      "loss_control": 0.2281494140625,
      "loss_data": 0.467041015625,
      "loss_total": 0.3215576112270355,
      "step": 44
    },
    {
      "epoch": 0.036885245901639344,
      "grad_norm": 0.4306834936141968,
      "learning_rate": 4.9398907103825136e-05,
      "loss": 0.6234,
      "step": 45
    },
    {
      "epoch": 0.036885245901639344,
      "loss_control": 0.425537109375,
      "loss_data": 0.0,
      "loss_total": 0.425537109375,
      "step": 45
    },
    {
      "epoch": 0.03770491803278689,
      "loss_control": 0.57568359375,
      "loss_data": 0.3583984375,
      "loss_total": 0.6473633050918579,
      "step": 46
    },
    {
      "epoch": 0.038524590163934426,
      "loss_control": 1.07421875,
      "loss_data": 0.361328125,
      "loss_total": 1.146484375,
      "step": 47
    },
    {
      "epoch": 0.03934426229508197,
      "loss_control": 0.470947265625,
      "loss_data": 0.35400390625,
      "loss_total": 0.541748046875,
      "step": 48
    },
    {
      "epoch": 0.04016393442622951,
      "loss_control": 0.60205078125,
      "loss_data": 0.0,
      "loss_total": 0.60205078125,
      "step": 49
    },
    {
      "epoch": 0.040983606557377046,
      "grad_norm": 0.996304452419281,
      "learning_rate": 4.933060109289618e-05,
      "loss": 0.6726,
      "step": 50
    },
    {
      "epoch": 0.040983606557377046,
      "loss_control": 0.53369140625,
      "loss_data": 0.0,
      "loss_total": 0.53369140625,
      "step": 50
    },
    {
      "epoch": 0.04180327868852459,
      "loss_control": 0.56689453125,
      "loss_data": 0.805419921875,
      "loss_total": 0.727978527545929,
      "step": 51
    },
    {
      "epoch": 0.04262295081967213,
      "loss_control": 0.7177734375,
      "loss_data": 0.379638671875,
      "loss_total": 0.793701171875,
      "step": 52
    },
    {
      "epoch": 0.04344262295081967,
      "loss_control": 0.59375,
      "loss_data": 0.42333984375,
      "loss_total": 0.678417980670929,
      "step": 53
    },
    {
      "epoch": 0.04426229508196721,
      "loss_control": 0.8076171875,
      "loss_data": 0.452392578125,
      "loss_total": 0.8980957269668579,
      "step": 54
    },
    {
      "epoch": 0.045081967213114756,
      "grad_norm": 1.080223560333252,
      "learning_rate": 4.926229508196721e-05,
      "loss": 0.7264,
      "step": 55
    },
    {
      "epoch": 0.045081967213114756,
      "loss_control": 0.292724609375,
      "loss_data": 0.0,
      "loss_total": 0.292724609375,
      "step": 55
    },
    {
      "epoch": 0.04590163934426229,
      "loss_control": 0.34521484375,
      "loss_data": 0.0,
      "loss_total": 0.34521484375,
      "step": 56
    },
    {
      "epoch": 0.04672131147540984,
      "loss_control": 0.399658203125,
      "loss_data": 0.0,
      "loss_total": 0.399658203125,
      "step": 57
    },
    {
      "epoch": 0.047540983606557376,
      "loss_control": 0.5732421875,
      "loss_data": 0.358642578125,
      "loss_total": 0.644970715045929,
      "step": 58
    },
    {
      "epoch": 0.04836065573770492,
      "loss_control": 0.20947265625,
      "loss_data": 0.0,
      "loss_total": 0.20947265625,
      "step": 59
    },
    {
      "epoch": 0.04918032786885246,
      "grad_norm": 0.6389829516410828,
      "learning_rate": 4.9193989071038255e-05,
      "loss": 0.3784,
      "step": 60
    },
    {
      "epoch": 0.04918032786885246,
      "loss_control": 0.466796875,
      "loss_data": 0.0,
      "loss_total": 0.466796875,
      "step": 60
    },
    {
      "epoch": 0.05,
      "loss_control": 0.2117919921875,
      "loss_data": 0.0,
      "loss_total": 0.2117919921875,
      "step": 61
    },
    {
      "epoch": 0.05081967213114754,
      "loss_control": 0.53173828125,
      "loss_data": 0.78076171875,
      "loss_total": 0.6878906488418579,
      "step": 62
    },
    {
      "epoch": 0.051639344262295085,
      "loss_control": 0.77392578125,
      "loss_data": 0.8828125,
      "loss_total": 0.950488269329071,
      "step": 63
    },
    {
      "epoch": 0.05245901639344262,
      "loss_control": 0.302734375,
      "loss_data": 0.0,
      "loss_total": 0.302734375,
      "step": 64
    },
    {
      "epoch": 0.05327868852459016,
      "grad_norm": 1.0814661979675293,
      "learning_rate": 4.912568306010929e-05,
      "loss": 0.5239,
      "step": 65
    },
    {
      "epoch": 0.05327868852459016,
      "loss_control": 0.42724609375,
      "loss_data": 0.456787109375,
      "loss_total": 0.518603503704071,
      "step": 65
    },
    {
      "epoch": 0.054098360655737705,
      "loss_control": 0.321044921875,
      "loss_data": 0.8623046875,
      "loss_total": 0.4935058653354645,
      "step": 66
    },
    {
      "epoch": 0.05491803278688524,
      "loss_control": 0.57470703125,
      "loss_data": 0.0,
      "loss_total": 0.57470703125,
      "step": 67
    },
    {
      "epoch": 0.05573770491803279,
      "loss_control": 0.1539306640625,
      "loss_data": 0.44677734375,
      "loss_total": 0.2432861328125,
      "step": 68
    },
    {
      "epoch": 0.056557377049180325,
      "loss_control": 0.42724609375,
      "loss_data": 0.432861328125,
      "loss_total": 0.5138183832168579,
      "step": 69
    },
    {
      "epoch": 0.05737704918032787,
      "grad_norm": 1.0969901084899902,
      "learning_rate": 4.905737704918033e-05,
      "loss": 0.4688,
      "step": 70
    },
    {
      "epoch": 0.05737704918032787,
      "loss_control": 0.583984375,
      "loss_data": 0.425537109375,
      "loss_total": 0.6690918207168579,
      "step": 70
    },
    {
      "epoch": 0.05819672131147541,
      "loss_control": 0.91259765625,
      "loss_data": 0.43896484375,
      "loss_total": 1.000390648841858,
      "step": 71
    },
    {
      "epoch": 0.05901639344262295,
      "loss_control": 0.3359375,
      "loss_data": 0.40869140625,
      "loss_total": 0.41767579317092896,
      "step": 72
    },
    {
      "epoch": 0.05983606557377049,
      "loss_control": 0.458740234375,
      "loss_data": 0.425537109375,
      "loss_total": 0.5438476800918579,
      "step": 73
    },
    {
      "epoch": 0.060655737704918035,
      "loss_control": 0.164306640625,
      "loss_data": 0.0,
      "loss_total": 0.164306640625,
      "step": 74
    },
    {
      "epoch": 0.06147540983606557,
      "grad_norm": 0.648086667060852,
      "learning_rate": 4.8989071038251366e-05,
      "loss": 0.5591,
      "step": 75
    },
    {
      "epoch": 0.06147540983606557,
      "loss_control": 0.4365234375,
      "loss_data": 0.82275390625,
      "loss_total": 0.60107421875,
      "step": 75
    },
    {
      "epoch": 0.06229508196721312,
      "loss_control": 0.1331787109375,
      "loss_data": 0.457763671875,
      "loss_total": 0.2247314453125,
      "step": 76
    },
    {
      "epoch": 0.06311475409836066,
      "loss_control": 0.23974609375,
      "loss_data": 0.410888671875,
      "loss_total": 0.3219238221645355,
      "step": 77
    },
    {
      "epoch": 0.06393442622950819,
      "loss_control": 0.362548828125,
      "loss_data": 0.4443359375,
      "loss_total": 0.451416015625,
      "step": 78
    },
    {
      "epoch": 0.06475409836065574,
      "loss_control": 0.210205078125,
      "loss_data": 0.443359375,
      "loss_total": 0.29887694120407104,
      "step": 79
    },
    {
      "epoch": 0.06557377049180328,
      "grad_norm": 0.5375922322273254,
      "learning_rate": 4.892076502732241e-05,
      "loss": 0.3796,
      "step": 80
    },
    {
      "epoch": 0.06557377049180328,
      "loss_control": 0.37158203125,
      "loss_data": 0.89794921875,
      "loss_total": 0.5511718988418579,
      "step": 80
    },
    {
      "epoch": 0.06639344262295081,
      "loss_control": 0.1634521484375,
      "loss_data": 0.0,
      "loss_total": 0.1634521484375,
      "step": 81
    },
    {
      "epoch": 0.06721311475409836,
      "loss_control": 0.25634765625,
      "loss_data": 0.8779296875,
      "loss_total": 0.43193358182907104,
      "step": 82
    },
    {
      "epoch": 0.0680327868852459,
      "loss_control": 0.176513671875,
      "loss_data": 0.442626953125,
      "loss_total": 0.2650390565395355,
      "step": 83
    },
    {
      "epoch": 0.06885245901639345,
      "loss_control": 0.07977294921875,
      "loss_data": 0.401123046875,
      "loss_total": 0.15999755263328552,
      "step": 84
    },
    {
      "epoch": 0.06967213114754098,
      "grad_norm": 0.3771693706512451,
      "learning_rate": 4.885245901639344e-05,
      "loss": 0.3143,
      "step": 85
    },
    {
      "epoch": 0.06967213114754098,
      "loss_control": 0.2481689453125,
      "loss_data": 0.422607421875,
      "loss_total": 0.33269041776657104,
      "step": 85
    },
    {
      "epoch": 0.07049180327868852,
      "loss_control": 0.2296142578125,
      "loss_data": 0.477294921875,
      "loss_total": 0.3250732421875,
      "step": 86
    },
    {
      "epoch": 0.07131147540983607,
      "loss_control": 0.07891845703125,
      "loss_data": 0.0,
      "loss_total": 0.07891845703125,
      "step": 87
    },
    {
      "epoch": 0.07213114754098361,
      "loss_control": 0.259033203125,
      "loss_data": 0.44970703125,
      "loss_total": 0.3489746153354645,
      "step": 88
    },
    {
      "epoch": 0.07295081967213114,
      "loss_control": 0.1724853515625,
      "loss_data": 0.0,
      "loss_total": 0.1724853515625,
      "step": 89
    },
    {
      "epoch": 0.07377049180327869,
      "grad_norm": 0.5099152326583862,
      "learning_rate": 4.8784153005464485e-05,
      "loss": 0.2516,
      "step": 90
    },
    {
      "epoch": 0.07377049180327869,
      "loss_control": 0.097900390625,
      "loss_data": 0.0,
      "loss_total": 0.097900390625,
      "step": 90
    },
    {
      "epoch": 0.07459016393442623,
      "loss_control": 0.08990478515625,
      "loss_data": 0.935302734375,
      "loss_total": 0.27696532011032104,
      "step": 91
    },
    {
      "epoch": 0.07540983606557378,
      "loss_control": 0.251953125,
      "loss_data": 0.0,
      "loss_total": 0.251953125,
      "step": 92
    },
    {
      "epoch": 0.07622950819672131,
      "loss_control": 0.1177978515625,
      "loss_data": 0.47265625,
      "loss_total": 0.21232910454273224,
      "step": 93
    },
    {
      "epoch": 0.07704918032786885,
      "loss_control": 0.25634765625,
      "loss_data": 0.0,
      "loss_total": 0.25634765625,
      "step": 94
    },
    {
      "epoch": 0.0778688524590164,
      "grad_norm": 2.062988519668579,
      "learning_rate": 4.871584699453552e-05,
      "loss": 0.2191,
      "step": 95
    },
    {
      "epoch": 0.0778688524590164,
      "loss_control": 0.10577392578125,
      "loss_data": 0.438720703125,
      "loss_total": 0.19351807236671448,
      "step": 95
    },
    {
      "epoch": 0.07868852459016394,
      "loss_control": 0.36181640625,
      "loss_data": 0.447509765625,
      "loss_total": 0.4513183534145355,
      "step": 96
    },
    {
      "epoch": 0.07950819672131147,
      "loss_control": 0.1517333984375,
      "loss_data": 0.44580078125,
      "loss_total": 0.24089355766773224,
      "step": 97
    },
    {
      "epoch": 0.08032786885245902,
      "loss_control": 0.2626953125,
      "loss_data": 0.45703125,
      "loss_total": 0.3541015684604645,
      "step": 98
    },
    {
      "epoch": 0.08114754098360656,
      "loss_control": 0.11474609375,
      "loss_data": 0.0,
      "loss_total": 0.11474609375,
      "step": 99
    },
    {
      "epoch": 0.08196721311475409,
      "grad_norm": 0.9208279252052307,
      "learning_rate": 4.864754098360656e-05,
      "loss": 0.2709,
      "step": 100
    },
    {
      "epoch": 0.08196721311475409,
      "loss_control": 0.06378173828125,
      "loss_data": 0.46923828125,
      "loss_total": 0.15762940049171448,
      "step": 100
    },
    {
      "epoch": 0.08278688524590164,
      "loss_control": 0.2108154296875,
      "loss_data": 0.344970703125,
      "loss_total": 0.2798095643520355,
      "step": 101
    },
    {
      "epoch": 0.08360655737704918,
      "loss_control": 0.2646484375,
      "loss_data": 0.0,
      "loss_total": 0.2646484375,
      "step": 102
    },
    {
      "epoch": 0.08442622950819673,
      "loss_control": 0.16650390625,
      "loss_data": 0.91650390625,
      "loss_total": 0.34980469942092896,
      "step": 103
    },
    {
      "epoch": 0.08524590163934426,
      "loss_control": 0.1767578125,
      "loss_data": 0.0,
      "loss_total": 0.1767578125,
      "step": 104
    },
    {
      "epoch": 0.0860655737704918,
      "grad_norm": 1.1876907348632812,
      "learning_rate": 4.85792349726776e-05,
      "loss": 0.2457,
      "step": 105
    },
    {
      "epoch": 0.0860655737704918,
      "loss_control": 0.38330078125,
      "loss_data": 0.447021484375,
      "loss_total": 0.47270506620407104,
      "step": 105
    },
    {
      "epoch": 0.08688524590163935,
      "loss_control": 0.07275390625,
      "loss_data": 0.0,
      "loss_total": 0.07275390625,
      "step": 106
    },
    {
      "epoch": 0.08770491803278689,
      "loss_control": 0.187255859375,
      "loss_data": 0.468505859375,
      "loss_total": 0.28095704317092896,
      "step": 107
    },
    {
      "epoch": 0.08852459016393442,
      "loss_control": 0.0775146484375,
      "loss_data": 0.0,
      "loss_total": 0.0775146484375,
      "step": 108
    },
    {
      "epoch": 0.08934426229508197,
      "loss_control": 0.1551513671875,
      "loss_data": 0.443115234375,
      "loss_total": 0.2437744140625,
      "step": 109
    },
    {
      "epoch": 0.09016393442622951,
      "grad_norm": 0.557873547077179,
      "learning_rate": 4.851092896174864e-05,
      "loss": 0.2295,
      "step": 110
    },
    {
      "epoch": 0.09016393442622951,
      "loss_control": 0.0849609375,
      "loss_data": 0.462890625,
      "loss_total": 0.17753906548023224,
      "step": 110
    },
    {
      "epoch": 0.09098360655737706,
      "loss_control": 0.0709228515625,
      "loss_data": 0.0,
      "loss_total": 0.0709228515625,
      "step": 111
    },
    {
      "epoch": 0.09180327868852459,
      "loss_control": 0.07550048828125,
      "loss_data": 0.4375,
      "loss_total": 0.16300049424171448,
      "step": 112
    },
    {
      "epoch": 0.09262295081967213,
      "loss_control": 0.1671142578125,
      "loss_data": 0.45361328125,
      "loss_total": 0.2578369081020355,
      "step": 113
    },
    {
      "epoch": 0.09344262295081968,
      "loss_control": 0.2362060546875,
      "loss_data": 0.0,
      "loss_total": 0.2362060546875,
      "step": 114
    },
    {
      "epoch": 0.0942622950819672,
      "grad_norm": 0.44968411326408386,
      "learning_rate": 4.844262295081968e-05,
      "loss": 0.1811,
      "step": 115
    },
    {
      "epoch": 0.0942622950819672,
      "loss_control": 0.28173828125,
      "loss_data": 0.856201171875,
      "loss_total": 0.4529785215854645,
      "step": 115
    },
    {
      "epoch": 0.09508196721311475,
      "loss_control": 0.34814453125,
      "loss_data": 0.0,
      "loss_total": 0.34814453125,
      "step": 116
    },
    {
      "epoch": 0.0959016393442623,
      "loss_control": 0.1597900390625,
      "loss_data": 0.971923828125,
      "loss_total": 0.35417479276657104,
      "step": 117
    },
    {
      "epoch": 0.09672131147540984,
      "loss_control": 0.208251953125,
      "loss_data": 0.469970703125,
      "loss_total": 0.30224609375,
      "step": 118
    },
    {
      "epoch": 0.09754098360655737,
      "loss_control": 0.1895751953125,
      "loss_data": 0.897705078125,
      "loss_total": 0.3691162168979645,
      "step": 119
    },
    {
      "epoch": 0.09836065573770492,
      "grad_norm": 0.8472217321395874,
      "learning_rate": 4.8374316939890715e-05,
      "loss": 0.3653,
      "step": 120
    },
    {
      "epoch": 0.09836065573770492,
      "loss_control": 0.1412353515625,
      "loss_data": 0.0,
      "loss_total": 0.1412353515625,
      "step": 120
    },
    {
      "epoch": 0.09918032786885246,
      "loss_control": 0.0762939453125,
      "loss_data": 0.934814453125,
      "loss_total": 0.26325684785842896,
      "step": 121
    },
    {
      "epoch": 0.1,
      "loss_control": 0.325927734375,
      "loss_data": 0.442138671875,
      "loss_total": 0.41435545682907104,
      "step": 122
    },
    {
      "epoch": 0.10081967213114754,
      "loss_control": 0.130126953125,
      "loss_data": 0.0,
      "loss_total": 0.130126953125,
      "step": 123
    },
    {
      "epoch": 0.10163934426229508,
      "loss_control": 0.07550048828125,
      "loss_data": 0.462890625,
      "loss_total": 0.16807861626148224,
      "step": 124
    },
    {
      "epoch": 0.10245901639344263,
      "grad_norm": 0.573451817035675,
      "learning_rate": 4.830601092896175e-05,
      "loss": 0.2234,
      "step": 125
    },
    {
      "epoch": 0.10245901639344263,
      "loss_control": 0.133056640625,
      "loss_data": 0.4462890625,
      "loss_total": 0.22231444716453552,
      "step": 125
    },
    {
      "epoch": 0.10327868852459017,
      "loss_control": 0.0721435546875,
      "loss_data": 0.465087890625,
      "loss_total": 0.1651611328125,
      "step": 126
    },
    {
      "epoch": 0.1040983606557377,
      "loss_control": 0.302978515625,
      "loss_data": 0.458740234375,
      "loss_total": 0.39472657442092896,
      "step": 127
    },
    {
      "epoch": 0.10491803278688525,
      "loss_control": 0.07965087890625,
      "loss_data": 0.0,
      "loss_total": 0.07965087890625,
      "step": 128
    },
    {
      "epoch": 0.10573770491803279,
      "loss_control": 0.06048583984375,
      "loss_data": 0.0,
      "loss_total": 0.06048583984375,
      "step": 129
    },
    {
      "epoch": 0.10655737704918032,
      "grad_norm": 0.4788219928741455,
      "learning_rate": 4.823770491803279e-05,
      "loss": 0.1845,
      "step": 130
    },
    {
      "epoch": 0.10655737704918032,
      "loss_control": 0.08526611328125,
      "loss_data": 0.87939453125,
      "loss_total": 0.2611450254917145,
      "step": 130
    },
    {
      "epoch": 0.10737704918032787,
      "loss_control": 0.040496826171875,
      "loss_data": 0.483642578125,
      "loss_total": 0.13722534477710724,
      "step": 131
    },
    {
      "epoch": 0.10819672131147541,
      "loss_control": 0.048919677734375,
      "loss_data": 0.485107421875,
      "loss_total": 0.14594116806983948,
      "step": 132
    },
    {
      "epoch": 0.10901639344262296,
      "loss_control": 0.07879638671875,
      "loss_data": 0.4326171875,
      "loss_total": 0.16531983017921448,
      "step": 133
    },
    {
      "epoch": 0.10983606557377049,
      "loss_control": 0.0211944580078125,
      "loss_data": 0.0,
      "loss_total": 0.0211944580078125,
      "step": 134
    },
    {
      "epoch": 0.11065573770491803,
      "grad_norm": 0.377080500125885,
      "learning_rate": 4.816939890710383e-05,
      "loss": 0.1462,
      "step": 135
    },
    {
      "epoch": 0.11065573770491803,
      "loss_control": 0.290283203125,
      "loss_data": 0.444580078125,
      "loss_total": 0.37919920682907104,
      "step": 135
    },
    {
      "epoch": 0.11147540983606558,
      "loss_control": 0.1549072265625,
      "loss_data": 0.0,
      "loss_total": 0.1549072265625,
      "step": 136
    },
    {
      "epoch": 0.11229508196721312,
      "loss_control": 0.017608642578125,
      "loss_data": 0.0,
      "loss_total": 0.017608642578125,
      "step": 137
    },
    {
      "epoch": 0.11311475409836065,
      "loss_control": 0.149169921875,
      "loss_data": 0.46044921875,
      "loss_total": 0.24125976860523224,
      "step": 138
    },
    {
      "epoch": 0.1139344262295082,
      "loss_control": 0.01299285888671875,
      "loss_data": 0.0,
      "loss_total": 0.01299285888671875,
      "step": 139
    },
    {
      "epoch": 0.11475409836065574,
      "grad_norm": 0.0859069675207138,
      "learning_rate": 4.810109289617486e-05,
      "loss": 0.1612,
      "step": 140
    },
    {
      "epoch": 0.11475409836065574,
      "loss_control": 0.311767578125,
      "loss_data": 0.0,
      "loss_total": 0.311767578125,
      "step": 140
    },
    {
      "epoch": 0.11557377049180328,
      "loss_control": 0.0237884521484375,
      "loss_data": 0.934814453125,
      "loss_total": 0.21075133979320526,
      "step": 141
    },
    {
      "epoch": 0.11639344262295082,
      "loss_control": 0.01934814453125,
      "loss_data": 0.491943359375,
      "loss_total": 0.11773681640625,
      "step": 142
    },
    {
      "epoch": 0.11721311475409836,
      "loss_control": 0.027587890625,
      "loss_data": 0.482666015625,
      "loss_total": 0.12412109225988388,
      "step": 143
    },
    {
      "epoch": 0.1180327868852459,
      "loss_control": 0.046844482421875,
      "loss_data": 0.958251953125,
      "loss_total": 0.238494873046875,
      "step": 144
    },
    {
      "epoch": 0.11885245901639344,
      "grad_norm": 0.22710730135440826,
      "learning_rate": 4.8032786885245904e-05,
      "loss": 0.2006,
      "step": 145
    },
    {
      "epoch": 0.11885245901639344,
      "loss_control": 0.0238800048828125,
      "loss_data": 0.0,
      "loss_total": 0.0238800048828125,
      "step": 145
    },
    {
      "epoch": 0.11967213114754098,
      "loss_control": 0.0523681640625,
      "loss_data": 0.95458984375,
      "loss_total": 0.2432861328125,
      "step": 146
    },
    {
      "epoch": 0.12049180327868853,
      "loss_control": 0.208984375,
      "loss_data": 0.427001953125,
      "loss_total": 0.29438477754592896,
      "step": 147
    },
    {
      "epoch": 0.12131147540983607,
      "loss_control": 0.011566162109375,
      "loss_data": 0.496337890625,
      "loss_total": 0.11083374172449112,
      "step": 148
    },
    {
      "epoch": 0.1221311475409836,
      "loss_control": 0.03765869140625,
      "loss_data": 0.9658203125,
      "loss_total": 0.23082275688648224,
      "step": 149
    },
    {
      "epoch": 0.12295081967213115,
      "grad_norm": 0.17496781051158905,
      "learning_rate": 4.796448087431694e-05,
      "loss": 0.1806,
      "step": 150
    },
    {
      "epoch": 0.12295081967213115,
      "loss_control": 0.025299072265625,
      "loss_data": 0.0,
      "loss_total": 0.025299072265625,
      "step": 150
    },
    {
      "epoch": 0.12377049180327869,
      "loss_control": 0.0165252685546875,
      "loss_data": 0.908203125,
      "loss_total": 0.1981658935546875,
      "step": 151
    },
    {
      "epoch": 0.12459016393442623,
      "loss_control": 0.058013916015625,
      "loss_data": 0.473388671875,
      "loss_total": 0.15269166231155396,
      "step": 152
    },
    {
      "epoch": 0.12540983606557377,
      "loss_control": 0.075439453125,
      "loss_data": 0.873779296875,
      "loss_total": 0.25019532442092896,
      "step": 153
    },
    {
      "epoch": 0.12622950819672132,
      "loss_control": 0.10321044921875,
      "loss_data": 0.459228515625,
      "loss_total": 0.19505615532398224,
      "step": 154
    },
    {
      "epoch": 0.12704918032786885,
      "grad_norm": 3.8184874057769775,
      "learning_rate": 4.789617486338798e-05,
      "loss": 0.1643,
      "step": 155
    },
    {
      "epoch": 0.12704918032786885,
      "loss_control": 0.014984130859375,
      "loss_data": 0.49169921875,
      "loss_total": 0.11332397907972336,
      "step": 155
    },
    {
      "epoch": 0.12786885245901639,
      "loss_control": 0.029052734375,
      "loss_data": 0.495361328125,
      "loss_total": 0.12812501192092896,
      "step": 156
    },
    {
      "epoch": 0.12868852459016394,
      "loss_control": 0.0731201171875,
      "loss_data": 0.0,
      "loss_total": 0.0731201171875,
      "step": 157
    },
    {
      "epoch": 0.12950819672131147,
      "loss_control": 0.18212890625,
      "loss_data": 0.0,
      "loss_total": 0.18212890625,
      "step": 158
    },
    {
      "epoch": 0.130327868852459,
      "loss_control": 0.0213470458984375,
      "loss_data": 0.927734375,
      "loss_total": 0.2068939208984375,
      "step": 159
    },
    {
      "epoch": 0.13114754098360656,
      "grad_norm": 0.1536943018436432,
      "learning_rate": 4.7827868852459016e-05,
      "loss": 0.1407,
      "step": 160
    },
    {
      "epoch": 0.13114754098360656,
      "loss_control": 0.08929443359375,
      "loss_data": 0.94921875,
      "loss_total": 0.2791382074356079,
      "step": 160
    },
    {
      "epoch": 0.1319672131147541,
      "loss_control": 0.1302490234375,
      "loss_data": 0.945068359375,
      "loss_total": 0.31926268339157104,
      "step": 161
    },
    {
      "epoch": 0.13278688524590163,
      "loss_control": 0.023681640625,
      "loss_data": 0.0,
      "loss_total": 0.023681640625,
      "step": 162
    },
    {
      "epoch": 0.13360655737704918,
      "loss_control": 0.01461029052734375,
      "loss_data": 0.955810546875,
      "loss_total": 0.20577239990234375,
      "step": 163
    },
    {
      "epoch": 0.13442622950819672,
      "loss_control": 0.132568359375,
      "loss_data": 0.0,
      "loss_total": 0.132568359375,
      "step": 164
    },
    {
      "epoch": 0.13524590163934427,
      "grad_norm": 0.5209565758705139,
      "learning_rate": 4.775956284153006e-05,
      "loss": 0.1921,
      "step": 165
    },
    {
      "epoch": 0.13524590163934427,
      "loss_control": 0.0216217041015625,
      "loss_data": 0.486083984375,
      "loss_total": 0.11883850395679474,
      "step": 165
    },
    {
      "epoch": 0.1360655737704918,
      "loss_control": 0.0687255859375,
      "loss_data": 0.912841796875,
      "loss_total": 0.25129395723342896,
      "step": 166
    },
    {
      "epoch": 0.13688524590163934,
      "loss_control": 0.04461669921875,
      "loss_data": 0.879150390625,
      "loss_total": 0.22044678032398224,
      "step": 167
    },
    {
      "epoch": 0.1377049180327869,
      "loss_control": 0.022735595703125,
      "loss_data": 0.460205078125,
      "loss_total": 0.114776611328125,
      "step": 168
    },
    {
      "epoch": 0.13852459016393442,
      "loss_control": 0.03125,
      "loss_data": 0.971435546875,
      "loss_total": 0.22553710639476776,
      "step": 169
    },
    {
      "epoch": 0.13934426229508196,
      "grad_norm": 0.213332861661911,
      "learning_rate": 4.769125683060109e-05,
      "loss": 0.1862,
      "step": 170
    },
    {
      "epoch": 0.13934426229508196,
      "loss_control": 0.0286865234375,
      "loss_data": 0.0,
      "loss_total": 0.0286865234375,
      "step": 170
    },
    {
      "epoch": 0.14016393442622951,
      "loss_control": 0.013458251953125,
      "loss_data": 0.0,
      "loss_total": 0.013458251953125,
      "step": 171
    },
    {
      "epoch": 0.14098360655737704,
      "loss_control": 0.0271759033203125,
      "loss_data": 0.0,
      "loss_total": 0.0271759033203125,
      "step": 172
    },
    {
      "epoch": 0.1418032786885246,
      "loss_control": 0.0633544921875,
      "loss_data": 0.462158203125,
      "loss_total": 0.15578612685203552,
      "step": 173
    },
    {
      "epoch": 0.14262295081967213,
      "loss_control": 0.012725830078125,
      "loss_data": 0.494873046875,
      "loss_total": 0.11170043796300888,
      "step": 174
    },
    {
      "epoch": 0.14344262295081966,
      "grad_norm": 0.09294101595878601,
      "learning_rate": 4.7622950819672134e-05,
      "loss": 0.0674,
      "step": 175
    },
    {
      "epoch": 0.14344262295081966,
      "loss_control": 0.01227569580078125,
      "loss_data": 0.971923828125,
      "loss_total": 0.2066604644060135,
      "step": 175
    },
    {
      "epoch": 0.14426229508196722,
      "loss_control": 0.007328033447265625,
      "loss_data": 0.99267578125,
      "loss_total": 0.20586319267749786,
      "step": 176
    },
    {
      "epoch": 0.14508196721311475,
      "loss_control": 0.0192108154296875,
      "loss_data": 0.944091796875,
      "loss_total": 0.20802918076515198,
      "step": 177
    },
    {
      "epoch": 0.14590163934426228,
      "loss_control": 0.116943359375,
      "loss_data": 0.0,
      "loss_total": 0.116943359375,
      "step": 178
    },
    {
      "epoch": 0.14672131147540984,
      "loss_control": 0.0130767822265625,
      "loss_data": 0.480224609375,
      "loss_total": 0.10912170261144638,
      "step": 179
    },
    {
      "epoch": 0.14754098360655737,
      "grad_norm": 0.09173150360584259,
      "learning_rate": 4.755464480874317e-05,
      "loss": 0.1693,
      "step": 180
    },
    {
      "epoch": 0.14754098360655737,
      "loss_control": 0.11639404296875,
      "loss_data": 0.0,
      "loss_total": 0.11639404296875,
      "step": 180
    },
    {
      "epoch": 0.1483606557377049,
      "loss_control": 0.038482666015625,
      "loss_data": 0.0,
      "loss_total": 0.038482666015625,
      "step": 181
    },
    {
      "epoch": 0.14918032786885246,
      "loss_control": 0.1494140625,
      "loss_data": 0.942138671875,
      "loss_total": 0.33784180879592896,
      "step": 182
    },
    {
      "epoch": 0.15,
      "loss_control": 0.024627685546875,
      "loss_data": 0.484375,
      "loss_total": 0.12150269001722336,
      "step": 183
    },
    {
      "epoch": 0.15081967213114755,
      "loss_control": 0.02001953125,
      "loss_data": 0.486572265625,
      "loss_total": 0.11733398586511612,
      "step": 184
    },
    {
      "epoch": 0.15163934426229508,
      "grad_norm": 0.17790445685386658,
      "learning_rate": 4.748633879781421e-05,
      "loss": 0.1463,
      "step": 185
    },
    {
      "epoch": 0.15163934426229508,
      "loss_control": 0.015899658203125,
      "loss_data": 0.945068359375,
      "loss_total": 0.20491333305835724,
      "step": 185
    },
    {
      "epoch": 0.15245901639344261,
      "loss_control": 0.0220184326171875,
      "loss_data": 0.46142578125,
      "loss_total": 0.1143035888671875,
      "step": 186
    },
    {
      "epoch": 0.15327868852459017,
      "loss_control": 0.0313720703125,
      "loss_data": 0.45361328125,
      "loss_total": 0.12209472805261612,
      "step": 187
    },
    {
      "epoch": 0.1540983606557377,
      "loss_control": 0.03948974609375,
      "loss_data": 0.0,
      "loss_total": 0.03948974609375,
      "step": 188
    },
    {
      "epoch": 0.15491803278688523,
      "loss_control": 0.0258636474609375,
      "loss_data": 0.480712890625,
      "loss_total": 0.12200623005628586,
      "step": 189
    },
    {
      "epoch": 0.1557377049180328,
      "grad_norm": 0.2327778935432434,
      "learning_rate": 4.7418032786885246e-05,
      "loss": 0.1206,
      "step": 190
    },
    {
      "epoch": 0.1557377049180328,
      "loss_control": 0.0225067138671875,
      "loss_data": 0.45751953125,
      "loss_total": 0.11401062458753586,
      "step": 190
    },
    {
      "epoch": 0.15655737704918032,
      "loss_control": 0.054656982421875,
      "loss_data": 0.471435546875,
      "loss_total": 0.14894409477710724,
      "step": 191
    },
    {
      "epoch": 0.15737704918032788,
      "loss_control": 0.01438140869140625,
      "loss_data": 0.463134765625,
      "loss_total": 0.10700836032629013,
      "step": 192
    },
    {
      "epoch": 0.1581967213114754,
      "loss_control": 0.008453369140625,
      "loss_data": 0.475830078125,
      "loss_total": 0.10361938923597336,
      "step": 193
    },
    {
      "epoch": 0.15901639344262294,
      "loss_control": 0.01934814453125,
      "loss_data": 0.4873046875,
      "loss_total": 0.11680908501148224,
      "step": 194
    },
    {
      "epoch": 0.1598360655737705,
      "grad_norm": 0.18901363015174866,
      "learning_rate": 4.734972677595629e-05,
      "loss": 0.1181,
      "step": 195
    },
    {
      "epoch": 0.1598360655737705,
      "loss_control": 0.04766845703125,
      "loss_data": 0.950927734375,
      "loss_total": 0.23785400390625,
      "step": 195
    },
    {
      "epoch": 0.16065573770491803,
      "loss_control": 0.020660400390625,
      "loss_data": 0.45849609375,
      "loss_total": 0.11235962063074112,
      "step": 196
    },
    {
      "epoch": 0.16147540983606556,
      "loss_control": 0.0178985595703125,
      "loss_data": 0.0,
      "loss_total": 0.0178985595703125,
      "step": 197
    },
    {
      "epoch": 0.16229508196721312,
      "loss_control": 0.0367431640625,
      "loss_data": 0.935546875,
      "loss_total": 0.22385254502296448,
      "step": 198
    },
    {
      "epoch": 0.16311475409836065,
      "loss_control": 0.0031147003173828125,
      "loss_data": 0.0,
      "loss_total": 0.0031147003173828125,
      "step": 199
    },
    {
      "epoch": 0.16393442622950818,
      "grad_norm": 0.02266390435397625,
      "learning_rate": 4.728142076502732e-05,
      "loss": 0.119,
      "step": 200
    },
    {
      "epoch": 0.16393442622950818,
      "loss_control": 0.0176849365234375,
      "loss_data": 0.973876953125,
      "loss_total": 0.21246032416820526,
      "step": 200
    },
    {
      "epoch": 0.16475409836065574,
      "loss_control": 0.00757598876953125,
      "loss_data": 0.497314453125,
      "loss_total": 0.10703887790441513,
      "step": 201
    },
    {
      "epoch": 0.16557377049180327,
      "loss_control": 0.004791259765625,
      "loss_data": 0.4970703125,
      "loss_total": 0.10420532524585724,
      "step": 202
    },
    {
      "epoch": 0.16639344262295083,
      "loss_control": 0.019561767578125,
      "loss_data": 0.4853515625,
      "loss_total": 0.11663208156824112,
      "step": 203
    },
    {
      "epoch": 0.16721311475409836,
      "loss_control": 0.137451171875,
      "loss_data": 0.95703125,
      "loss_total": 0.328857421875,
      "step": 204
    },
    {
      "epoch": 0.1680327868852459,
      "grad_norm": 1.6678637266159058,
      "learning_rate": 4.7213114754098365e-05,
      "loss": 0.1738,
      "step": 205
    },
    {
      "epoch": 0.1680327868852459,
      "loss_control": 0.01165008544921875,
      "loss_data": 0.495849609375,
      "loss_total": 0.11082001030445099,
      "step": 205
    },
    {
      "epoch": 0.16885245901639345,
      "loss_control": 0.08941650390625,
      "loss_data": 0.0,
      "loss_total": 0.08941650390625,
      "step": 206
    },
    {
      "epoch": 0.16967213114754098,
      "loss_control": 0.00473785400390625,
      "loss_data": 0.9921875,
      "loss_total": 0.203175351023674,
      "step": 207
    },
    {
      "epoch": 0.17049180327868851,
      "loss_control": 0.0213775634765625,
      "loss_data": 0.490478515625,
      "loss_total": 0.11947327107191086,
      "step": 208
    },
    {
      "epoch": 0.17131147540983607,
      "loss_control": 0.0093994140625,
      "loss_data": 0.0,
      "loss_total": 0.0093994140625,
      "step": 209
    },
    {
      "epoch": 0.1721311475409836,
      "grad_norm": 0.07517191022634506,
      "learning_rate": 4.71448087431694e-05,
      "loss": 0.1065,
      "step": 210
    },
    {
      "epoch": 0.1721311475409836,
      "loss_control": 0.032684326171875,
      "loss_data": 0.49560546875,
      "loss_total": 0.131805419921875,
      "step": 210
    },
    {
      "epoch": 0.17295081967213113,
      "loss_control": 0.0567626953125,
      "loss_data": 0.943603515625,
      "loss_total": 0.2454833984375,
      "step": 211
    },
    {
      "epoch": 0.1737704918032787,
      "loss_control": 0.038116455078125,
      "loss_data": 0.0,
      "loss_total": 0.038116455078125,
      "step": 212
    },
    {
      "epoch": 0.17459016393442622,
      "loss_control": 0.010498046875,
      "loss_data": 0.483642578125,
      "loss_total": 0.10722656548023224,
      "step": 213
    },
    {
      "epoch": 0.17540983606557378,
      "loss_control": 0.01235198974609375,
      "loss_data": 0.49169921875,
      "loss_total": 0.11069183796644211,
      "step": 214
    },
    {
      "epoch": 0.1762295081967213,
      "grad_norm": 0.06431298702955246,
      "learning_rate": 4.707650273224044e-05,
      "loss": 0.1267,
      "step": 215
    },
    {
      "epoch": 0.1762295081967213,
      "loss_control": 0.0084991455078125,
      "loss_data": 0.44091796875,
      "loss_total": 0.09668274223804474,
      "step": 215
    },
    {
      "epoch": 0.17704918032786884,
      "loss_control": 0.035858154296875,
      "loss_data": 0.0,
      "loss_total": 0.035858154296875,
      "step": 216
    },
    {
      "epoch": 0.1778688524590164,
      "loss_control": 0.03192138671875,
      "loss_data": 0.479736328125,
      "loss_total": 0.12786865234375,
      "step": 217
    },
    {
      "epoch": 0.17868852459016393,
      "loss_control": 0.07159423828125,
      "loss_data": 0.468017578125,
      "loss_total": 0.16519775986671448,
      "step": 218
    },
    {
      "epoch": 0.17950819672131146,
      "loss_control": 0.006595611572265625,
      "loss_data": 0.447998046875,
      "loss_total": 0.09619522094726562,
      "step": 219
    },
    {
      "epoch": 0.18032786885245902,
      "grad_norm": 0.07016056030988693,
      "learning_rate": 4.7008196721311476e-05,
      "loss": 0.1044,
      "step": 220
    },
    {
      "epoch": 0.18032786885245902,
      "loss_control": 0.01427459716796875,
      "loss_data": 0.0,
      "loss_total": 0.01427459716796875,
      "step": 220
    },
    {
      "epoch": 0.18114754098360655,
      "loss_control": 0.006732940673828125,
      "loss_data": 0.0,
      "loss_total": 0.006732940673828125,
      "step": 221
    },
    {
      "epoch": 0.1819672131147541,
      "loss_control": 0.00940704345703125,
      "loss_data": 0.0,
      "loss_total": 0.00940704345703125,
      "step": 222
    },
    {
      "epoch": 0.18278688524590164,
      "loss_control": 0.01180267333984375,
      "loss_data": 0.49072265625,
      "loss_total": 0.10994720458984375,
      "step": 223
    },
    {
      "epoch": 0.18360655737704917,
      "loss_control": 0.006931304931640625,
      "loss_data": 0.0,
      "loss_total": 0.006931304931640625,
      "step": 224
    },
    {
      "epoch": 0.18442622950819673,
      "grad_norm": 0.07349319010972977,
      "learning_rate": 4.693989071038252e-05,
      "loss": 0.0295,
      "step": 225
    },
    {
      "epoch": 0.18442622950819673,
      "loss_control": 0.005748748779296875,
      "loss_data": 0.0,
      "loss_total": 0.005748748779296875,
      "step": 225
    },
    {
      "epoch": 0.18524590163934426,
      "loss_control": 0.0118560791015625,
      "loss_data": 0.958740234375,
      "loss_total": 0.20360413193702698,
      "step": 226
    },
    {
      "epoch": 0.1860655737704918,
      "loss_control": 0.005748748779296875,
      "loss_data": 0.495849609375,
      "loss_total": 0.10491867363452911,
      "step": 227
    },
    {
      "epoch": 0.18688524590163935,
      "loss_control": 0.004566192626953125,
      "loss_data": 0.0,
      "loss_total": 0.004566192626953125,
      "step": 228
    },
    {
      "epoch": 0.18770491803278688,
      "loss_control": 0.040008544921875,
      "loss_data": 0.0,
      "loss_total": 0.040008544921875,
      "step": 229
    },
    {
      "epoch": 0.1885245901639344,
      "grad_norm": 0.49334779381752014,
      "learning_rate": 4.687158469945355e-05,
      "loss": 0.0718,
      "step": 230
    },
    {
      "epoch": 0.1885245901639344,
      "loss_control": 0.01263427734375,
      "loss_data": 0.0,
      "loss_total": 0.01263427734375,
      "step": 230
    },
    {
      "epoch": 0.18934426229508197,
      "loss_control": 0.0022716522216796875,
      "loss_data": 0.963134765625,
      "loss_total": 0.1948986053466797,
      "step": 231
    },
    {
      "epoch": 0.1901639344262295,
      "loss_control": 0.005084991455078125,
      "loss_data": 0.498291015625,
      "loss_total": 0.10474319756031036,
      "step": 232
    },
    {
      "epoch": 0.19098360655737706,
      "loss_control": 0.01419830322265625,
      "loss_data": 0.0,
      "loss_total": 0.01419830322265625,
      "step": 233
    },
    {
      "epoch": 0.1918032786885246,
      "loss_control": 0.00971221923828125,
      "loss_data": 0.492919921875,
      "loss_total": 0.10829620808362961,
      "step": 234
    },
    {
      "epoch": 0.19262295081967212,
      "grad_norm": 0.07431850582361221,
      "learning_rate": 4.6803278688524595e-05,
      "loss": 0.087,
      "step": 235
    },
    {
      "epoch": 0.19262295081967212,
      "loss_control": 0.01392364501953125,
      "loss_data": 0.0,
      "loss_total": 0.01392364501953125,
      "step": 235
    },
    {
      "epoch": 0.19344262295081968,
      "loss_control": 0.0162200927734375,
      "loss_data": 0.0,
      "loss_total": 0.0162200927734375,
      "step": 236
    },
    {
      "epoch": 0.1942622950819672,
      "loss_control": 0.01294708251953125,
      "loss_data": 0.0,
      "loss_total": 0.01294708251953125,
      "step": 237
    },
    {
      "epoch": 0.19508196721311474,
      "loss_control": 0.0029449462890625,
      "loss_data": 0.499267578125,
      "loss_total": 0.1027984619140625,
      "step": 238
    },
    {
      "epoch": 0.1959016393442623,
      "loss_control": 0.00418853759765625,
      "loss_data": 0.497314453125,
      "loss_total": 0.10365142673254013,
      "step": 239
    },
    {
      "epoch": 0.19672131147540983,
      "grad_norm": 0.024374624714255333,
      "learning_rate": 4.673497267759563e-05,
      "loss": 0.0499,
      "step": 240
    },
    {
      "epoch": 0.19672131147540983,
      "loss_control": 0.03155517578125,
      "loss_data": 0.484619140625,
      "loss_total": 0.12847900390625,
      "step": 240
    },
    {
      "epoch": 0.19754098360655736,
      "loss_control": 0.0297088623046875,
      "loss_data": 0.0,
      "loss_total": 0.0297088623046875,
      "step": 241
    },
    {
      "epoch": 0.19836065573770492,
      "loss_control": 0.0031948089599609375,
      "loss_data": 0.498046875,
      "loss_total": 0.10280418395996094,
      "step": 242
    },
    {
      "epoch": 0.19918032786885245,
      "loss_control": 0.0018930435180664062,
      "loss_data": 0.0,
      "loss_total": 0.0018930435180664062,
      "step": 243
    },
    {
      "epoch": 0.2,
      "loss_control": 0.01177978515625,
      "loss_data": 0.44921875,
      "loss_total": 0.10162353515625,
      "step": 244
    },
    {
      "epoch": 0.20081967213114754,
      "grad_norm": 0.10686105489730835,
      "learning_rate": 4.666666666666667e-05,
      "loss": 0.0729,
      "step": 245
    },
    {
      "epoch": 0.20081967213114754,
      "loss_control": 0.00618743896484375,
      "loss_data": 0.0,
      "loss_total": 0.00618743896484375,
      "step": 245
    },
    {
      "epoch": 0.20163934426229507,
      "loss_control": 0.005115509033203125,
      "loss_data": 0.0,
      "loss_total": 0.005115509033203125,
      "step": 246
    },
    {
      "epoch": 0.20245901639344263,
      "loss_control": 0.0033779144287109375,
      "loss_data": 0.0,
      "loss_total": 0.0033779144287109375,
      "step": 247
    },
    {
      "epoch": 0.20327868852459016,
      "loss_control": 0.009613037109375,
      "loss_data": 0.0,
      "loss_total": 0.009613037109375,
      "step": 248
    },
    {
      "epoch": 0.2040983606557377,
      "loss_control": 0.00444793701171875,
      "loss_data": 0.0,
      "loss_total": 0.00444793701171875,
      "step": 249
    },
    {
      "epoch": 0.20491803278688525,
      "grad_norm": 0.03914537653326988,
      "learning_rate": 4.659836065573771e-05,
      "loss": 0.0057,
      "step": 250
    },
    {
      "epoch": 0.20491803278688525,
      "loss_control": 0.13427734375,
      "loss_data": 0.402587890625,
      "loss_total": 0.21479493379592896,
      "step": 250
    },
    {
      "epoch": 0.20573770491803278,
      "loss_control": 0.0182342529296875,
      "loss_data": 0.489013671875,
      "loss_total": 0.11603698879480362,
      "step": 251
    },
    {
      "epoch": 0.20655737704918034,
      "loss_control": 0.021881103515625,
      "loss_data": 0.472900390625,
      "loss_total": 0.11646118015050888,
      "step": 252
    },
    {
      "epoch": 0.20737704918032787,
      "loss_control": 0.029571533203125,
      "loss_data": 0.498046875,
      "loss_total": 0.129180908203125,
      "step": 253
    },
    {
      "epoch": 0.2081967213114754,
      "loss_control": 0.04266357421875,
      "loss_data": 0.486083984375,
      "loss_total": 0.13988037407398224,
      "step": 254
    },
    {
      "epoch": 0.20901639344262296,
      "grad_norm": 0.34425994753837585,
      "learning_rate": 4.653005464480875e-05,
      "loss": 0.1433,
      "step": 255
    },
    {
      "epoch": 0.20901639344262296,
      "loss_control": 0.00418853759765625,
      "loss_data": 0.0,
      "loss_total": 0.00418853759765625,
      "step": 255
    },
    {
      "epoch": 0.2098360655737705,
      "loss_control": 0.042877197265625,
      "loss_data": 0.0,
      "loss_total": 0.042877197265625,
      "step": 256
    },
    {
      "epoch": 0.21065573770491802,
      "loss_control": 0.11376953125,
      "loss_data": 0.46826171875,
      "loss_total": 0.20742186903953552,
      "step": 257
    },
    {
      "epoch": 0.21147540983606558,
      "loss_control": 0.00386810302734375,
      "loss_data": 0.497802734375,
      "loss_total": 0.10342865437269211,
      "step": 258
    },
    {
      "epoch": 0.2122950819672131,
      "loss_control": 0.00482940673828125,
      "loss_data": 0.0,
      "loss_total": 0.00482940673828125,
      "step": 259
    },
    {
      "epoch": 0.21311475409836064,
      "grad_norm": 0.04533088952302933,
      "learning_rate": 4.646174863387978e-05,
      "loss": 0.0725,
      "step": 260
    },
    {
      "epoch": 0.21311475409836064,
      "loss_control": 0.0055389404296875,
      "loss_data": 0.495849609375,
      "loss_total": 0.10470886528491974,
      "step": 260
    },
    {
      "epoch": 0.2139344262295082,
      "loss_control": 0.005809783935546875,
      "loss_data": 0.0,
      "loss_total": 0.005809783935546875,
      "step": 261
    },
    {
      "epoch": 0.21475409836065573,
      "loss_control": 0.0167388916015625,
      "loss_data": 0.0,
      "loss_total": 0.0167388916015625,
      "step": 262
    },
    {
      "epoch": 0.2155737704918033,
      "loss_control": 0.0306549072265625,
      "loss_data": 0.0,
      "loss_total": 0.0306549072265625,
      "step": 263
    },
    {
      "epoch": 0.21639344262295082,
      "loss_control": 0.019378662109375,
      "loss_data": 0.47265625,
      "loss_total": 0.11390991508960724,
      "step": 264
    },
    {
      "epoch": 0.21721311475409835,
      "grad_norm": 0.2701303958892822,
      "learning_rate": 4.6393442622950825e-05,
      "loss": 0.0544,
      "step": 265
    },
    {
      "epoch": 0.21721311475409835,
      "loss_control": 0.0013246536254882812,
      "loss_data": 0.0,
      "loss_total": 0.0013246536254882812,
      "step": 265
    },
    {
      "epoch": 0.2180327868852459,
      "loss_control": 0.006397247314453125,
      "loss_data": 0.495849609375,
      "loss_total": 0.10556717216968536,
      "step": 266
    },
    {
      "epoch": 0.21885245901639344,
      "loss_control": 0.01116943359375,
      "loss_data": 0.936767578125,
      "loss_total": 0.19852295517921448,
      "step": 267
    },
    {
      "epoch": 0.21967213114754097,
      "loss_control": 0.01007843017578125,
      "loss_data": 0.4990234375,
      "loss_total": 0.10988312214612961,
      "step": 268
    },
    {
      "epoch": 0.22049180327868853,
      "loss_control": 0.00258636474609375,
      "loss_data": 0.0,
      "loss_total": 0.00258636474609375,
      "step": 269
    },
    {
      "epoch": 0.22131147540983606,
      "grad_norm": 0.01349338423460722,
      "learning_rate": 4.632513661202186e-05,
      "loss": 0.0836,
      "step": 270
    },
    {
      "epoch": 0.22131147540983606,
      "loss_control": 0.00408172607421875,
      "loss_data": 0.49853515625,
      "loss_total": 0.10378875583410263,
      "step": 270
    },
    {
      "epoch": 0.22213114754098362,
      "loss_control": 0.006195068359375,
      "loss_data": 0.993896484375,
      "loss_total": 0.20497436821460724,
      "step": 271
    },
    {
      "epoch": 0.22295081967213115,
      "loss_control": 0.0097808837890625,
      "loss_data": 0.0,
      "loss_total": 0.0097808837890625,
      "step": 272
    },
    {
      "epoch": 0.22377049180327868,
      "loss_control": 0.004062652587890625,
      "loss_data": 0.0,
      "loss_total": 0.004062652587890625,
      "step": 273
    },
    {
      "epoch": 0.22459016393442624,
      "loss_control": 0.0077972412109375,
      "loss_data": 0.0,
      "loss_total": 0.0077972412109375,
      "step": 274
    },
    {
      "epoch": 0.22540983606557377,
      "grad_norm": 0.04903952032327652,
      "learning_rate": 4.62568306010929e-05,
      "loss": 0.0661,
      "step": 275
    },
    {
      "epoch": 0.22540983606557377,
      "loss_control": 0.006290435791015625,
      "loss_data": 0.961181640625,
      "loss_total": 0.1985267698764801,
      "step": 275
    },
    {
      "epoch": 0.2262295081967213,
      "loss_control": 0.00911712646484375,
      "loss_data": 0.0,
      "loss_total": 0.00911712646484375,
      "step": 276
    },
    {
      "epoch": 0.22704918032786886,
      "loss_control": 0.006816864013671875,
      "loss_data": 0.0,
      "loss_total": 0.006816864013671875,
      "step": 277
    },
    {
      "epoch": 0.2278688524590164,
      "loss_control": 0.0275115966796875,
      "loss_data": 0.485107421875,
      "loss_total": 0.12453307956457138,
      "step": 278
    },
    {
      "epoch": 0.22868852459016392,
      "loss_control": 0.0159454345703125,
      "loss_data": 0.488525390625,
      "loss_total": 0.11365051567554474,
      "step": 279
    },
    {
      "epoch": 0.22950819672131148,
      "grad_norm": 0.1959320604801178,
      "learning_rate": 4.618852459016394e-05,
      "loss": 0.0905,
      "step": 280
    },
    {
      "epoch": 0.22950819672131148,
      "loss_control": 0.0182037353515625,
      "loss_data": 0.46484375,
      "loss_total": 0.11117248982191086,
      "step": 280
    },
    {
      "epoch": 0.230327868852459,
      "loss_control": 0.0056610107421875,
      "loss_data": 0.0,
      "loss_total": 0.0056610107421875,
      "step": 281
    },
    {
      "epoch": 0.23114754098360657,
      "loss_control": 0.0031280517578125,
      "loss_data": 0.0,
      "loss_total": 0.0031280517578125,
      "step": 282
    },
    {
      "epoch": 0.2319672131147541,
      "loss_control": 0.0042877197265625,
      "loss_data": 0.47216796875,
      "loss_total": 0.09872131794691086,
      "step": 283
    },
    {
      "epoch": 0.23278688524590163,
      "loss_control": 0.005645751953125,
      "loss_data": 0.979736328125,
      "loss_total": 0.20159302651882172,
      "step": 284
    },
    {
      "epoch": 0.2336065573770492,
      "grad_norm": 0.09359154850244522,
      "learning_rate": 4.612021857923497e-05,
      "loss": 0.0841,
      "step": 285
    },
    {
      "epoch": 0.2336065573770492,
      "loss_control": 0.03125,
      "loss_data": 0.975830078125,
      "loss_total": 0.22641602158546448,
      "step": 285
    },
    {
      "epoch": 0.23442622950819672,
      "loss_control": 0.01128387451171875,
      "loss_data": 0.49853515625,
      "loss_total": 0.11099090427160263,
      "step": 286
    },
    {
      "epoch": 0.23524590163934425,
      "loss_control": 0.003971099853515625,
      "loss_data": 0.496826171875,
      "loss_total": 0.10333633422851562,
      "step": 287
    },
    {
      "epoch": 0.2360655737704918,
      "loss_control": 0.01165771484375,
      "loss_data": 0.0,
      "loss_total": 0.01165771484375,
      "step": 288
    },
    {
      "epoch": 0.23688524590163934,
      "loss_control": 0.0035762786865234375,
      "loss_data": 0.499755859375,
      "loss_total": 0.10352744907140732,
      "step": 289
    },
    {
      "epoch": 0.23770491803278687,
      "grad_norm": 0.06939060986042023,
      "learning_rate": 4.6051912568306014e-05,
      "loss": 0.1112,
      "step": 290
    },
    {
      "epoch": 0.23770491803278687,
      "loss_control": 0.0156402587890625,
      "loss_data": 0.46484375,
      "loss_total": 0.10860901325941086,
      "step": 290
    },
    {
      "epoch": 0.23852459016393443,
      "loss_control": 0.0197601318359375,
      "loss_data": 0.95849609375,
      "loss_total": 0.21145935356616974,
      "step": 291
    },
    {
      "epoch": 0.23934426229508196,
      "loss_control": 0.008941650390625,
      "loss_data": 0.49267578125,
      "loss_total": 0.10747680813074112,
      "step": 292
    },
    {
      "epoch": 0.24016393442622952,
      "loss_control": 0.0037059783935546875,
      "loss_data": 0.499267578125,
      "loss_total": 0.10355949401855469,
      "step": 293
    },
    {
      "epoch": 0.24098360655737705,
      "loss_control": 0.0016307830810546875,
      "loss_data": 0.0,
      "loss_total": 0.0016307830810546875,
      "step": 294
    },
    {
      "epoch": 0.24180327868852458,
      "grad_norm": 0.01666627638041973,
      "learning_rate": 4.598360655737705e-05,
      "loss": 0.1065,
      "step": 295
    },
    {
      "epoch": 0.24180327868852458,
      "loss_control": 0.0022029876708984375,
      "loss_data": 0.498291015625,
      "loss_total": 0.10186119377613068,
      "step": 295
    },
    {
      "epoch": 0.24262295081967214,
      "loss_control": 0.00390625,
      "loss_data": 0.484375,
      "loss_total": 0.10078125447034836,
      "step": 296
    },
    {
      "epoch": 0.24344262295081967,
      "loss_control": 0.0117340087890625,
      "loss_data": 0.487060546875,
      "loss_total": 0.1091461181640625,
      "step": 297
    },
    {
      "epoch": 0.2442622950819672,
      "loss_control": 0.0129547119140625,
      "loss_data": 0.489013671875,
      "loss_total": 0.11075744777917862,
      "step": 298
    },
    {
      "epoch": 0.24508196721311476,
      "loss_control": 0.0130157470703125,
      "loss_data": 0.0,
      "loss_total": 0.0130157470703125,
      "step": 299
    },
    {
      "epoch": 0.2459016393442623,
      "grad_norm": 0.24353647232055664,
      "learning_rate": 4.591530054644809e-05,
      "loss": 0.0871,
      "step": 300
    },
    {
      "epoch": 0.2459016393442623,
      "loss_control": 0.010101318359375,
      "loss_data": 0.0,
      "loss_total": 0.010101318359375,
      "step": 300
    },
    {
      "epoch": 0.24672131147540985,
      "loss_control": 0.010345458984375,
      "loss_data": 0.0,
      "loss_total": 0.010345458984375,
      "step": 301
    },
    {
      "epoch": 0.24754098360655738,
      "loss_control": 0.039520263671875,
      "loss_data": 0.483154296875,
      "loss_total": 0.13615113496780396,
      "step": 302
    },
    {
      "epoch": 0.2483606557377049,
      "loss_control": 0.0084075927734375,
      "loss_data": 0.499267578125,
      "loss_total": 0.1082611083984375,
      "step": 303
    },
    {
      "epoch": 0.24918032786885247,
      "loss_control": 0.0067138671875,
      "loss_data": 0.0,
      "loss_total": 0.0067138671875,
      "step": 304
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.04910408332943916,
      "learning_rate": 4.5846994535519125e-05,
      "loss": 0.0543,
      "step": 305
    },
    {
      "epoch": 0.25,
      "loss_control": 0.0026607513427734375,
      "loss_data": 0.0,
      "loss_total": 0.0026607513427734375,
      "step": 305
    },
    {
      "epoch": 0.25081967213114753,
      "loss_control": 0.0029296875,
      "loss_data": 0.49853515625,
      "loss_total": 0.10263671725988388,
      "step": 306
    },
    {
      "epoch": 0.25163934426229506,
      "loss_control": 0.0024929046630859375,
      "loss_data": 0.453857421875,
      "loss_total": 0.0932643935084343,
      "step": 307
    },
    {
      "epoch": 0.25245901639344265,
      "loss_control": 0.0097198486328125,
      "loss_data": 0.0,
      "loss_total": 0.0097198486328125,
      "step": 308
    },
    {
      "epoch": 0.2532786885245902,
      "loss_control": 0.033660888671875,
      "loss_data": 0.476806640625,
      "loss_total": 0.12902221083641052,
      "step": 309
    },
    {
      "epoch": 0.2540983606557377,
      "grad_norm": 0.3862488567829132,
      "learning_rate": 4.577868852459017e-05,
      "loss": 0.0675,
      "step": 310
    },
    {
      "epoch": 0.2540983606557377,
      "loss_control": 0.003520965576171875,
      "loss_data": 0.0,
      "loss_total": 0.003520965576171875,
      "step": 310
    },
    {
      "epoch": 0.25491803278688524,
      "loss_control": 0.00505828857421875,
      "loss_data": 0.0,
      "loss_total": 0.00505828857421875,
      "step": 311
    },
    {
      "epoch": 0.25573770491803277,
      "loss_control": 0.019073486328125,
      "loss_data": 0.0,
      "loss_total": 0.019073486328125,
      "step": 312
    },
    {
      "epoch": 0.2565573770491803,
      "loss_control": 0.0034923553466796875,
      "loss_data": 0.0,
      "loss_total": 0.0034923553466796875,
      "step": 313
    },
    {
      "epoch": 0.2573770491803279,
      "loss_control": 0.00380706787109375,
      "loss_data": 0.4970703125,
      "loss_total": 0.10322113335132599,
      "step": 314
    },
    {
      "epoch": 0.2581967213114754,
      "grad_norm": 0.01975744217634201,
      "learning_rate": 4.57103825136612e-05,
      "loss": 0.0269,
      "step": 315
    },
    {
      "epoch": 0.2581967213114754,
      "loss_control": 0.004947662353515625,
      "loss_data": 0.499267578125,
      "loss_total": 0.10480117797851562,
      "step": 315
    },
    {
      "epoch": 0.25901639344262295,
      "loss_control": 0.0021915435791015625,
      "loss_data": 0.4990234375,
      "loss_total": 0.10199623554944992,
      "step": 316
    },
    {
      "epoch": 0.2598360655737705,
      "loss_control": 0.026763916015625,
      "loss_data": 0.956298828125,
      "loss_total": 0.21802368760108948,
      "step": 317
    },
    {
      "epoch": 0.260655737704918,
      "loss_control": 0.0293731689453125,
      "loss_data": 0.49951171875,
      "loss_total": 0.12927551567554474,
      "step": 318
    },
    {
      "epoch": 0.2614754098360656,
      "loss_control": 0.006755828857421875,
      "loss_data": 0.4482421875,
      "loss_total": 0.09640426933765411,
      "step": 319
    },
    {
      "epoch": 0.26229508196721313,
      "grad_norm": 0.07227453589439392,
      "learning_rate": 4.5642076502732244e-05,
      "loss": 0.1301,
      "step": 320
    },
    {
      "epoch": 0.26229508196721313,
      "loss_control": 0.002933502197265625,
      "loss_data": 0.9970703125,
      "loss_total": 0.2023475617170334,
      "step": 320
    },
    {
      "epoch": 0.26311475409836066,
      "loss_control": 0.00489044189453125,
      "loss_data": 0.480712890625,
      "loss_total": 0.10103302448987961,
      "step": 321
    },
    {
      "epoch": 0.2639344262295082,
      "loss_control": 0.0033779144287109375,
      "loss_data": 0.0,
      "loss_total": 0.0033779144287109375,
      "step": 322
    },
    {
      "epoch": 0.2647540983606557,
      "loss_control": 0.00885009765625,
      "loss_data": 0.965576171875,
      "loss_total": 0.20196533203125,
      "step": 323
    },
    {
      "epoch": 0.26557377049180325,
      "loss_control": 0.003978729248046875,
      "loss_data": 0.497314453125,
      "loss_total": 0.10344161838293076,
      "step": 324
    },
    {
      "epoch": 0.26639344262295084,
      "grad_norm": 0.05163513496518135,
      "learning_rate": 4.557377049180328e-05,
      "loss": 0.1224,
      "step": 325
    },
    {
      "epoch": 0.26639344262295084,
      "loss_control": 0.0143585205078125,
      "loss_data": 0.0,
      "loss_total": 0.0143585205078125,
      "step": 325
    },
    {
      "epoch": 0.26721311475409837,
      "loss_control": 0.002918243408203125,
      "loss_data": 0.44970703125,
      "loss_total": 0.092859648168087,
      "step": 326
    },
    {
      "epoch": 0.2680327868852459,
      "loss_control": 0.007427215576171875,
      "loss_data": 0.497314453125,
      "loss_total": 0.10689010471105576,
      "step": 327
    },
    {
      "epoch": 0.26885245901639343,
      "loss_control": 0.0140380859375,
      "loss_data": 0.0,
      "loss_total": 0.0140380859375,
      "step": 328
    },
    {
      "epoch": 0.26967213114754096,
      "loss_control": 0.01158905029296875,
      "loss_data": 0.491455078125,
      "loss_total": 0.10988006740808487,
      "step": 329
    },
    {
      "epoch": 0.27049180327868855,
      "grad_norm": 0.12488766014575958,
      "learning_rate": 4.550546448087432e-05,
      "loss": 0.0676,
      "step": 330
    },
    {
      "epoch": 0.27049180327868855,
      "loss_control": 0.012542724609375,
      "loss_data": 0.49169921875,
      "loss_total": 0.11088257282972336,
      "step": 330
    },
    {
      "epoch": 0.2713114754098361,
      "loss_control": 0.002376556396484375,
      "loss_data": 0.99755859375,
      "loss_total": 0.2018882781267166,
      "step": 331
    },
    {
      "epoch": 0.2721311475409836,
      "loss_control": 0.01221466064453125,
      "loss_data": 0.0,
      "loss_total": 0.01221466064453125,
      "step": 332
    },
    {
      "epoch": 0.27295081967213114,
      "loss_control": 0.0027103424072265625,
      "loss_data": 0.0,
      "loss_total": 0.0027103424072265625,
      "step": 333
    },
    {
      "epoch": 0.27377049180327867,
      "loss_control": 0.00319671630859375,
      "loss_data": 0.0,
      "loss_total": 0.00319671630859375,
      "step": 334
    },
    {
      "epoch": 0.27459016393442626,
      "grad_norm": 0.03579002246260643,
      "learning_rate": 4.5437158469945356e-05,
      "loss": 0.0662,
      "step": 335
    },
    {
      "epoch": 0.27459016393442626,
      "loss_control": 0.004604339599609375,
      "loss_data": 0.476806640625,
      "loss_total": 0.0999656692147255,
      "step": 335
    },
    {
      "epoch": 0.2754098360655738,
      "loss_control": 0.0030117034912109375,
      "loss_data": 0.0,
      "loss_total": 0.0030117034912109375,
      "step": 336
    },
    {
      "epoch": 0.2762295081967213,
      "loss_control": 0.003955841064453125,
      "loss_data": 0.48779296875,
      "loss_total": 0.10151443630456924,
      "step": 337
    },
    {
      "epoch": 0.27704918032786885,
      "loss_control": 0.01161956787109375,
      "loss_data": 0.947265625,
      "loss_total": 0.20107269287109375,
      "step": 338
    },
    {
      "epoch": 0.2778688524590164,
      "loss_control": 0.0015745162963867188,
      "loss_data": 0.49853515625,
      "loss_total": 0.1012815460562706,
      "step": 339
    },
    {
      "epoch": 0.2786885245901639,
      "grad_norm": 0.010328663513064384,
      "learning_rate": 4.53688524590164e-05,
      "loss": 0.1014,
      "step": 340
    },
    {
      "epoch": 0.2786885245901639,
      "loss_control": 0.00621795654296875,
      "loss_data": 0.466064453125,
      "loss_total": 0.09943085163831711,
      "step": 340
    },
    {
      "epoch": 0.2795081967213115,
      "loss_control": 0.00914764404296875,
      "loss_data": 0.4990234375,
      "loss_total": 0.10895233601331711,
      "step": 341
    },
    {
      "epoch": 0.28032786885245903,
      "loss_control": 0.0009479522705078125,
      "loss_data": 0.0,
      "loss_total": 0.0009479522705078125,
      "step": 342
    },
    {
      "epoch": 0.28114754098360656,
      "loss_control": 0.01093292236328125,
      "loss_data": 0.9501953125,
      "loss_total": 0.20097199082374573,
      "step": 343
    },
    {
      "epoch": 0.2819672131147541,
      "loss_control": 0.004093170166015625,
      "loss_data": 0.0,
      "loss_total": 0.004093170166015625,
      "step": 344
    },
    {
      "epoch": 0.2827868852459016,
      "grad_norm": 0.028511913493275642,
      "learning_rate": 4.530054644808743e-05,
      "loss": 0.0829,
      "step": 345
    },
    {
      "epoch": 0.2827868852459016,
      "loss_control": 0.1435546875,
      "loss_data": 0.495849609375,
      "loss_total": 0.24272461235523224,
      "step": 345
    },
    {
      "epoch": 0.2836065573770492,
      "loss_control": 0.053558349609375,
      "loss_data": 0.468017578125,
      "loss_total": 0.14716187119483948,
      "step": 346
    },
    {
      "epoch": 0.28442622950819674,
      "loss_control": 0.017242431640625,
      "loss_data": 0.956298828125,
      "loss_total": 0.20850220322608948,
      "step": 347
    },
    {
      "epoch": 0.28524590163934427,
      "loss_control": 0.0273895263671875,
      "loss_data": 0.46240234375,
      "loss_total": 0.11986999958753586,
      "step": 348
    },
    {
      "epoch": 0.2860655737704918,
      "loss_control": 0.0169525146484375,
      "loss_data": 0.9853515625,
      "loss_total": 0.21402283012866974,
      "step": 349
    },
    {
      "epoch": 0.28688524590163933,
      "grad_norm": 0.19325178861618042,
      "learning_rate": 4.5232240437158474e-05,
      "loss": 0.1865,
      "step": 350
    },
    {
      "epoch": 0.28688524590163933,
      "loss_control": 0.01202392578125,
      "loss_data": 0.40234375,
      "loss_total": 0.09249267727136612,
      "step": 350
    },
    {
      "epoch": 0.28770491803278686,
      "loss_control": 0.01105499267578125,
      "loss_data": 0.960693359375,
      "loss_total": 0.20319366455078125,
      "step": 351
    },
    {
      "epoch": 0.28852459016393445,
      "loss_control": 0.00353240966796875,
      "loss_data": 0.498779296875,
      "loss_total": 0.10328827053308487,
      "step": 352
    },
    {
      "epoch": 0.289344262295082,
      "loss_control": 0.005252838134765625,
      "loss_data": 0.0,
      "loss_total": 0.005252838134765625,
      "step": 353
    },
    {
      "epoch": 0.2901639344262295,
      "loss_control": 0.0175933837890625,
      "loss_data": 0.96240234375,
      "loss_total": 0.21007385849952698,
      "step": 354
    },
    {
      "epoch": 0.29098360655737704,
      "grad_norm": 0.16661909222602844,
      "learning_rate": 4.516393442622951e-05,
      "loss": 0.1229,
      "step": 355
    },
    {
      "epoch": 0.29098360655737704,
      "loss_control": 0.005962371826171875,
      "loss_data": 0.40625,
      "loss_total": 0.08721237629652023,
      "step": 355
    },
    {
      "epoch": 0.29180327868852457,
      "loss_control": 0.0099945068359375,
      "loss_data": 0.4931640625,
      "loss_total": 0.1086273193359375,
      "step": 356
    },
    {
      "epoch": 0.29262295081967216,
      "loss_control": 0.0205535888671875,
      "loss_data": 0.451416015625,
      "loss_total": 0.11083679646253586,
      "step": 357
    },
    {
      "epoch": 0.2934426229508197,
      "loss_control": 0.0097198486328125,
      "loss_data": 0.4990234375,
      "loss_total": 0.10952454060316086,
      "step": 358
    },
    {
      "epoch": 0.2942622950819672,
      "loss_control": 0.008697509765625,
      "loss_data": 0.0,
      "loss_total": 0.008697509765625,
      "step": 359
    },
    {
      "epoch": 0.29508196721311475,
      "grad_norm": 0.14955082535743713,
      "learning_rate": 4.509562841530055e-05,
      "loss": 0.085,
      "step": 360
    },
    {
      "epoch": 0.29508196721311475,
      "loss_control": 0.00426483154296875,
      "loss_data": 0.0,
      "loss_total": 0.00426483154296875,
      "step": 360
    },
    {
      "epoch": 0.2959016393442623,
      "loss_control": 0.032562255859375,
      "loss_data": 0.0,
      "loss_total": 0.032562255859375,
      "step": 361
    },
    {
      "epoch": 0.2967213114754098,
      "loss_control": 0.002349853515625,
      "loss_data": 0.4990234375,
      "loss_total": 0.10215454548597336,
      "step": 362
    },
    {
      "epoch": 0.2975409836065574,
      "loss_control": 0.0014858245849609375,
      "loss_data": 0.0,
      "loss_total": 0.0014858245849609375,
      "step": 363
    },
    {
      "epoch": 0.2983606557377049,
      "loss_control": 0.00893402099609375,
      "loss_data": 0.4951171875,
      "loss_total": 0.10795745998620987,
      "step": 364
    },
    {
      "epoch": 0.29918032786885246,
      "grad_norm": 0.06783626973628998,
      "learning_rate": 4.5027322404371586e-05,
      "loss": 0.0497,
      "step": 365
    },
    {
      "epoch": 0.29918032786885246,
      "loss_control": 0.0084991455078125,
      "loss_data": 0.99169921875,
      "loss_total": 0.20683899521827698,
      "step": 365
    },
    {
      "epoch": 0.3,
      "loss_control": 0.003692626953125,
      "loss_data": 0.497802734375,
      "loss_total": 0.10325317829847336,
      "step": 366
    },
    {
      "epoch": 0.3008196721311475,
      "loss_control": 0.01611328125,
      "loss_data": 0.937744140625,
      "loss_total": 0.20366211235523224,
      "step": 367
    },
    {
      "epoch": 0.3016393442622951,
      "loss_control": 0.005352020263671875,
      "loss_data": 0.49609375,
      "loss_total": 0.10457076877355576,
      "step": 368
    },
    {
      "epoch": 0.30245901639344264,
      "loss_control": 0.00399017333984375,
      "loss_data": 0.486328125,
      "loss_total": 0.10125579684972763,
      "step": 369
    },
    {
      "epoch": 0.30327868852459017,
      "grad_norm": 0.08219191431999207,
      "learning_rate": 4.495901639344263e-05,
      "loss": 0.1439,
      "step": 370
    },
    {
      "epoch": 0.30327868852459017,
      "loss_control": 0.006160736083984375,
      "loss_data": 0.495361328125,
      "loss_total": 0.10523300617933273,
      "step": 370
    },
    {
      "epoch": 0.3040983606557377,
      "loss_control": 0.0038585662841796875,
      "loss_data": 0.496826171875,
      "loss_total": 0.10322380065917969,
      "step": 371
    },
    {
      "epoch": 0.30491803278688523,
      "loss_control": 0.003261566162109375,
      "loss_data": 0.0,
      "loss_total": 0.003261566162109375,
      "step": 372
    },
    {
      "epoch": 0.30573770491803276,
      "loss_control": 0.003936767578125,
      "loss_data": 0.971923828125,
      "loss_total": 0.19832153618335724,
      "step": 373
    },
    {
      "epoch": 0.30655737704918035,
      "loss_control": 0.00347137451171875,
      "loss_data": 0.49755859375,
      "loss_total": 0.10298309475183487,
      "step": 374
    },
    {
      "epoch": 0.3073770491803279,
      "grad_norm": 0.06210433319211006,
      "learning_rate": 4.489071038251366e-05,
      "loss": 0.1026,
      "step": 375
    },
    {
      "epoch": 0.3073770491803279,
      "loss_control": 0.0014352798461914062,
      "loss_data": 0.499267578125,
      "loss_total": 0.1012887954711914,
      "step": 375
    },
    {
      "epoch": 0.3081967213114754,
      "loss_control": 0.00170135498046875,
      "loss_data": 0.454345703125,
      "loss_total": 0.09257049858570099,
      "step": 376
    },
    {
      "epoch": 0.30901639344262294,
      "loss_control": 0.005626678466796875,
      "loss_data": 0.0,
      "loss_total": 0.005626678466796875,
      "step": 377
    },
    {
      "epoch": 0.30983606557377047,
      "loss_control": 0.0024929046630859375,
      "loss_data": 0.453369140625,
      "loss_total": 0.09316673129796982,
      "step": 378
    },
    {
      "epoch": 0.31065573770491806,
      "loss_control": 0.01499176025390625,
      "loss_data": 0.0,
      "loss_total": 0.01499176025390625,
      "step": 379
    },
    {
      "epoch": 0.3114754098360656,
      "grad_norm": 0.10566743463277817,
      "learning_rate": 4.4822404371584705e-05,
      "loss": 0.0615,
      "step": 380
    },
    {
      "epoch": 0.3114754098360656,
      "loss_control": 0.0039215087890625,
      "loss_data": 0.446044921875,
      "loss_total": 0.09313049167394638,
      "step": 380
    },
    {
      "epoch": 0.3122950819672131,
      "loss_control": 0.0026302337646484375,
      "loss_data": 0.0,
      "loss_total": 0.0026302337646484375,
      "step": 381
    },
    {
      "epoch": 0.31311475409836065,
      "loss_control": 0.0016498565673828125,
      "loss_data": 0.49951171875,
      "loss_total": 0.10155220329761505,
      "step": 382
    },
    {
      "epoch": 0.3139344262295082,
      "loss_control": 0.007228851318359375,
      "loss_data": 0.496826171875,
      "loss_total": 0.10659408569335938,
      "step": 383
    },
    {
      "epoch": 0.31475409836065577,
      "loss_control": 0.03082275390625,
      "loss_data": 0.45068359375,
      "loss_total": 0.12095947563648224,
      "step": 384
    },
    {
      "epoch": 0.3155737704918033,
      "grad_norm": 0.29165446758270264,
      "learning_rate": 4.475409836065574e-05,
      "loss": 0.085,
      "step": 385
    },
    {
      "epoch": 0.3155737704918033,
      "loss_control": 0.011932373046875,
      "loss_data": 0.0,
      "loss_total": 0.011932373046875,
      "step": 385
    },
    {
      "epoch": 0.3163934426229508,
      "loss_control": 0.004116058349609375,
      "loss_data": 0.9609375,
      "loss_total": 0.1963035613298416,
      "step": 386
    },
    {
      "epoch": 0.31721311475409836,
      "loss_control": 0.0107269287109375,
      "loss_data": 0.498291015625,
      "loss_total": 0.11038513481616974,
      "step": 387
    },
    {
      "epoch": 0.3180327868852459,
      "loss_control": 0.0018587112426757812,
      "loss_data": 0.451416015625,
      "loss_total": 0.09214191883802414,
      "step": 388
    },
    {
      "epoch": 0.3188524590163934,
      "loss_control": 0.010406494140625,
      "loss_data": 0.960205078125,
      "loss_total": 0.20244751870632172,
      "step": 389
    },
    {
      "epoch": 0.319672131147541,
      "grad_norm": 0.12517473101615906,
      "learning_rate": 4.468579234972678e-05,
      "loss": 0.1226,
      "step": 390
    },
    {
      "epoch": 0.319672131147541,
      "loss_control": 0.0114288330078125,
      "loss_data": 0.0,
      "loss_total": 0.0114288330078125,
      "step": 390
    },
    {
      "epoch": 0.32049180327868854,
      "loss_control": 0.0017347335815429688,
      "loss_data": 0.0,
      "loss_total": 0.0017347335815429688,
      "step": 391
    },
    {
      "epoch": 0.32131147540983607,
      "loss_control": 0.02362060546875,
      "loss_data": 0.0,
      "loss_total": 0.02362060546875,
      "step": 392
    },
    {
      "epoch": 0.3221311475409836,
      "loss_control": 0.0014629364013671875,
      "loss_data": 0.4990234375,
      "loss_total": 0.10126762837171555,
      "step": 393
    },
    {
      "epoch": 0.32295081967213113,
      "loss_control": 0.0025501251220703125,
      "loss_data": 0.0,
      "loss_total": 0.0025501251220703125,
      "step": 394
    },
    {
      "epoch": 0.3237704918032787,
      "grad_norm": 0.025372589007019997,
      "learning_rate": 4.4617486338797816e-05,
      "loss": 0.0281,
      "step": 395
    },
    {
      "epoch": 0.3237704918032787,
      "loss_control": 0.004535675048828125,
      "loss_data": 0.0,
      "loss_total": 0.004535675048828125,
      "step": 395
    },
    {
      "epoch": 0.32459016393442625,
      "loss_control": 0.004825592041015625,
      "loss_data": 0.47021484375,
      "loss_total": 0.09886856377124786,
      "step": 396
    },
    {
      "epoch": 0.3254098360655738,
      "loss_control": 0.0038623809814453125,
      "loss_data": 0.0,
      "loss_total": 0.0038623809814453125,
      "step": 397
    },
    {
      "epoch": 0.3262295081967213,
      "loss_control": 0.0082855224609375,
      "loss_data": 0.0,
      "loss_total": 0.0082855224609375,
      "step": 398
    },
    {
      "epoch": 0.32704918032786884,
      "loss_control": 0.005382537841796875,
      "loss_data": 0.0,
      "loss_total": 0.005382537841796875,
      "step": 399
    },
    {
      "epoch": 0.32786885245901637,
      "grad_norm": 0.04866417124867439,
      "learning_rate": 4.454918032786886e-05,
      "loss": 0.0242,
      "step": 400
    },
    {
      "epoch": 0.32786885245901637,
      "loss_control": 0.0007071495056152344,
      "loss_data": 0.49951171875,
      "loss_total": 0.10060949623584747,
      "step": 400
    },
    {
      "epoch": 0.32868852459016396,
      "loss_control": 0.0194549560546875,
      "loss_data": 0.4990234375,
      "loss_total": 0.11925964802503586,
      "step": 401
    },
    {
      "epoch": 0.3295081967213115,
      "loss_control": 0.0043182373046875,
      "loss_data": 0.0,
      "loss_total": 0.0043182373046875,
      "step": 402
    },
    {
      "epoch": 0.330327868852459,
      "loss_control": 0.00894927978515625,
      "loss_data": 0.966552734375,
      "loss_total": 0.202259823679924,
      "step": 403
    },
    {
      "epoch": 0.33114754098360655,
      "loss_control": 0.0224151611328125,
      "loss_data": 0.49462890625,
      "loss_total": 0.12134094536304474,
      "step": 404
    },
    {
      "epoch": 0.3319672131147541,
      "grad_norm": 0.20806799829006195,
      "learning_rate": 4.448087431693989e-05,
      "loss": 0.1096,
      "step": 405
    },
    {
      "epoch": 0.3319672131147541,
      "loss_control": 0.0042724609375,
      "loss_data": 0.478759765625,
      "loss_total": 0.10002441704273224,
      "step": 405
    },
    {
      "epoch": 0.33278688524590166,
      "loss_control": 0.03411865234375,
      "loss_data": 0.493408203125,
      "loss_total": 0.13280029594898224,
      "step": 406
    },
    {
      "epoch": 0.3336065573770492,
      "loss_control": 0.018585205078125,
      "loss_data": 0.49072265625,
      "loss_total": 0.116729736328125,
      "step": 407
    },
    {
      "epoch": 0.3344262295081967,
      "loss_control": 0.001232147216796875,
      "loss_data": 0.452392578125,
      "loss_total": 0.091710664331913,
      "step": 408
    },
    {
      "epoch": 0.33524590163934426,
      "loss_control": 0.0029621124267578125,
      "loss_data": 0.476806640625,
      "loss_total": 0.09832344204187393,
      "step": 409
    },
    {
      "epoch": 0.3360655737704918,
      "grad_norm": 0.05283613130450249,
      "learning_rate": 4.4412568306010935e-05,
      "loss": 0.1079,
      "step": 410
    },
    {
      "epoch": 0.3360655737704918,
      "loss_control": 0.0027370452880859375,
      "loss_data": 0.49853515625,
      "loss_total": 0.10244407504796982,
      "step": 410
    },
    {
      "epoch": 0.3368852459016393,
      "loss_control": 0.004863739013671875,
      "loss_data": 0.49658203125,
      "loss_total": 0.10418014973402023,
      "step": 411
    },
    {
      "epoch": 0.3377049180327869,
      "loss_control": 0.0235443115234375,
      "loss_data": 0.0,
      "loss_total": 0.0235443115234375,
      "step": 412
    },
    {
      "epoch": 0.33852459016393444,
      "loss_control": 0.00516510009765625,
      "loss_data": 0.0,
      "loss_total": 0.00516510009765625,
      "step": 413
    },
    {
      "epoch": 0.33934426229508197,
      "loss_control": 0.0037403106689453125,
      "loss_data": 0.0,
      "loss_total": 0.0037403106689453125,
      "step": 414
    },
    {
      "epoch": 0.3401639344262295,
      "grad_norm": 0.04710855334997177,
      "learning_rate": 4.434426229508197e-05,
      "loss": 0.0478,
      "step": 415
    },
    {
      "epoch": 0.3401639344262295,
      "loss_control": 0.02301025390625,
      "loss_data": 0.93212890625,
      "loss_total": 0.20943604409694672,
      "step": 415
    },
    {
      "epoch": 0.34098360655737703,
      "loss_control": 0.00782012939453125,
      "loss_data": 0.4931640625,
      "loss_total": 0.10645294189453125,
      "step": 416
    },
    {
      "epoch": 0.3418032786885246,
      "loss_control": 0.0205535888671875,
      "loss_data": 0.919189453125,
      "loss_total": 0.2043914794921875,
      "step": 417
    },
    {
      "epoch": 0.34262295081967215,
      "loss_control": 0.00218963623046875,
      "loss_data": 0.499267578125,
      "loss_total": 0.10204315185546875,
      "step": 418
    },
    {
      "epoch": 0.3434426229508197,
      "loss_control": 0.0012645721435546875,
      "loss_data": 0.0,
      "loss_total": 0.0012645721435546875,
      "step": 419
    },
    {
      "epoch": 0.3442622950819672,
      "grad_norm": 0.00859719980508089,
      "learning_rate": 4.427595628415301e-05,
      "loss": 0.1247,
      "step": 420
    },
    {
      "epoch": 0.3442622950819672,
      "loss_control": 0.00463104248046875,
      "loss_data": 0.495849609375,
      "loss_total": 0.10380096733570099,
      "step": 420
    },
    {
      "epoch": 0.34508196721311474,
      "loss_control": 0.024658203125,
      "loss_data": 0.46044921875,
      "loss_total": 0.11674804985523224,
      "step": 421
    },
    {
      "epoch": 0.34590163934426227,
      "loss_control": 0.01165771484375,
      "loss_data": 0.0,
      "loss_total": 0.01165771484375,
      "step": 422
    },
    {
      "epoch": 0.34672131147540985,
      "loss_control": 0.003688812255859375,
      "loss_data": 0.4658203125,
      "loss_total": 0.0968528762459755,
      "step": 423
    },
    {
      "epoch": 0.3475409836065574,
      "loss_control": 0.0162506103515625,
      "loss_data": 0.48828125,
      "loss_total": 0.1139068603515625,
      "step": 424
    },
    {
      "epoch": 0.3483606557377049,
      "grad_norm": 0.1284453421831131,
      "learning_rate": 4.420765027322405e-05,
      "loss": 0.0886,
      "step": 425
    },
    {
      "epoch": 0.3483606557377049,
      "loss_control": 0.0066070556640625,
      "loss_data": 0.0,
      "loss_total": 0.0066070556640625,
      "step": 425
    },
    {
      "epoch": 0.34918032786885245,
      "loss_control": 0.004100799560546875,
      "loss_data": 0.0,
      "loss_total": 0.004100799560546875,
      "step": 426
    },
    {
      "epoch": 0.35,
      "loss_control": 0.002300262451171875,
      "loss_data": 0.0,
      "loss_total": 0.002300262451171875,
      "step": 427
    },
    {
      "epoch": 0.35081967213114756,
      "loss_control": 0.03802490234375,
      "loss_data": 0.0,
      "loss_total": 0.03802490234375,
      "step": 428
    },
    {
      "epoch": 0.3516393442622951,
      "loss_control": 0.0020236968994140625,
      "loss_data": 0.0,
      "loss_total": 0.0020236968994140625,
      "step": 429
    },
    {
      "epoch": 0.3524590163934426,
      "grad_norm": 0.013253830373287201,
      "learning_rate": 4.413934426229508e-05,
      "loss": 0.0106,
      "step": 430
    },
    {
      "epoch": 0.3524590163934426,
      "loss_control": 0.057708740234375,
      "loss_data": 0.484619140625,
      "loss_total": 0.154632568359375,
      "step": 430
    },
    {
      "epoch": 0.35327868852459016,
      "loss_control": 0.002864837646484375,
      "loss_data": 0.952880859375,
      "loss_total": 0.1934410184621811,
      "step": 431
    },
    {
      "epoch": 0.3540983606557377,
      "loss_control": 0.0112152099609375,
      "loss_data": 0.473876953125,
      "loss_total": 0.10599060356616974,
      "step": 432
    },
    {
      "epoch": 0.3549180327868853,
      "loss_control": 0.0035762786865234375,
      "loss_data": 0.0,
      "loss_total": 0.0035762786865234375,
      "step": 433
    },
    {
      "epoch": 0.3557377049180328,
      "loss_control": 0.0064849853515625,
      "loss_data": 0.472412109375,
      "loss_total": 0.1009674072265625,
      "step": 434
    },
    {
      "epoch": 0.35655737704918034,
      "grad_norm": 0.08723180741071701,
      "learning_rate": 4.4071038251366124e-05,
      "loss": 0.1117,
      "step": 435
    },
    {
      "epoch": 0.35655737704918034,
      "loss_control": 0.0038967132568359375,
      "loss_data": 0.0,
      "loss_total": 0.0038967132568359375,
      "step": 435
    },
    {
      "epoch": 0.35737704918032787,
      "loss_control": 0.0304107666015625,
      "loss_data": 0.96875,
      "loss_total": 0.22416077554225922,
      "step": 436
    },
    {
      "epoch": 0.3581967213114754,
      "loss_control": 0.01148223876953125,
      "loss_data": 0.474853515625,
      "loss_total": 0.10645294189453125,
      "step": 437
    },
    {
      "epoch": 0.3590163934426229,
      "loss_control": 0.00247955322265625,
      "loss_data": 0.466552734375,
      "loss_total": 0.09579010307788849,
      "step": 438
    },
    {
      "epoch": 0.3598360655737705,
      "loss_control": 0.00611114501953125,
      "loss_data": 0.0,
      "loss_total": 0.00611114501953125,
      "step": 439
    },
    {
      "epoch": 0.36065573770491804,
      "grad_norm": 0.07893354445695877,
      "learning_rate": 4.400273224043716e-05,
      "loss": 0.0873,
      "step": 440
    },
    {
      "epoch": 0.36065573770491804,
      "loss_control": 0.0030002593994140625,
      "loss_data": 0.0,
      "loss_total": 0.0030002593994140625,
      "step": 440
    },
    {
      "epoch": 0.3614754098360656,
      "loss_control": 0.0036411285400390625,
      "loss_data": 0.0,
      "loss_total": 0.0036411285400390625,
      "step": 441
    },
    {
      "epoch": 0.3622950819672131,
      "loss_control": 0.0169677734375,
      "loss_data": 0.0,
      "loss_total": 0.0169677734375,
      "step": 442
    },
    {
      "epoch": 0.36311475409836064,
      "loss_control": 0.00473785400390625,
      "loss_data": 0.9462890625,
      "loss_total": 0.1939956694841385,
      "step": 443
    },
    {
      "epoch": 0.3639344262295082,
      "loss_control": 0.0015363693237304688,
      "loss_data": 0.0,
      "loss_total": 0.0015363693237304688,
      "step": 444
    },
    {
      "epoch": 0.36475409836065575,
      "grad_norm": 0.01210828311741352,
      "learning_rate": 4.3934426229508194e-05,
      "loss": 0.0438,
      "step": 445
    },
    {
      "epoch": 0.36475409836065575,
      "loss_control": 0.018524169921875,
      "loss_data": 0.486572265625,
      "loss_total": 0.11583862453699112,
      "step": 445
    },
    {
      "epoch": 0.3655737704918033,
      "loss_control": 0.0026569366455078125,
      "loss_data": 0.498046875,
      "loss_total": 0.10226631164550781,
      "step": 446
    },
    {
      "epoch": 0.3663934426229508,
      "loss_control": 0.015289306640625,
      "loss_data": 0.46240234375,
      "loss_total": 0.10776977986097336,
      "step": 447
    },
    {
      "epoch": 0.36721311475409835,
      "loss_control": 0.005222320556640625,
      "loss_data": 0.0,
      "loss_total": 0.005222320556640625,
      "step": 448
    },
    {
      "epoch": 0.3680327868852459,
      "loss_control": 0.004917144775390625,
      "loss_data": 0.472900390625,
      "loss_total": 0.0994972214102745,
      "step": 449
    },
    {
      "epoch": 0.36885245901639346,
      "grad_norm": 0.06611592322587967,
      "learning_rate": 4.3866120218579235e-05,
      "loss": 0.0861,
      "step": 450
    },
    {
      "epoch": 0.36885245901639346,
      "loss_control": 0.0232391357421875,
      "loss_data": 0.485595703125,
      "loss_total": 0.12035828083753586,
      "step": 450
    },
    {
      "epoch": 0.369672131147541,
      "loss_control": 0.0011444091796875,
      "loss_data": 0.9990234375,
      "loss_total": 0.20094910264015198,
      "step": 451
    },
    {
      "epoch": 0.3704918032786885,
      "loss_control": 0.0014982223510742188,
      "loss_data": 0.0,
      "loss_total": 0.0014982223510742188,
      "step": 452
    },
    {
      "epoch": 0.37131147540983606,
      "loss_control": 0.0028400421142578125,
      "loss_data": 0.0,
      "loss_total": 0.0028400421142578125,
      "step": 453
    },
    {
      "epoch": 0.3721311475409836,
      "loss_control": 0.0023479461669921875,
      "loss_data": 0.0,
      "loss_total": 0.0023479461669921875,
      "step": 454
    },
    {
      "epoch": 0.3729508196721312,
      "grad_norm": 0.017344417050480843,
      "learning_rate": 4.379781420765027e-05,
      "loss": 0.0656,
      "step": 455
    },
    {
      "epoch": 0.3729508196721312,
      "loss_control": 0.0013933181762695312,
      "loss_data": 0.0,
      "loss_total": 0.0013933181762695312,
      "step": 455
    },
    {
      "epoch": 0.3737704918032787,
      "loss_control": 0.0030193328857421875,
      "loss_data": 0.49951171875,
      "loss_total": 0.10292167961597443,
      "step": 456
    },
    {
      "epoch": 0.37459016393442623,
      "loss_control": 0.00403594970703125,
      "loss_data": 0.496337890625,
      "loss_total": 0.10330352932214737,
      "step": 457
    },
    {
      "epoch": 0.37540983606557377,
      "loss_control": 0.0011043548583984375,
      "loss_data": 0.0,
      "loss_total": 0.0011043548583984375,
      "step": 458
    },
    {
      "epoch": 0.3762295081967213,
      "loss_control": 0.002079010009765625,
      "loss_data": 0.462158203125,
      "loss_total": 0.09451065212488174,
      "step": 459
    },
    {
      "epoch": 0.3770491803278688,
      "grad_norm": 0.05175415799021721,
      "learning_rate": 4.372950819672131e-05,
      "loss": 0.0606,
      "step": 460
    },
    {
      "epoch": 0.3770491803278688,
      "loss_control": 0.0094451904296875,
      "loss_data": 0.43115234375,
      "loss_total": 0.09567566215991974,
      "step": 460
    },
    {
      "epoch": 0.3778688524590164,
      "loss_control": 0.01253509521484375,
      "loss_data": 0.46435546875,
      "loss_total": 0.10540618747472763,
      "step": 461
    },
    {
      "epoch": 0.37868852459016394,
      "loss_control": 0.002227783203125,
      "loss_data": 0.0,
      "loss_total": 0.002227783203125,
      "step": 462
    },
    {
      "epoch": 0.3795081967213115,
      "loss_control": 0.005954742431640625,
      "loss_data": 0.0,
      "loss_total": 0.005954742431640625,
      "step": 463
    },
    {
      "epoch": 0.380327868852459,
      "loss_control": 0.0013837814331054688,
      "loss_data": 0.0,
      "loss_total": 0.0013837814331054688,
      "step": 464
    },
    {
      "epoch": 0.38114754098360654,
      "grad_norm": 0.008508507162332535,
      "learning_rate": 4.366120218579235e-05,
      "loss": 0.0421,
      "step": 465
    },
    {
      "epoch": 0.38114754098360654,
      "loss_control": 0.002407073974609375,
      "loss_data": 0.0,
      "loss_total": 0.002407073974609375,
      "step": 465
    },
    {
      "epoch": 0.3819672131147541,
      "loss_control": 0.004413604736328125,
      "loss_data": 0.0,
      "loss_total": 0.004413604736328125,
      "step": 466
    },
    {
      "epoch": 0.38278688524590165,
      "loss_control": 0.0064239501953125,
      "loss_data": 0.498779296875,
      "loss_total": 0.10617981106042862,
      "step": 467
    },
    {
      "epoch": 0.3836065573770492,
      "loss_control": 0.0022754669189453125,
      "loss_data": 0.499267578125,
      "loss_total": 0.10212898254394531,
      "step": 468
    },
    {
      "epoch": 0.3844262295081967,
      "loss_control": 0.0128173828125,
      "loss_data": 0.929443359375,
      "loss_total": 0.19870606064796448,
      "step": 469
    },
    {
      "epoch": 0.38524590163934425,
      "grad_norm": 0.349381685256958,
      "learning_rate": 4.359289617486339e-05,
      "loss": 0.0828,
      "step": 470
    },
    {
      "epoch": 0.38524590163934425,
      "loss_control": 0.0129241943359375,
      "loss_data": 0.89599609375,
      "loss_total": 0.1921234130859375,
      "step": 470
    },
    {
      "epoch": 0.3860655737704918,
      "loss_control": 0.00281524658203125,
      "loss_data": 0.49755859375,
      "loss_total": 0.10232696682214737,
      "step": 471
    },
    {
      "epoch": 0.38688524590163936,
      "loss_control": 0.0266265869140625,
      "loss_data": 0.4697265625,
      "loss_total": 0.12057190388441086,
      "step": 472
    },
    {
      "epoch": 0.3877049180327869,
      "loss_control": 0.053680419921875,
      "loss_data": 0.975830078125,
      "loss_total": 0.24884644150733948,
      "step": 473
    },
    {
      "epoch": 0.3885245901639344,
      "loss_control": 0.001331329345703125,
      "loss_data": 0.47119140625,
      "loss_total": 0.09556961059570312,
      "step": 474
    },
    {
      "epoch": 0.38934426229508196,
      "grad_norm": 0.025388898327946663,
      "learning_rate": 4.3524590163934424e-05,
      "loss": 0.1519,
      "step": 475
    },
    {
      "epoch": 0.38934426229508196,
      "loss_control": 0.0013227462768554688,
      "loss_data": 0.0,
      "loss_total": 0.0013227462768554688,
      "step": 475
    },
    {
      "epoch": 0.3901639344262295,
      "loss_control": 0.00368499755859375,
      "loss_data": 0.48779296875,
      "loss_total": 0.10124359279870987,
      "step": 476
    },
    {
      "epoch": 0.3909836065573771,
      "loss_control": 0.032073974609375,
      "loss_data": 0.946044921875,
      "loss_total": 0.221282958984375,
      "step": 477
    },
    {
      "epoch": 0.3918032786885246,
      "loss_control": 0.0125885009765625,
      "loss_data": 0.491455078125,
      "loss_total": 0.11087951809167862,
      "step": 478
    },
    {
      "epoch": 0.39262295081967213,
      "loss_control": 0.00939178466796875,
      "loss_data": 0.0,
      "loss_total": 0.00939178466796875,
      "step": 479
    },
    {
      "epoch": 0.39344262295081966,
      "grad_norm": 0.09510770440101624,
      "learning_rate": 4.3456284153005466e-05,
      "loss": 0.0888,
      "step": 480
    },
    {
      "epoch": 0.39344262295081966,
      "loss_control": 0.0037784576416015625,
      "loss_data": 0.0,
      "loss_total": 0.0037784576416015625,
      "step": 480
    },
    {
      "epoch": 0.3942622950819672,
      "loss_control": 0.0020160675048828125,
      "loss_data": 0.0,
      "loss_total": 0.0020160675048828125,
      "step": 481
    },
    {
      "epoch": 0.3950819672131147,
      "loss_control": 0.00212860107421875,
      "loss_data": 0.0,
      "loss_total": 0.00212860107421875,
      "step": 482
    },
    {
      "epoch": 0.3959016393442623,
      "loss_control": 0.04461669921875,
      "loss_data": 0.0,
      "loss_total": 0.04461669921875,
      "step": 483
    },
    {
      "epoch": 0.39672131147540984,
      "loss_control": 0.002765655517578125,
      "loss_data": 0.4990234375,
      "loss_total": 0.10257034748792648,
      "step": 484
    },
    {
      "epoch": 0.3975409836065574,
      "grad_norm": 0.022611118853092194,
      "learning_rate": 4.338797814207651e-05,
      "loss": 0.031,
      "step": 485
    },
    {
      "epoch": 0.3975409836065574,
      "loss_control": 0.110595703125,
      "loss_data": 0.457275390625,
      "loss_total": 0.20205077528953552,
      "step": 485
    },
    {
      "epoch": 0.3983606557377049,
      "loss_control": 0.0022525787353515625,
      "loss_data": 0.0,
      "loss_total": 0.0022525787353515625,
      "step": 486
    },
    {
      "epoch": 0.39918032786885244,
      "loss_control": 0.0016307830810546875,
      "loss_data": 0.499267578125,
      "loss_total": 0.10148429870605469,
      "step": 487
    },
    {
      "epoch": 0.4,
      "loss_control": 0.005237579345703125,
      "loss_data": 0.0,
      "loss_total": 0.005237579345703125,
      "step": 488
    },
    {
      "epoch": 0.40081967213114755,
      "loss_control": 0.00634002685546875,
      "loss_data": 0.495849609375,
      "loss_total": 0.10550995171070099,
      "step": 489
    },
    {
      "epoch": 0.4016393442622951,
      "grad_norm": 0.05864612013101578,
      "learning_rate": 4.331967213114754e-05,
      "loss": 0.0833,
      "step": 490
    },
    {
      "epoch": 0.4016393442622951,
      "loss_control": 0.0023212432861328125,
      "loss_data": 0.0,
      "loss_total": 0.0023212432861328125,
      "step": 490
    },
    {
      "epoch": 0.4024590163934426,
      "loss_control": 0.0041351318359375,
      "loss_data": 0.0,
      "loss_total": 0.0041351318359375,
      "step": 491
    },
    {
      "epoch": 0.40327868852459015,
      "loss_control": 0.005992889404296875,
      "loss_data": 0.0,
      "loss_total": 0.005992889404296875,
      "step": 492
    },
    {
      "epoch": 0.40409836065573773,
      "loss_control": 0.0152130126953125,
      "loss_data": 0.486572265625,
      "loss_total": 0.11252746731042862,
      "step": 493
    },
    {
      "epoch": 0.40491803278688526,
      "loss_control": 0.002285003662109375,
      "loss_data": 0.498046875,
      "loss_total": 0.10189437866210938,
      "step": 494
    },
    {
      "epoch": 0.4057377049180328,
      "grad_norm": 0.014711876399815083,
      "learning_rate": 4.3251366120218584e-05,
      "loss": 0.0454,
      "step": 495
    },
    {
      "epoch": 0.4057377049180328,
      "loss_control": 0.0033893585205078125,
      "loss_data": 0.4990234375,
      "loss_total": 0.10319405049085617,
      "step": 495
    },
    {
      "epoch": 0.4065573770491803,
      "loss_control": 0.0009636878967285156,
      "loss_data": 0.9736328125,
      "loss_total": 0.19569025933742523,
      "step": 496
    },
    {
      "epoch": 0.40737704918032785,
      "loss_control": 0.03680419921875,
      "loss_data": 0.0,
      "loss_total": 0.03680419921875,
      "step": 497
    },
    {
      "epoch": 0.4081967213114754,
      "loss_control": 0.00501251220703125,
      "loss_data": 0.0,
      "loss_total": 0.00501251220703125,
      "step": 498
    },
    {
      "epoch": 0.40901639344262297,
      "loss_control": 0.0009937286376953125,
      "loss_data": 0.49951171875,
      "loss_total": 0.10089607536792755,
      "step": 499
    },
    {
      "epoch": 0.4098360655737705,
      "grad_norm": 0.01763574779033661,
      "learning_rate": 4.318306010928962e-05,
      "loss": 0.0883,
      "step": 500
    },
    {
      "epoch": 0.4098360655737705,
      "loss_control": 0.0013685226440429688,
      "loss_data": 0.499755859375,
      "loss_total": 0.10131969302892685,
      "step": 500
    },
    {
      "epoch": 0.41065573770491803,
      "loss_control": 0.0017499923706054688,
      "loss_data": 0.49951171875,
      "loss_total": 0.10165233910083771,
      "step": 501
    },
    {
      "epoch": 0.41147540983606556,
      "loss_control": 0.0034618377685546875,
      "loss_data": 0.0,
      "loss_total": 0.0034618377685546875,
      "step": 502
    },
    {
      "epoch": 0.4122950819672131,
      "loss_control": 0.0034503936767578125,
      "loss_data": 0.49365234375,
      "loss_total": 0.1021808609366417,
      "step": 503
    },
    {
      "epoch": 0.4131147540983607,
      "loss_control": 0.00714111328125,
      "loss_data": 0.49755859375,
      "loss_total": 0.10665283352136612,
      "step": 504
    },
    {
      "epoch": 0.4139344262295082,
      "grad_norm": 0.06661258637905121,
      "learning_rate": 4.311475409836066e-05,
      "loss": 0.0831,
      "step": 505
    },
    {
      "epoch": 0.4139344262295082,
      "loss_control": 0.0005002021789550781,
      "loss_data": 0.459228515625,
      "loss_total": 0.09234590828418732,
      "step": 505
    },
    {
      "epoch": 0.41475409836065574,
      "loss_control": 0.00559234619140625,
      "loss_data": 0.9658203125,
      "loss_total": 0.1987564116716385,
      "step": 506
    },
    {
      "epoch": 0.4155737704918033,
      "loss_control": 0.00569915771484375,
      "loss_data": 0.45361328125,
      "loss_total": 0.09642181545495987,
      "step": 507
    },
    {
      "epoch": 0.4163934426229508,
      "loss_control": 0.11767578125,
      "loss_data": 0.96533203125,
      "loss_total": 0.31074219942092896,
      "step": 508
    },
    {
      "epoch": 0.41721311475409834,
      "loss_control": 0.020050048828125,
      "loss_data": 0.488037109375,
      "loss_total": 0.11765747517347336,
      "step": 509
    },
    {
      "epoch": 0.4180327868852459,
      "grad_norm": 0.2115137279033661,
      "learning_rate": 4.3046448087431696e-05,
      "loss": 0.1632,
      "step": 510
    },
    {
      "epoch": 0.4180327868852459,
      "loss_control": 0.0010843276977539062,
      "loss_data": 0.463623046875,
      "loss_total": 0.09380894154310226,
      "step": 510
    },
    {
      "epoch": 0.41885245901639345,
      "loss_control": 0.0027408599853515625,
      "loss_data": 0.46826171875,
      "loss_total": 0.09639320522546768,
      "step": 511
    },
    {
      "epoch": 0.419672131147541,
      "loss_control": 0.00563812255859375,
      "loss_data": 0.495361328125,
      "loss_total": 0.10471039265394211,
      "step": 512
    },
    {
      "epoch": 0.4204918032786885,
      "loss_control": 0.01094818115234375,
      "loss_data": 0.0,
      "loss_total": 0.01094818115234375,
      "step": 513
    },
    {
      "epoch": 0.42131147540983604,
      "loss_control": 0.00673675537109375,
      "loss_data": 0.0,
      "loss_total": 0.00673675537109375,
      "step": 514
    },
    {
      "epoch": 0.42213114754098363,
      "grad_norm": 0.06763685494661331,
      "learning_rate": 4.297814207650274e-05,
      "loss": 0.0625,
      "step": 515
    },
    {
      "epoch": 0.42213114754098363,
      "loss_control": 0.0013513565063476562,
      "loss_data": 0.480712890625,
      "loss_total": 0.09749393910169601,
      "step": 515
    },
    {
      "epoch": 0.42295081967213116,
      "loss_control": 0.0011806488037109375,
      "loss_data": 0.9296875,
      "loss_total": 0.18711815774440765,
      "step": 516
    },
    {
      "epoch": 0.4237704918032787,
      "loss_control": 0.0011930465698242188,
      "loss_data": 0.0,
      "loss_total": 0.0011930465698242188,
      "step": 517
    },
    {
      "epoch": 0.4245901639344262,
      "loss_control": 0.004398345947265625,
      "loss_data": 0.0,
      "loss_total": 0.004398345947265625,
      "step": 518
    },
    {
      "epoch": 0.42540983606557375,
      "loss_control": 0.002223968505859375,
      "loss_data": 0.49951171875,
      "loss_total": 0.10212631523609161,
      "step": 519
    },
    {
      "epoch": 0.4262295081967213,
      "grad_norm": 0.017367081716656685,
      "learning_rate": 4.290983606557377e-05,
      "loss": 0.0785,
      "step": 520
    },
    {
      "epoch": 0.4262295081967213,
      "loss_control": 0.004413604736328125,
      "loss_data": 0.498291015625,
      "loss_total": 0.10407181084156036,
      "step": 520
    },
    {
      "epoch": 0.42704918032786887,
      "loss_control": 0.012420654296875,
      "loss_data": 0.4482421875,
      "loss_total": 0.10206909477710724,
      "step": 521
    },
    {
      "epoch": 0.4278688524590164,
      "loss_control": 0.0008988380432128906,
      "loss_data": 0.49951171875,
      "loss_total": 0.10080118477344513,
      "step": 522
    },
    {
      "epoch": 0.42868852459016393,
      "loss_control": 0.0048828125,
      "loss_data": 0.497802734375,
      "loss_total": 0.10444336384534836,
      "step": 523
    },
    {
      "epoch": 0.42950819672131146,
      "loss_control": 0.04833984375,
      "loss_data": 0.0,
      "loss_total": 0.04833984375,
      "step": 524
    },
    {
      "epoch": 0.430327868852459,
      "grad_norm": 0.32004839181900024,
      "learning_rate": 4.2841530054644815e-05,
      "loss": 0.0919,
      "step": 525
    },
    {
      "epoch": 0.430327868852459,
      "loss_control": 0.000629425048828125,
      "loss_data": 0.999267578125,
      "loss_total": 0.20048294961452484,
      "step": 525
    },
    {
      "epoch": 0.4311475409836066,
      "loss_control": 0.0012521743774414062,
      "loss_data": 0.0,
      "loss_total": 0.0012521743774414062,
      "step": 526
    },
    {
      "epoch": 0.4319672131147541,
      "loss_control": 0.0011873245239257812,
      "loss_data": 0.493408203125,
      "loss_total": 0.09986896812915802,
      "step": 527
    },
    {
      "epoch": 0.43278688524590164,
      "loss_control": 0.0001512765884399414,
      "loss_data": 0.0,
      "loss_total": 0.0001512765884399414,
      "step": 528
    },
    {
      "epoch": 0.4336065573770492,
      "loss_control": 0.0013065338134765625,
      "loss_data": 0.0,
      "loss_total": 0.0013065338134765625,
      "step": 529
    },
    {
      "epoch": 0.4344262295081967,
      "grad_norm": 0.009814334101974964,
      "learning_rate": 4.277322404371585e-05,
      "loss": 0.0606,
      "step": 530
    },
    {
      "epoch": 0.4344262295081967,
      "loss_control": 0.0026092529296875,
      "loss_data": 0.497802734375,
      "loss_total": 0.10216980427503586,
      "step": 530
    },
    {
      "epoch": 0.43524590163934423,
      "loss_control": 0.00151824951171875,
      "loss_data": 0.48486328125,
      "loss_total": 0.09849090874195099,
      "step": 531
    },
    {
      "epoch": 0.4360655737704918,
      "loss_control": 0.00582122802734375,
      "loss_data": 0.4443359375,
      "loss_total": 0.09468841552734375,
      "step": 532
    },
    {
      "epoch": 0.43688524590163935,
      "loss_control": 0.0036602020263671875,
      "loss_data": 0.0,
      "loss_total": 0.0036602020263671875,
      "step": 533
    },
    {
      "epoch": 0.4377049180327869,
      "loss_control": 0.0014495849609375,
      "loss_data": 0.0,
      "loss_total": 0.0014495849609375,
      "step": 534
    },
    {
      "epoch": 0.4385245901639344,
      "grad_norm": 0.01235971413552761,
      "learning_rate": 4.270491803278689e-05,
      "loss": 0.0601,
      "step": 535
    },
    {
      "epoch": 0.4385245901639344,
      "loss_control": 0.0206756591796875,
      "loss_data": 0.4853515625,
      "loss_total": 0.11774597316980362,
      "step": 535
    },
    {
      "epoch": 0.43934426229508194,
      "loss_control": 0.0019931793212890625,
      "loss_data": 0.0,
      "loss_total": 0.0019931793212890625,
      "step": 536
    },
    {
      "epoch": 0.44016393442622953,
      "loss_control": 0.0008363723754882812,
      "loss_data": 0.49951171875,
      "loss_total": 0.10073871910572052,
      "step": 537
    },
    {
      "epoch": 0.44098360655737706,
      "loss_control": 0.006862640380859375,
      "loss_data": 0.49462890625,
      "loss_total": 0.10578842461109161,
      "step": 538
    },
    {
      "epoch": 0.4418032786885246,
      "loss_control": 0.0006718635559082031,
      "loss_data": 0.0,
      "loss_total": 0.0006718635559082031,
      "step": 539
    },
    {
      "epoch": 0.4426229508196721,
      "grad_norm": 0.00418873643502593,
      "learning_rate": 4.2636612021857926e-05,
      "loss": 0.0654,
      "step": 540
    },
    {
      "epoch": 0.4426229508196721,
      "loss_control": 0.00133514404296875,
      "loss_data": 0.4765625,
      "loss_total": 0.09664764255285263,
      "step": 540
    },
    {
      "epoch": 0.44344262295081965,
      "loss_control": 0.006420135498046875,
      "loss_data": 0.0,
      "loss_total": 0.006420135498046875,
      "step": 541
    },
    {
      "epoch": 0.44426229508196724,
      "loss_control": 0.0022983551025390625,
      "loss_data": 0.0,
      "loss_total": 0.0022983551025390625,
      "step": 542
    },
    {
      "epoch": 0.44508196721311477,
      "loss_control": 0.0030574798583984375,
      "loss_data": 0.99609375,
      "loss_total": 0.20227622985839844,
      "step": 543
    },
    {
      "epoch": 0.4459016393442623,
      "loss_control": 0.0053253173828125,
      "loss_data": 0.0,
      "loss_total": 0.0053253173828125,
      "step": 544
    },
    {
      "epoch": 0.44672131147540983,
      "grad_norm": 0.06395084410905838,
      "learning_rate": 4.256830601092897e-05,
      "loss": 0.0626,
      "step": 545
    },
    {
      "epoch": 0.44672131147540983,
      "loss_control": 0.0009374618530273438,
      "loss_data": 0.49951171875,
      "loss_total": 0.10083980858325958,
      "step": 545
    },
    {
      "epoch": 0.44754098360655736,
      "loss_control": 0.0015306472778320312,
      "loss_data": 0.0,
      "loss_total": 0.0015306472778320312,
      "step": 546
    },
    {
      "epoch": 0.4483606557377049,
      "loss_control": 0.0008492469787597656,
      "loss_data": 0.0,
      "loss_total": 0.0008492469787597656,
      "step": 547
    },
    {
      "epoch": 0.4491803278688525,
      "loss_control": 0.0026607513427734375,
      "loss_data": 0.962158203125,
      "loss_total": 0.19509239494800568,
      "step": 548
    },
    {
      "epoch": 0.45,
      "loss_control": 0.006214141845703125,
      "loss_data": 0.498779296875,
      "loss_total": 0.10597000271081924,
      "step": 549
    },
    {
      "epoch": 0.45081967213114754,
      "grad_norm": 0.0692097395658493,
      "learning_rate": 4.25e-05,
      "loss": 0.0809,
      "step": 550
    },
    {
      "epoch": 0.45081967213114754,
      "loss_control": 0.001964569091796875,
      "loss_data": 0.0,
      "loss_total": 0.001964569091796875,
      "step": 550
    },
    {
      "epoch": 0.4516393442622951,
      "loss_control": 0.00960540771484375,
      "loss_data": 0.44189453125,
      "loss_total": 0.09798431396484375,
      "step": 551
    },
    {
      "epoch": 0.4524590163934426,
      "loss_control": 0.0007529258728027344,
      "loss_data": 0.0,
      "loss_total": 0.0007529258728027344,
      "step": 552
    },
    {
      "epoch": 0.4532786885245902,
      "loss_control": 0.00922393798828125,
      "loss_data": 0.496826171875,
      "loss_total": 0.10858917236328125,
      "step": 553
    },
    {
      "epoch": 0.4540983606557377,
      "loss_control": 0.0011310577392578125,
      "loss_data": 0.499267578125,
      "loss_total": 0.10098457336425781,
      "step": 554
    },
    {
      "epoch": 0.45491803278688525,
      "grad_norm": 0.0077323103323578835,
      "learning_rate": 4.2431693989071045e-05,
      "loss": 0.0621,
      "step": 555
    },
    {
      "epoch": 0.45491803278688525,
      "loss_control": 0.0006375312805175781,
      "loss_data": 0.0,
      "loss_total": 0.0006375312805175781,
      "step": 555
    },
    {
      "epoch": 0.4557377049180328,
      "loss_control": 0.00586700439453125,
      "loss_data": 0.0,
      "loss_total": 0.00586700439453125,
      "step": 556
    },
    {
      "epoch": 0.4565573770491803,
      "loss_control": 0.002704620361328125,
      "loss_data": 0.47607421875,
      "loss_total": 0.09791946411132812,
      "step": 557
    },
    {
      "epoch": 0.45737704918032784,
      "loss_control": 0.0009660720825195312,
      "loss_data": 0.0,
      "loss_total": 0.0009660720825195312,
      "step": 558
    },
    {
      "epoch": 0.45819672131147543,
      "loss_control": 0.0015716552734375,
      "loss_data": 0.4990234375,
      "loss_total": 0.10137634724378586,
      "step": 559
    },
    {
      "epoch": 0.45901639344262296,
      "grad_norm": 0.01402910053730011,
      "learning_rate": 4.236338797814208e-05,
      "loss": 0.0414,
      "step": 560
    },
    {
      "epoch": 0.45901639344262296,
      "loss_control": 0.0009703636169433594,
      "loss_data": 0.49951171875,
      "loss_total": 0.1008727103471756,
      "step": 560
    },
    {
      "epoch": 0.4598360655737705,
      "loss_control": 0.005237579345703125,
      "loss_data": 0.496337890625,
      "loss_total": 0.10450515896081924,
      "step": 561
    },
    {
      "epoch": 0.460655737704918,
      "loss_control": 0.0007038116455078125,
      "loss_data": 0.0,
      "loss_total": 0.0007038116455078125,
      "step": 562
    },
    {
      "epoch": 0.46147540983606555,
      "loss_control": 0.001430511474609375,
      "loss_data": 0.499755859375,
      "loss_total": 0.10138168185949326,
      "step": 563
    },
    {
      "epoch": 0.46229508196721314,
      "loss_control": 0.00318145751953125,
      "loss_data": 0.486083984375,
      "loss_total": 0.10039825737476349,
      "step": 564
    },
    {
      "epoch": 0.46311475409836067,
      "grad_norm": 0.03355637192726135,
      "learning_rate": 4.229508196721312e-05,
      "loss": 0.0816,
      "step": 565
    },
    {
      "epoch": 0.46311475409836067,
      "loss_control": 0.0011110305786132812,
      "loss_data": 0.0,
      "loss_total": 0.0011110305786132812,
      "step": 565
    },
    {
      "epoch": 0.4639344262295082,
      "loss_control": 0.0027942657470703125,
      "loss_data": 0.472412109375,
      "loss_total": 0.09727668762207031,
      "step": 566
    },
    {
      "epoch": 0.46475409836065573,
      "loss_control": 0.0166473388671875,
      "loss_data": 0.0,
      "loss_total": 0.0166473388671875,
      "step": 567
    },
    {
      "epoch": 0.46557377049180326,
      "loss_control": 0.007602691650390625,
      "loss_data": 0.0,
      "loss_total": 0.007602691650390625,
      "step": 568
    },
    {
      "epoch": 0.4663934426229508,
      "loss_control": 0.0020656585693359375,
      "loss_data": 0.978515625,
      "loss_total": 0.19776879251003265,
      "step": 569
    },
    {
      "epoch": 0.4672131147540984,
      "grad_norm": 0.05920061469078064,
      "learning_rate": 4.2226775956284157e-05,
      "loss": 0.0641,
      "step": 570
    },
    {
      "epoch": 0.4672131147540984,
      "loss_control": 0.0011854171752929688,
      "loss_data": 0.476806640625,
      "loss_total": 0.09654674679040909,
      "step": 570
    },
    {
      "epoch": 0.4680327868852459,
      "loss_control": 0.0008721351623535156,
      "loss_data": 0.49951171875,
      "loss_total": 0.10077448189258575,
      "step": 571
    },
    {
      "epoch": 0.46885245901639344,
      "loss_control": 0.003528594970703125,
      "loss_data": 0.4755859375,
      "loss_total": 0.09864578396081924,
      "step": 572
    },
    {
      "epoch": 0.46967213114754097,
      "loss_control": 0.0005917549133300781,
      "loss_data": 0.0,
      "loss_total": 0.0005917549133300781,
      "step": 573
    },
    {
      "epoch": 0.4704918032786885,
      "loss_control": 0.0019702911376953125,
      "loss_data": 0.0,
      "loss_total": 0.0019702911376953125,
      "step": 574
    },
    {
      "epoch": 0.4713114754098361,
      "grad_norm": 0.014417805708944798,
      "learning_rate": 4.215846994535519e-05,
      "loss": 0.0597,
      "step": 575
    },
    {
      "epoch": 0.4713114754098361,
      "loss_control": 0.01342010498046875,
      "loss_data": 0.0,
      "loss_total": 0.01342010498046875,
      "step": 575
    },
    {
      "epoch": 0.4721311475409836,
      "loss_control": 0.0032444000244140625,
      "loss_data": 0.475830078125,
      "loss_total": 0.09841042011976242,
      "step": 576
    },
    {
      "epoch": 0.47295081967213115,
      "loss_control": 0.007266998291015625,
      "loss_data": 0.4697265625,
      "loss_total": 0.10121231526136398,
      "step": 577
    },
    {
      "epoch": 0.4737704918032787,
      "loss_control": 0.003223419189453125,
      "loss_data": 0.0,
      "loss_total": 0.003223419189453125,
      "step": 578
    },
    {
      "epoch": 0.4745901639344262,
      "loss_control": 0.005859375,
      "loss_data": 0.0,
      "loss_total": 0.005859375,
      "step": 579
    },
    {
      "epoch": 0.47540983606557374,
      "grad_norm": 0.049957506358623505,
      "learning_rate": 4.2090163934426227e-05,
      "loss": 0.0444,
      "step": 580
    },
    {
      "epoch": 0.47540983606557374,
      "loss_control": 0.0081939697265625,
      "loss_data": 0.0,
      "loss_total": 0.0081939697265625,
      "step": 580
    },
    {
      "epoch": 0.47622950819672133,
      "loss_control": 0.0007867813110351562,
      "loss_data": 0.499267578125,
      "loss_total": 0.10064029693603516,
      "step": 581
    },
    {
      "epoch": 0.47704918032786886,
      "loss_control": 0.0037689208984375,
      "loss_data": 0.0,
      "loss_total": 0.0037689208984375,
      "step": 582
    },
    {
      "epoch": 0.4778688524590164,
      "loss_control": 0.00273895263671875,
      "loss_data": 0.0,
      "loss_total": 0.00273895263671875,
      "step": 583
    },
    {
      "epoch": 0.4786885245901639,
      "loss_control": 0.0006499290466308594,
      "loss_data": 0.0,
      "loss_total": 0.0006499290466308594,
      "step": 584
    },
    {
      "epoch": 0.47950819672131145,
      "grad_norm": 0.0043403818272054195,
      "learning_rate": 4.202185792349727e-05,
      "loss": 0.0232,
      "step": 585
    },
    {
      "epoch": 0.47950819672131145,
      "loss_control": 0.0025043487548828125,
      "loss_data": 0.0,
      "loss_total": 0.0025043487548828125,
      "step": 585
    },
    {
      "epoch": 0.48032786885245904,
      "loss_control": 0.00469970703125,
      "loss_data": 0.0,
      "loss_total": 0.00469970703125,
      "step": 586
    },
    {
      "epoch": 0.48114754098360657,
      "loss_control": 0.00814056396484375,
      "loss_data": 0.979248046875,
      "loss_total": 0.203990176320076,
      "step": 587
    },
    {
      "epoch": 0.4819672131147541,
      "loss_control": 0.0019245147705078125,
      "loss_data": 0.0,
      "loss_total": 0.0019245147705078125,
      "step": 588
    },
    {
      "epoch": 0.48278688524590163,
      "loss_control": 0.004322052001953125,
      "loss_data": 0.0,
      "loss_total": 0.004322052001953125,
      "step": 589
    },
    {
      "epoch": 0.48360655737704916,
      "grad_norm": 0.03713586926460266,
      "learning_rate": 4.19535519125683e-05,
      "loss": 0.0435,
      "step": 590
    },
    {
      "epoch": 0.48360655737704916,
      "loss_control": 0.0019216537475585938,
      "loss_data": 0.4990234375,
      "loss_total": 0.10172634571790695,
      "step": 590
    },
    {
      "epoch": 0.48442622950819675,
      "loss_control": 0.0004088878631591797,
      "loss_data": 0.0,
      "loss_total": 0.0004088878631591797,
      "step": 591
    },
    {
      "epoch": 0.4852459016393443,
      "loss_control": 0.003467559814453125,
      "loss_data": 0.0,
      "loss_total": 0.003467559814453125,
      "step": 592
    },
    {
      "epoch": 0.4860655737704918,
      "loss_control": 0.0010538101196289062,
      "loss_data": 0.979248046875,
      "loss_total": 0.19690342247486115,
      "step": 593
    },
    {
      "epoch": 0.48688524590163934,
      "loss_control": 0.0007257461547851562,
      "loss_data": 0.47900390625,
      "loss_total": 0.09652652591466904,
      "step": 594
    },
    {
      "epoch": 0.48770491803278687,
      "grad_norm": 0.031268514692783356,
      "learning_rate": 4.1885245901639345e-05,
      "loss": 0.0798,
      "step": 595
    },
    {
      "epoch": 0.48770491803278687,
      "loss_control": 0.0015430450439453125,
      "loss_data": 0.98583984375,
      "loss_total": 0.19871102273464203,
      "step": 595
    },
    {
      "epoch": 0.4885245901639344,
      "loss_control": 0.00289154052734375,
      "loss_data": 0.0,
      "loss_total": 0.00289154052734375,
      "step": 596
    },
    {
      "epoch": 0.489344262295082,
      "loss_control": 0.0012426376342773438,
      "loss_data": 0.486083984375,
      "loss_total": 0.09845943748950958,
      "step": 597
    },
    {
      "epoch": 0.4901639344262295,
      "loss_control": 0.007343292236328125,
      "loss_data": 0.0,
      "loss_total": 0.007343292236328125,
      "step": 598
    },
    {
      "epoch": 0.49098360655737705,
      "loss_control": 0.0013275146484375,
      "loss_data": 0.499267578125,
      "loss_total": 0.1011810302734375,
      "step": 599
    },
    {
      "epoch": 0.4918032786885246,
      "grad_norm": 0.010949729010462761,
      "learning_rate": 4.181693989071038e-05,
      "loss": 0.0817,
      "step": 600
    },
    {
      "epoch": 0.4918032786885246,
      "loss_control": 0.0009746551513671875,
      "loss_data": 0.0,
      "loss_total": 0.0009746551513671875,
      "step": 600
    },
    {
      "epoch": 0.4926229508196721,
      "loss_control": 0.002025604248046875,
      "loss_data": 0.0,
      "loss_total": 0.002025604248046875,
      "step": 601
    },
    {
      "epoch": 0.4934426229508197,
      "loss_control": 0.00354766845703125,
      "loss_data": 0.0,
      "loss_total": 0.00354766845703125,
      "step": 602
    },
    {
      "epoch": 0.49426229508196723,
      "loss_control": 0.0014371871948242188,
      "loss_data": 0.499755859375,
      "loss_total": 0.1013883575797081,
      "step": 603
    },
    {
      "epoch": 0.49508196721311476,
      "loss_control": 0.0032711029052734375,
      "loss_data": 0.971923828125,
      "loss_total": 0.19765587151050568,
      "step": 604
    },
    {
      "epoch": 0.4959016393442623,
      "grad_norm": 0.060873229056596756,
      "learning_rate": 4.174863387978142e-05,
      "loss": 0.0611,
      "step": 605
    },
    {
      "epoch": 0.4959016393442623,
      "loss_control": 0.00830078125,
      "loss_data": 0.5,
      "loss_total": 0.10830078274011612,
      "step": 605
    },
    {
      "epoch": 0.4967213114754098,
      "loss_control": 0.0009403228759765625,
      "loss_data": 0.0,
      "loss_total": 0.0009403228759765625,
      "step": 606
    },
    {
      "epoch": 0.49754098360655735,
      "loss_control": 0.0010061264038085938,
      "loss_data": 0.999267578125,
      "loss_total": 0.2008596509695053,
      "step": 607
    },
    {
      "epoch": 0.49836065573770494,
      "loss_control": 0.0023040771484375,
      "loss_data": 0.951171875,
      "loss_total": 0.19253845512866974,
      "step": 608
    },
    {
      "epoch": 0.49918032786885247,
      "loss_control": 0.00848388671875,
      "loss_data": 0.965087890625,
      "loss_total": 0.20150147378444672,
      "step": 609
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.11793538182973862,
      "learning_rate": 4.168032786885246e-05,
      "loss": 0.1408,
      "step": 610
    },
    {
      "epoch": 0.5,
      "loss_control": 0.01358795166015625,
      "loss_data": 0.4375,
      "loss_total": 0.10108795017004013,
      "step": 610
    },
    {
      "epoch": 0.5008196721311475,
      "loss_control": 0.003528594970703125,
      "loss_data": 0.472412109375,
      "loss_total": 0.09801101684570312,
      "step": 611
    },
    {
      "epoch": 0.5016393442622951,
      "loss_control": 0.0041656494140625,
      "loss_data": 0.99609375,
      "loss_total": 0.2033843994140625,
      "step": 612
    },
    {
      "epoch": 0.5024590163934426,
      "loss_control": 0.005283355712890625,
      "loss_data": 0.0,
      "loss_total": 0.005283355712890625,
      "step": 613
    },
    {
      "epoch": 0.5032786885245901,
      "loss_control": 0.0019588470458984375,
      "loss_data": 0.0,
      "loss_total": 0.0019588470458984375,
      "step": 614
    },
    {
      "epoch": 0.5040983606557377,
      "grad_norm": 0.019607722759246826,
      "learning_rate": 4.16120218579235e-05,
      "loss": 0.0819,
      "step": 615
    },
    {
      "epoch": 0.5040983606557377,
      "loss_control": 0.0029163360595703125,
      "loss_data": 0.499755859375,
      "loss_total": 0.1028675064444542,
      "step": 615
    },
    {
      "epoch": 0.5049180327868853,
      "loss_control": 0.0018281936645507812,
      "loss_data": 0.498291015625,
      "loss_total": 0.10148639976978302,
      "step": 616
    },
    {
      "epoch": 0.5057377049180328,
      "loss_control": 0.0019683837890625,
      "loss_data": 0.0,
      "loss_total": 0.0019683837890625,
      "step": 617
    },
    {
      "epoch": 0.5065573770491804,
      "loss_control": 0.0010967254638671875,
      "loss_data": 0.9990234375,
      "loss_total": 0.20090141892433167,
      "step": 618
    },
    {
      "epoch": 0.5073770491803279,
      "loss_control": 0.00531005859375,
      "loss_data": 0.4970703125,
      "loss_total": 0.10472412407398224,
      "step": 619
    },
    {
      "epoch": 0.5081967213114754,
      "grad_norm": 0.06596831977367401,
      "learning_rate": 4.1543715846994534e-05,
      "loss": 0.1024,
      "step": 620
    },
    {
      "epoch": 0.5081967213114754,
      "loss_control": 0.005741119384765625,
      "loss_data": 0.4951171875,
      "loss_total": 0.10476455837488174,
      "step": 620
    },
    {
      "epoch": 0.509016393442623,
      "loss_control": 0.006954193115234375,
      "loss_data": 0.451416015625,
      "loss_total": 0.09723740071058273,
      "step": 621
    },
    {
      "epoch": 0.5098360655737705,
      "loss_control": 0.0033416748046875,
      "loss_data": 0.931884765625,
      "loss_total": 0.18971863389015198,
      "step": 622
    },
    {
      "epoch": 0.510655737704918,
      "loss_control": 0.0016393661499023438,
      "loss_data": 0.498779296875,
      "loss_total": 0.10139522701501846,
      "step": 623
    },
    {
      "epoch": 0.5114754098360655,
      "loss_control": 0.004322052001953125,
      "loss_data": 0.0,
      "loss_total": 0.004322052001953125,
      "step": 624
    },
    {
      "epoch": 0.5122950819672131,
      "grad_norm": 0.03549863025546074,
      "learning_rate": 4.1475409836065575e-05,
      "loss": 0.0995,
      "step": 625
    },
    {
      "epoch": 0.5122950819672131,
      "loss_control": 0.003719329833984375,
      "loss_data": 0.49755859375,
      "loss_total": 0.1032310500741005,
      "step": 625
    },
    {
      "epoch": 0.5131147540983606,
      "loss_control": 0.002513885498046875,
      "loss_data": 0.458251953125,
      "loss_total": 0.09416427463293076,
      "step": 626
    },
    {
      "epoch": 0.5139344262295082,
      "loss_control": 0.0010204315185546875,
      "loss_data": 0.499267578125,
      "loss_total": 0.10087394714355469,
      "step": 627
    },
    {
      "epoch": 0.5147540983606558,
      "loss_control": 0.0027713775634765625,
      "loss_data": 0.0,
      "loss_total": 0.0027713775634765625,
      "step": 628
    },
    {
      "epoch": 0.5155737704918033,
      "loss_control": 0.0026187896728515625,
      "loss_data": 0.497802734375,
      "loss_total": 0.10217934101819992,
      "step": 629
    },
    {
      "epoch": 0.5163934426229508,
      "grad_norm": 0.02020389772951603,
      "learning_rate": 4.140710382513661e-05,
      "loss": 0.0806,
      "step": 630
    },
    {
      "epoch": 0.5163934426229508,
      "loss_control": 0.0018758773803710938,
      "loss_data": 0.0,
      "loss_total": 0.0018758773803710938,
      "step": 630
    },
    {
      "epoch": 0.5172131147540984,
      "loss_control": 0.0007762908935546875,
      "loss_data": 0.0,
      "loss_total": 0.0007762908935546875,
      "step": 631
    },
    {
      "epoch": 0.5180327868852459,
      "loss_control": 0.0011005401611328125,
      "loss_data": 0.499755859375,
      "loss_total": 0.1010517105460167,
      "step": 632
    },
    {
      "epoch": 0.5188524590163934,
      "loss_control": 0.00283050537109375,
      "loss_data": 0.498046875,
      "loss_total": 0.10243988037109375,
      "step": 633
    },
    {
      "epoch": 0.519672131147541,
      "loss_control": 0.00269317626953125,
      "loss_data": 0.0,
      "loss_total": 0.00269317626953125,
      "step": 634
    },
    {
      "epoch": 0.5204918032786885,
      "grad_norm": 0.02777034416794777,
      "learning_rate": 4.133879781420765e-05,
      "loss": 0.0418,
      "step": 635
    },
    {
      "epoch": 0.5204918032786885,
      "loss_control": 0.0027256011962890625,
      "loss_data": 0.997314453125,
      "loss_total": 0.20218849182128906,
      "step": 635
    },
    {
      "epoch": 0.521311475409836,
      "loss_control": 0.0045318603515625,
      "loss_data": 0.0,
      "loss_total": 0.0045318603515625,
      "step": 636
    },
    {
      "epoch": 0.5221311475409836,
      "loss_control": 0.0007910728454589844,
      "loss_data": 0.0,
      "loss_total": 0.0007910728454589844,
      "step": 637
    },
    {
      "epoch": 0.5229508196721312,
      "loss_control": 0.0012159347534179688,
      "loss_data": 0.970458984375,
      "loss_total": 0.19530773162841797,
      "step": 638
    },
    {
      "epoch": 0.5237704918032787,
      "loss_control": 0.0018291473388671875,
      "loss_data": 0.992919921875,
      "loss_total": 0.20041313767433167,
      "step": 639
    },
    {
      "epoch": 0.5245901639344263,
      "grad_norm": 0.025962626561522484,
      "learning_rate": 4.127049180327869e-05,
      "loss": 0.1206,
      "step": 640
    },
    {
      "epoch": 0.5245901639344263,
      "loss_control": 0.002079010009765625,
      "loss_data": 0.478759765625,
      "loss_total": 0.09783096611499786,
      "step": 640
    },
    {
      "epoch": 0.5254098360655738,
      "loss_control": 0.00115966796875,
      "loss_data": 0.0,
      "loss_total": 0.00115966796875,
      "step": 641
    },
    {
      "epoch": 0.5262295081967213,
      "loss_control": 0.0017242431640625,
      "loss_data": 0.44580078125,
      "loss_total": 0.09088440239429474,
      "step": 642
    },
    {
      "epoch": 0.5270491803278688,
      "loss_control": 0.0016460418701171875,
      "loss_data": 0.0,
      "loss_total": 0.0016460418701171875,
      "step": 643
    },
    {
      "epoch": 0.5278688524590164,
      "loss_control": 0.008819580078125,
      "loss_data": 0.497802734375,
      "loss_total": 0.10838013142347336,
      "step": 644
    },
    {
      "epoch": 0.5286885245901639,
      "grad_norm": 0.0904354602098465,
      "learning_rate": 4.120218579234973e-05,
      "loss": 0.06,
      "step": 645
    },
    {
      "epoch": 0.5286885245901639,
      "loss_control": 0.0248260498046875,
      "loss_data": 0.0,
      "loss_total": 0.0248260498046875,
      "step": 645
    },
    {
      "epoch": 0.5295081967213114,
      "loss_control": 0.0023174285888671875,
      "loss_data": 0.0,
      "loss_total": 0.0023174285888671875,
      "step": 646
    },
    {
      "epoch": 0.530327868852459,
      "loss_control": 0.0013580322265625,
      "loss_data": 0.0,
      "loss_total": 0.0013580322265625,
      "step": 647
    },
    {
      "epoch": 0.5311475409836065,
      "loss_control": 0.0046844482421875,
      "loss_data": 0.0,
      "loss_total": 0.0046844482421875,
      "step": 648
    },
    {
      "epoch": 0.5319672131147541,
      "loss_control": 0.00328826904296875,
      "loss_data": 0.49755859375,
      "loss_total": 0.10279998928308487,
      "step": 649
    },
    {
      "epoch": 0.5327868852459017,
      "grad_norm": 0.027416929602622986,
      "learning_rate": 4.1133879781420764e-05,
      "loss": 0.0272,
      "step": 650
    },
    {
      "epoch": 0.5327868852459017,
      "loss_control": 0.00428009033203125,
      "loss_data": 0.995849609375,
      "loss_total": 0.203450009226799,
      "step": 650
    },
    {
      "epoch": 0.5336065573770492,
      "loss_control": 0.00726318359375,
      "loss_data": 0.4833984375,
      "loss_total": 0.10394287109375,
      "step": 651
    },
    {
      "epoch": 0.5344262295081967,
      "loss_control": 0.0008845329284667969,
      "loss_data": 0.49951171875,
      "loss_total": 0.10078687965869904,
      "step": 652
    },
    {
      "epoch": 0.5352459016393443,
      "loss_control": 0.001678466796875,
      "loss_data": 0.498779296875,
      "loss_total": 0.10143432766199112,
      "step": 653
    },
    {
      "epoch": 0.5360655737704918,
      "loss_control": 0.00026988983154296875,
      "loss_data": 0.499755859375,
      "loss_total": 0.10022106021642685,
      "step": 654
    },
    {
      "epoch": 0.5368852459016393,
      "grad_norm": 0.0018644978990778327,
      "learning_rate": 4.1065573770491806e-05,
      "loss": 0.122,
      "step": 655
    },
    {
      "epoch": 0.5368852459016393,
      "loss_control": 0.00307464599609375,
      "loss_data": 0.0,
      "loss_total": 0.00307464599609375,
      "step": 655
    },
    {
      "epoch": 0.5377049180327869,
      "loss_control": 0.0007686614990234375,
      "loss_data": 0.480712890625,
      "loss_total": 0.0969112440943718,
      "step": 656
    },
    {
      "epoch": 0.5385245901639344,
      "loss_control": 0.0014848709106445312,
      "loss_data": 0.0,
      "loss_total": 0.0014848709106445312,
      "step": 657
    },
    {
      "epoch": 0.5393442622950819,
      "loss_control": 0.0006856918334960938,
      "loss_data": 0.0,
      "loss_total": 0.0006856918334960938,
      "step": 658
    },
    {
      "epoch": 0.5401639344262295,
      "loss_control": 0.0009784698486328125,
      "loss_data": 0.0,
      "loss_total": 0.0009784698486328125,
      "step": 659
    },
    {
      "epoch": 0.5409836065573771,
      "grad_norm": 0.0063971965573728085,
      "learning_rate": 4.099726775956285e-05,
      "loss": 0.0206,
      "step": 660
    },
    {
      "epoch": 0.5409836065573771,
      "loss_control": 0.0010013580322265625,
      "loss_data": 0.9990234375,
      "loss_total": 0.20080605149269104,
      "step": 660
    },
    {
      "epoch": 0.5418032786885246,
      "loss_control": 0.0008449554443359375,
      "loss_data": 0.499755859375,
      "loss_total": 0.10079612582921982,
      "step": 661
    },
    {
      "epoch": 0.5426229508196722,
      "loss_control": 0.0085906982421875,
      "loss_data": 0.469482421875,
      "loss_total": 0.10248718410730362,
      "step": 662
    },
    {
      "epoch": 0.5434426229508197,
      "loss_control": 0.0022640228271484375,
      "loss_data": 0.0,
      "loss_total": 0.0022640228271484375,
      "step": 663
    },
    {
      "epoch": 0.5442622950819672,
      "loss_control": 0.0016155242919921875,
      "loss_data": 0.499755859375,
      "loss_total": 0.10156669467687607,
      "step": 664
    },
    {
      "epoch": 0.5450819672131147,
      "grad_norm": 0.02038242295384407,
      "learning_rate": 4.092896174863388e-05,
      "loss": 0.1016,
      "step": 665
    },
    {
      "epoch": 0.5450819672131147,
      "loss_control": 0.007244110107421875,
      "loss_data": 0.0,
      "loss_total": 0.007244110107421875,
      "step": 665
    },
    {
      "epoch": 0.5459016393442623,
      "loss_control": 0.004093170166015625,
      "loss_data": 0.478759765625,
      "loss_total": 0.09984512627124786,
      "step": 666
    },
    {
      "epoch": 0.5467213114754098,
      "loss_control": 0.0024623870849609375,
      "loss_data": 0.4990234375,
      "loss_total": 0.1022670790553093,
      "step": 667
    },
    {
      "epoch": 0.5475409836065573,
      "loss_control": 0.00836181640625,
      "loss_data": 0.0,
      "loss_total": 0.00836181640625,
      "step": 668
    },
    {
      "epoch": 0.5483606557377049,
      "loss_control": 0.0208587646484375,
      "loss_data": 0.484375,
      "loss_total": 0.11773376911878586,
      "step": 669
    },
    {
      "epoch": 0.5491803278688525,
      "grad_norm": 0.5423479676246643,
      "learning_rate": 4.0860655737704924e-05,
      "loss": 0.0671,
      "step": 670
    },
    {
      "epoch": 0.5491803278688525,
      "loss_control": 0.0745849609375,
      "loss_data": 0.0,
      "loss_total": 0.0745849609375,
      "step": 670
    },
    {
      "epoch": 0.55,
      "loss_control": 0.0012674331665039062,
      "loss_data": 0.976318359375,
      "loss_total": 0.19653110206127167,
      "step": 671
    },
    {
      "epoch": 0.5508196721311476,
      "loss_control": 0.000774383544921875,
      "loss_data": 0.4853515625,
      "loss_total": 0.097844697535038,
      "step": 672
    },
    {
      "epoch": 0.5516393442622951,
      "loss_control": 0.0009322166442871094,
      "loss_data": 0.480224609375,
      "loss_total": 0.09697713702917099,
      "step": 673
    },
    {
      "epoch": 0.5524590163934426,
      "loss_control": 0.0020351409912109375,
      "loss_data": 0.499267578125,
      "loss_total": 0.10188865661621094,
      "step": 674
    },
    {
      "epoch": 0.5532786885245902,
      "grad_norm": 0.011523418128490448,
      "learning_rate": 4.079234972677596e-05,
      "loss": 0.1136,
      "step": 675
    },
    {
      "epoch": 0.5532786885245902,
      "loss_control": 0.00418853759765625,
      "loss_data": 0.978271484375,
      "loss_total": 0.19984284043312073,
      "step": 675
    },
    {
      "epoch": 0.5540983606557377,
      "loss_control": 0.0182342529296875,
      "loss_data": 0.442138671875,
      "loss_total": 0.10666199028491974,
      "step": 676
    },
    {
      "epoch": 0.5549180327868852,
      "loss_control": 0.00591278076171875,
      "loss_data": 0.0,
      "loss_total": 0.00591278076171875,
      "step": 677
    },
    {
      "epoch": 0.5557377049180328,
      "loss_control": 0.0183258056640625,
      "loss_data": 0.4833984375,
      "loss_total": 0.1150054931640625,
      "step": 678
    },
    {
      "epoch": 0.5565573770491803,
      "loss_control": 0.003582000732421875,
      "loss_data": 0.4716796875,
      "loss_total": 0.09791793674230576,
      "step": 679
    },
    {
      "epoch": 0.5573770491803278,
      "grad_norm": 0.06047835946083069,
      "learning_rate": 4.0724043715847e-05,
      "loss": 0.1051,
      "step": 680
    },
    {
      "epoch": 0.5573770491803278,
      "loss_control": 0.0012903213500976562,
      "loss_data": 0.4990234375,
      "loss_total": 0.10109501332044601,
      "step": 680
    },
    {
      "epoch": 0.5581967213114755,
      "loss_control": 0.006267547607421875,
      "loss_data": 0.0,
      "loss_total": 0.006267547607421875,
      "step": 681
    },
    {
      "epoch": 0.559016393442623,
      "loss_control": 0.00199127197265625,
      "loss_data": 0.97607421875,
      "loss_total": 0.19720612466335297,
      "step": 682
    },
    {
      "epoch": 0.5598360655737705,
      "loss_control": 0.0010547637939453125,
      "loss_data": 0.0,
      "loss_total": 0.0010547637939453125,
      "step": 683
    },
    {
      "epoch": 0.5606557377049181,
      "loss_control": 0.0033855438232421875,
      "loss_data": 0.0,
      "loss_total": 0.0033855438232421875,
      "step": 684
    },
    {
      "epoch": 0.5614754098360656,
      "grad_norm": 0.07285888493061066,
      "learning_rate": 4.0655737704918036e-05,
      "loss": 0.0618,
      "step": 685
    },
    {
      "epoch": 0.5614754098360656,
      "loss_control": 0.0015592575073242188,
      "loss_data": 0.0,
      "loss_total": 0.0015592575073242188,
      "step": 685
    },
    {
      "epoch": 0.5622950819672131,
      "loss_control": 0.004268646240234375,
      "loss_data": 0.0,
      "loss_total": 0.004268646240234375,
      "step": 686
    },
    {
      "epoch": 0.5631147540983606,
      "loss_control": 0.002117156982421875,
      "loss_data": 0.0,
      "loss_total": 0.002117156982421875,
      "step": 687
    },
    {
      "epoch": 0.5639344262295082,
      "loss_control": 0.003963470458984375,
      "loss_data": 0.4970703125,
      "loss_total": 0.10337753593921661,
      "step": 688
    },
    {
      "epoch": 0.5647540983606557,
      "loss_control": 0.0007877349853515625,
      "loss_data": 0.0,
      "loss_total": 0.0007877349853515625,
      "step": 689
    },
    {
      "epoch": 0.5655737704918032,
      "grad_norm": 0.00712929992005229,
      "learning_rate": 4.058743169398908e-05,
      "loss": 0.0224,
      "step": 690
    },
    {
      "epoch": 0.5655737704918032,
      "loss_control": 0.006011962890625,
      "loss_data": 0.457763671875,
      "loss_total": 0.097564697265625,
      "step": 690
    },
    {
      "epoch": 0.5663934426229508,
      "loss_control": 0.0023288726806640625,
      "loss_data": 0.49951171875,
      "loss_total": 0.1022312194108963,
      "step": 691
    },
    {
      "epoch": 0.5672131147540984,
      "loss_control": 0.002197265625,
      "loss_data": 0.498046875,
      "loss_total": 0.101806640625,
      "step": 692
    },
    {
      "epoch": 0.5680327868852459,
      "loss_control": 0.006961822509765625,
      "loss_data": 0.0,
      "loss_total": 0.006961822509765625,
      "step": 693
    },
    {
      "epoch": 0.5688524590163935,
      "loss_control": 0.0012426376342773438,
      "loss_data": 0.0,
      "loss_total": 0.0012426376342773438,
      "step": 694
    },
    {
      "epoch": 0.569672131147541,
      "grad_norm": 0.008291180245578289,
      "learning_rate": 4.051912568306011e-05,
      "loss": 0.062,
      "step": 695
    },
    {
      "epoch": 0.569672131147541,
      "loss_control": 0.0013828277587890625,
      "loss_data": 0.498779296875,
      "loss_total": 0.10113868862390518,
      "step": 695
    },
    {
      "epoch": 0.5704918032786885,
      "loss_control": 0.00315093994140625,
      "loss_data": 0.0,
      "loss_total": 0.00315093994140625,
      "step": 696
    },
    {
      "epoch": 0.5713114754098361,
      "loss_control": 0.0012292861938476562,
      "loss_data": 0.0,
      "loss_total": 0.0012292861938476562,
      "step": 697
    },
    {
      "epoch": 0.5721311475409836,
      "loss_control": 0.003116607666015625,
      "loss_data": 0.96875,
      "loss_total": 0.19686661660671234,
      "step": 698
    },
    {
      "epoch": 0.5729508196721311,
      "loss_control": 0.0010232925415039062,
      "loss_data": 0.499267578125,
      "loss_total": 0.1008768081665039,
      "step": 699
    },
    {
      "epoch": 0.5737704918032787,
      "grad_norm": 0.00613840576261282,
      "learning_rate": 4.0450819672131155e-05,
      "loss": 0.0807,
      "step": 700
    },
    {
      "epoch": 0.5737704918032787,
      "loss_control": 0.0015506744384765625,
      "loss_data": 0.9697265625,
      "loss_total": 0.19549599289894104,
      "step": 700
    },
    {
      "epoch": 0.5745901639344262,
      "loss_control": 0.001064300537109375,
      "loss_data": 0.0,
      "loss_total": 0.001064300537109375,
      "step": 701
    },
    {
      "epoch": 0.5754098360655737,
      "loss_control": 0.0030879974365234375,
      "loss_data": 0.465576171875,
      "loss_total": 0.09620323032140732,
      "step": 702
    },
    {
      "epoch": 0.5762295081967214,
      "loss_control": 0.0014810562133789062,
      "loss_data": 0.0,
      "loss_total": 0.0014810562133789062,
      "step": 703
    },
    {
      "epoch": 0.5770491803278689,
      "loss_control": 0.005035400390625,
      "loss_data": 0.4375,
      "loss_total": 0.09253539890050888,
      "step": 704
    },
    {
      "epoch": 0.5778688524590164,
      "grad_norm": 0.09888151288032532,
      "learning_rate": 4.038251366120219e-05,
      "loss": 0.0774,
      "step": 705
    },
    {
      "epoch": 0.5778688524590164,
      "loss_control": 0.0008578300476074219,
      "loss_data": 0.97265625,
      "loss_total": 0.19538907706737518,
      "step": 705
    },
    {
      "epoch": 0.578688524590164,
      "loss_control": 0.0033740997314453125,
      "loss_data": 0.498291015625,
      "loss_total": 0.10303230583667755,
      "step": 706
    },
    {
      "epoch": 0.5795081967213115,
      "loss_control": 0.0006146430969238281,
      "loss_data": 0.0,
      "loss_total": 0.0006146430969238281,
      "step": 707
    },
    {
      "epoch": 0.580327868852459,
      "loss_control": 0.0006761550903320312,
      "loss_data": 0.999267578125,
      "loss_total": 0.20052967965602875,
      "step": 708
    },
    {
      "epoch": 0.5811475409836065,
      "loss_control": 0.0014801025390625,
      "loss_data": 0.0,
      "loss_total": 0.0014801025390625,
      "step": 709
    },
    {
      "epoch": 0.5819672131147541,
      "grad_norm": 0.014657538384199142,
      "learning_rate": 4.0314207650273225e-05,
      "loss": 0.1002,
      "step": 710
    },
    {
      "epoch": 0.5819672131147541,
      "loss_control": 0.0032939910888671875,
      "loss_data": 0.479736328125,
      "loss_total": 0.09924125671386719,
      "step": 710
    },
    {
      "epoch": 0.5827868852459016,
      "loss_control": 0.0029659271240234375,
      "loss_data": 0.0,
      "loss_total": 0.0029659271240234375,
      "step": 711
    },
    {
      "epoch": 0.5836065573770491,
      "loss_control": 0.00695037841796875,
      "loss_data": 0.95166015625,
      "loss_total": 0.19728241860866547,
      "step": 712
    },
    {
      "epoch": 0.5844262295081967,
      "loss_control": 0.0026073455810546875,
      "loss_data": 0.45703125,
      "loss_total": 0.09401359409093857,
      "step": 713
    },
    {
      "epoch": 0.5852459016393443,
      "loss_control": 0.0003821849822998047,
      "loss_data": 0.0,
      "loss_total": 0.0003821849822998047,
      "step": 714
    },
    {
      "epoch": 0.5860655737704918,
      "grad_norm": 0.002459832699969411,
      "learning_rate": 4.0245901639344266e-05,
      "loss": 0.0788,
      "step": 715
    },
    {
      "epoch": 0.5860655737704918,
      "loss_control": 0.0041046142578125,
      "loss_data": 0.4970703125,
      "loss_total": 0.10351867973804474,
      "step": 715
    },
    {
      "epoch": 0.5868852459016394,
      "loss_control": 0.0013217926025390625,
      "loss_data": 0.499267578125,
      "loss_total": 0.10117530822753906,
      "step": 716
    },
    {
      "epoch": 0.5877049180327869,
      "loss_control": 0.0006136894226074219,
      "loss_data": 0.467529296875,
      "loss_total": 0.09411954879760742,
      "step": 717
    },
    {
      "epoch": 0.5885245901639344,
      "loss_control": 0.0007834434509277344,
      "loss_data": 0.0,
      "loss_total": 0.0007834434509277344,
      "step": 718
    },
    {
      "epoch": 0.589344262295082,
      "loss_control": 0.001190185546875,
      "loss_data": 0.49951171875,
      "loss_total": 0.10109253227710724,
      "step": 719
    },
    {
      "epoch": 0.5901639344262295,
      "grad_norm": 0.005833403207361698,
      "learning_rate": 4.01775956284153e-05,
      "loss": 0.0801,
      "step": 720
    },
    {
      "epoch": 0.5901639344262295,
      "loss_control": 0.0150146484375,
      "loss_data": 0.96923828125,
      "loss_total": 0.2088623046875,
      "step": 720
    },
    {
      "epoch": 0.590983606557377,
      "loss_control": 0.0014066696166992188,
      "loss_data": 0.0,
      "loss_total": 0.0014066696166992188,
      "step": 721
    },
    {
      "epoch": 0.5918032786885246,
      "loss_control": 0.0030651092529296875,
      "loss_data": 0.96337890625,
      "loss_total": 0.19574089348316193,
      "step": 722
    },
    {
      "epoch": 0.5926229508196721,
      "loss_control": 0.0026378631591796875,
      "loss_data": 0.5,
      "loss_total": 0.1026378646492958,
      "step": 723
    },
    {
      "epoch": 0.5934426229508196,
      "loss_control": 0.001148223876953125,
      "loss_data": 0.499267578125,
      "loss_total": 0.10100173950195312,
      "step": 724
    },
    {
      "epoch": 0.5942622950819673,
      "grad_norm": 0.008218997158110142,
      "learning_rate": 4.0109289617486336e-05,
      "loss": 0.1219,
      "step": 725
    },
    {
      "epoch": 0.5942622950819673,
      "loss_control": 0.08306884765625,
      "loss_data": 0.499755859375,
      "loss_total": 0.18302002549171448,
      "step": 725
    },
    {
      "epoch": 0.5950819672131148,
      "loss_control": 0.0023174285888671875,
      "loss_data": 0.9658203125,
      "loss_total": 0.19548149406909943,
      "step": 726
    },
    {
      "epoch": 0.5959016393442623,
      "loss_control": 0.006317138671875,
      "loss_data": 0.0,
      "loss_total": 0.006317138671875,
      "step": 727
    },
    {
      "epoch": 0.5967213114754099,
      "loss_control": 0.0010881423950195312,
      "loss_data": 0.0,
      "loss_total": 0.0010881423950195312,
      "step": 728
    },
    {
      "epoch": 0.5975409836065574,
      "loss_control": 0.004669189453125,
      "loss_data": 0.497802734375,
      "loss_total": 0.10422974079847336,
      "step": 729
    },
    {
      "epoch": 0.5983606557377049,
      "grad_norm": 0.05688031390309334,
      "learning_rate": 4.004098360655738e-05,
      "loss": 0.098,
      "step": 730
    },
    {
      "epoch": 0.5983606557377049,
      "loss_control": 0.006267547607421875,
      "loss_data": 0.0,
      "loss_total": 0.006267547607421875,
      "step": 730
    },
    {
      "epoch": 0.5991803278688524,
      "loss_control": 0.03436279296875,
      "loss_data": 0.0,
      "loss_total": 0.03436279296875,
      "step": 731
    },
    {
      "epoch": 0.6,
      "loss_control": 0.0003018379211425781,
      "loss_data": 0.0,
      "loss_total": 0.0003018379211425781,
      "step": 732
    },
    {
      "epoch": 0.6008196721311475,
      "loss_control": 0.0014514923095703125,
      "loss_data": 0.0,
      "loss_total": 0.0014514923095703125,
      "step": 733
    },
    {
      "epoch": 0.601639344262295,
      "loss_control": 0.0008630752563476562,
      "loss_data": 0.438720703125,
      "loss_total": 0.08860721439123154,
      "step": 734
    },
    {
      "epoch": 0.6024590163934426,
      "grad_norm": 0.07454651594161987,
      "learning_rate": 3.997267759562841e-05,
      "loss": 0.0262,
      "step": 735
    },
    {
      "epoch": 0.6024590163934426,
      "loss_control": 0.0023937225341796875,
      "loss_data": 0.499267578125,
      "loss_total": 0.10224723815917969,
      "step": 735
    },
    {
      "epoch": 0.6032786885245902,
      "loss_control": 0.0007276535034179688,
      "loss_data": 0.49951171875,
      "loss_total": 0.10063000023365021,
      "step": 736
    },
    {
      "epoch": 0.6040983606557377,
      "loss_control": 0.00647735595703125,
      "loss_data": 0.94873046875,
      "loss_total": 0.1962234526872635,
      "step": 737
    },
    {
      "epoch": 0.6049180327868853,
      "loss_control": 0.002742767333984375,
      "loss_data": 0.49755859375,
      "loss_total": 0.1022544875741005,
      "step": 738
    },
    {
      "epoch": 0.6057377049180328,
      "loss_control": 0.00379180908203125,
      "loss_data": 0.0,
      "loss_total": 0.00379180908203125,
      "step": 739
    },
    {
      "epoch": 0.6065573770491803,
      "grad_norm": 0.05048584192991257,
      "learning_rate": 3.9904371584699455e-05,
      "loss": 0.101,
      "step": 740
    },
    {
      "epoch": 0.6065573770491803,
      "loss_control": 0.0012636184692382812,
      "loss_data": 0.0,
      "loss_total": 0.0012636184692382812,
      "step": 740
    },
    {
      "epoch": 0.6073770491803279,
      "loss_control": 0.00232696533203125,
      "loss_data": 0.46044921875,
      "loss_total": 0.09441681206226349,
      "step": 741
    },
    {
      "epoch": 0.6081967213114754,
      "loss_control": 0.0011854171752929688,
      "loss_data": 0.0,
      "loss_total": 0.0011854171752929688,
      "step": 742
    },
    {
      "epoch": 0.6090163934426229,
      "loss_control": 0.0022449493408203125,
      "loss_data": 0.459716796875,
      "loss_total": 0.09418831020593643,
      "step": 743
    },
    {
      "epoch": 0.6098360655737705,
      "loss_control": 0.004241943359375,
      "loss_data": 0.499755859375,
      "loss_total": 0.10419311374425888,
      "step": 744
    },
    {
      "epoch": 0.610655737704918,
      "grad_norm": 0.06684998422861099,
      "learning_rate": 3.983606557377049e-05,
      "loss": 0.059,
      "step": 745
    },
    {
      "epoch": 0.610655737704918,
      "loss_control": 0.0009274482727050781,
      "loss_data": 0.4755859375,
      "loss_total": 0.0960446372628212,
      "step": 745
    },
    {
      "epoch": 0.6114754098360655,
      "loss_control": 0.00868988037109375,
      "loss_data": 0.9814453125,
      "loss_total": 0.20497894287109375,
      "step": 746
    },
    {
      "epoch": 0.6122950819672132,
      "loss_control": 0.00424957275390625,
      "loss_data": 0.498046875,
      "loss_total": 0.10385894775390625,
      "step": 747
    },
    {
      "epoch": 0.6131147540983607,
      "loss_control": 0.0010023117065429688,
      "loss_data": 0.49951171875,
      "loss_total": 0.10090465843677521,
      "step": 748
    },
    {
      "epoch": 0.6139344262295082,
      "loss_control": 0.0094451904296875,
      "loss_data": 0.93505859375,
      "loss_total": 0.1964569091796875,
      "step": 749
    },
    {
      "epoch": 0.6147540983606558,
      "grad_norm": 0.09919263422489166,
      "learning_rate": 3.976775956284153e-05,
      "loss": 0.1404,
      "step": 750
    },
    {
      "epoch": 0.6147540983606558,
      "loss_control": 0.0003237724304199219,
      "loss_data": 0.499755859375,
      "loss_total": 0.1002749428153038,
      "step": 750
    },
    {
      "epoch": 0.6155737704918033,
      "loss_control": 0.0019426345825195312,
      "loss_data": 0.998046875,
      "loss_total": 0.20155201852321625,
      "step": 751
    },
    {
      "epoch": 0.6163934426229508,
      "loss_control": 0.0009794235229492188,
      "loss_data": 0.0,
      "loss_total": 0.0009794235229492188,
      "step": 752
    },
    {
      "epoch": 0.6172131147540983,
      "loss_control": 0.0012331008911132812,
      "loss_data": 0.0,
      "loss_total": 0.0012331008911132812,
      "step": 753
    },
    {
      "epoch": 0.6180327868852459,
      "loss_control": 0.0007953643798828125,
      "loss_data": 0.0,
      "loss_total": 0.0007953643798828125,
      "step": 754
    },
    {
      "epoch": 0.6188524590163934,
      "grad_norm": 0.0059986901469528675,
      "learning_rate": 3.969945355191257e-05,
      "loss": 0.061,
      "step": 755
    },
    {
      "epoch": 0.6188524590163934,
      "loss_control": 0.00214385986328125,
      "loss_data": 0.498046875,
      "loss_total": 0.10175323486328125,
      "step": 755
    },
    {
      "epoch": 0.6196721311475409,
      "loss_control": 0.002086639404296875,
      "loss_data": 0.498291015625,
      "loss_total": 0.10174484550952911,
      "step": 756
    },
    {
      "epoch": 0.6204918032786885,
      "loss_control": 0.00041365623474121094,
      "loss_data": 0.484619140625,
      "loss_total": 0.09733748435974121,
      "step": 757
    },
    {
      "epoch": 0.6213114754098361,
      "loss_control": 0.040771484375,
      "loss_data": 0.0,
      "loss_total": 0.040771484375,
      "step": 758
    },
    {
      "epoch": 0.6221311475409836,
      "loss_control": 0.00438690185546875,
      "loss_data": 0.496826171875,
      "loss_total": 0.10375213623046875,
      "step": 759
    },
    {
      "epoch": 0.6229508196721312,
      "grad_norm": 0.059169016778469086,
      "learning_rate": 3.963114754098361e-05,
      "loss": 0.0891,
      "step": 760
    },
    {
      "epoch": 0.6229508196721312,
      "loss_control": 0.000946044921875,
      "loss_data": 0.499267578125,
      "loss_total": 0.100799560546875,
      "step": 760
    },
    {
      "epoch": 0.6237704918032787,
      "loss_control": 0.0134735107421875,
      "loss_data": 0.4326171875,
      "loss_total": 0.09999694675207138,
      "step": 761
    },
    {
      "epoch": 0.6245901639344262,
      "loss_control": 0.000904083251953125,
      "loss_data": 0.999267578125,
      "loss_total": 0.20075760781764984,
      "step": 762
    },
    {
      "epoch": 0.6254098360655738,
      "loss_control": 0.0013170242309570312,
      "loss_data": 0.0,
      "loss_total": 0.0013170242309570312,
      "step": 763
    },
    {
      "epoch": 0.6262295081967213,
      "loss_control": 0.002166748046875,
      "loss_data": 0.498779296875,
      "loss_total": 0.10192260891199112,
      "step": 764
    },
    {
      "epoch": 0.6270491803278688,
      "grad_norm": 0.013776750303804874,
      "learning_rate": 3.9562841530054644e-05,
      "loss": 0.101,
      "step": 765
    },
    {
      "epoch": 0.6270491803278688,
      "loss_control": 0.0037555694580078125,
      "loss_data": 0.46435546875,
      "loss_total": 0.0966266617178917,
      "step": 765
    },
    {
      "epoch": 0.6278688524590164,
      "loss_control": 0.0041046142578125,
      "loss_data": 0.0,
      "loss_total": 0.0041046142578125,
      "step": 766
    },
    {
      "epoch": 0.6286885245901639,
      "loss_control": 0.00182342529296875,
      "loss_data": 0.499267578125,
      "loss_total": 0.10167694091796875,
      "step": 767
    },
    {
      "epoch": 0.6295081967213115,
      "loss_control": 0.001697540283203125,
      "loss_data": 0.499267578125,
      "loss_total": 0.10155105590820312,
      "step": 768
    },
    {
      "epoch": 0.6303278688524591,
      "loss_control": 0.0088958740234375,
      "loss_data": 0.9453125,
      "loss_total": 0.19795837998390198,
      "step": 769
    },
    {
      "epoch": 0.6311475409836066,
      "grad_norm": 0.15165263414382935,
      "learning_rate": 3.9494535519125685e-05,
      "loss": 0.1004,
      "step": 770
    },
    {
      "epoch": 0.6311475409836066,
      "loss_control": 0.0101776123046875,
      "loss_data": 0.0,
      "loss_total": 0.0101776123046875,
      "step": 770
    },
    {
      "epoch": 0.6319672131147541,
      "loss_control": 0.001499176025390625,
      "loss_data": 0.970703125,
      "loss_total": 0.19563980400562286,
      "step": 771
    },
    {
      "epoch": 0.6327868852459017,
      "loss_control": 0.0030002593994140625,
      "loss_data": 0.498291015625,
      "loss_total": 0.1026584655046463,
      "step": 772
    },
    {
      "epoch": 0.6336065573770492,
      "loss_control": 0.0015659332275390625,
      "loss_data": 0.0,
      "loss_total": 0.0015659332275390625,
      "step": 773
    },
    {
      "epoch": 0.6344262295081967,
      "loss_control": 0.00377655029296875,
      "loss_data": 0.0,
      "loss_total": 0.00377655029296875,
      "step": 774
    },
    {
      "epoch": 0.6352459016393442,
      "grad_norm": 0.08159896731376648,
      "learning_rate": 3.942622950819672e-05,
      "loss": 0.0628,
      "step": 775
    },
    {
      "epoch": 0.6352459016393442,
      "loss_control": 0.00307464599609375,
      "loss_data": 0.0,
      "loss_total": 0.00307464599609375,
      "step": 775
    },
    {
      "epoch": 0.6360655737704918,
      "loss_control": 0.00182342529296875,
      "loss_data": 0.0,
      "loss_total": 0.00182342529296875,
      "step": 776
    },
    {
      "epoch": 0.6368852459016393,
      "loss_control": 0.0002930164337158203,
      "loss_data": 0.4736328125,
      "loss_total": 0.09501957893371582,
      "step": 777
    },
    {
      "epoch": 0.6377049180327868,
      "loss_control": 0.0010128021240234375,
      "loss_data": 0.0,
      "loss_total": 0.0010128021240234375,
      "step": 778
    },
    {
      "epoch": 0.6385245901639345,
      "loss_control": 0.001438140869140625,
      "loss_data": 0.460693359375,
      "loss_total": 0.0935768112540245,
      "step": 779
    },
    {
      "epoch": 0.639344262295082,
      "grad_norm": 0.0502731092274189,
      "learning_rate": 3.935792349726776e-05,
      "loss": 0.0389,
      "step": 780
    },
    {
      "epoch": 0.639344262295082,
      "loss_control": 0.00749969482421875,
      "loss_data": 0.474365234375,
      "loss_total": 0.10237274318933487,
      "step": 780
    },
    {
      "epoch": 0.6401639344262295,
      "loss_control": 0.01184844970703125,
      "loss_data": 0.989013671875,
      "loss_total": 0.2096511870622635,
      "step": 781
    },
    {
      "epoch": 0.6409836065573771,
      "loss_control": 0.001033782958984375,
      "loss_data": 0.47021484375,
      "loss_total": 0.09507675468921661,
      "step": 782
    },
    {
      "epoch": 0.6418032786885246,
      "loss_control": 0.0007219314575195312,
      "loss_data": 0.49951171875,
      "loss_total": 0.10062427818775177,
      "step": 783
    },
    {
      "epoch": 0.6426229508196721,
      "loss_control": 0.0006260871887207031,
      "loss_data": 0.999267578125,
      "loss_total": 0.20047961175441742,
      "step": 784
    },
    {
      "epoch": 0.6434426229508197,
      "grad_norm": 0.004551270976662636,
      "learning_rate": 3.92896174863388e-05,
      "loss": 0.1416,
      "step": 785
    },
    {
      "epoch": 0.6434426229508197,
      "loss_control": 0.01220703125,
      "loss_data": 0.4765625,
      "loss_total": 0.10751952975988388,
      "step": 785
    },
    {
      "epoch": 0.6442622950819672,
      "loss_control": 0.00196075439453125,
      "loss_data": 0.97314453125,
      "loss_total": 0.1965896636247635,
      "step": 786
    },
    {
      "epoch": 0.6450819672131147,
      "loss_control": 0.0005083084106445312,
      "loss_data": 0.0,
      "loss_total": 0.0005083084106445312,
      "step": 787
    },
    {
      "epoch": 0.6459016393442623,
      "loss_control": 0.0007500648498535156,
      "loss_data": 0.961669921875,
      "loss_total": 0.19308404624462128,
      "step": 788
    },
    {
      "epoch": 0.6467213114754098,
      "loss_control": 0.0018978118896484375,
      "loss_data": 0.0,
      "loss_total": 0.0018978118896484375,
      "step": 789
    },
    {
      "epoch": 0.6475409836065574,
      "grad_norm": 0.017126841470599174,
      "learning_rate": 3.922131147540984e-05,
      "loss": 0.0999,
      "step": 790
    },
    {
      "epoch": 0.6475409836065574,
      "loss_control": 0.0013332366943359375,
      "loss_data": 0.0,
      "loss_total": 0.0013332366943359375,
      "step": 790
    },
    {
      "epoch": 0.648360655737705,
      "loss_control": 0.0013303756713867188,
      "loss_data": 0.0,
      "loss_total": 0.0013303756713867188,
      "step": 791
    },
    {
      "epoch": 0.6491803278688525,
      "loss_control": 0.0015363693237304688,
      "loss_data": 0.964111328125,
      "loss_total": 0.19435863196849823,
      "step": 792
    },
    {
      "epoch": 0.65,
      "loss_control": 0.0020084381103515625,
      "loss_data": 0.499267578125,
      "loss_total": 0.10186195373535156,
      "step": 793
    },
    {
      "epoch": 0.6508196721311476,
      "loss_control": 0.0016536712646484375,
      "loss_data": 0.476318359375,
      "loss_total": 0.09691734611988068,
      "step": 794
    },
    {
      "epoch": 0.6516393442622951,
      "grad_norm": 0.06441812962293625,
      "learning_rate": 3.9153005464480874e-05,
      "loss": 0.0792,
      "step": 795
    },
    {
      "epoch": 0.6516393442622951,
      "loss_control": 0.00606536865234375,
      "loss_data": 0.994384765625,
      "loss_total": 0.20494233071804047,
      "step": 795
    },
    {
      "epoch": 0.6524590163934426,
      "loss_control": 0.0022735595703125,
      "loss_data": 0.4990234375,
      "loss_total": 0.10207825154066086,
      "step": 796
    },
    {
      "epoch": 0.6532786885245901,
      "loss_control": 0.00064849853515625,
      "loss_data": 0.0,
      "loss_total": 0.00064849853515625,
      "step": 797
    },
    {
      "epoch": 0.6540983606557377,
      "loss_control": 0.0005712509155273438,
      "loss_data": 0.4560546875,
      "loss_total": 0.09178218990564346,
      "step": 798
    },
    {
      "epoch": 0.6549180327868852,
      "loss_control": 0.0011425018310546875,
      "loss_data": 0.0,
      "loss_total": 0.0011425018310546875,
      "step": 799
    },
    {
      "epoch": 0.6557377049180327,
      "grad_norm": 0.010754426941275597,
      "learning_rate": 3.9084699453551916e-05,
      "loss": 0.0801,
      "step": 800
    },
    {
      "epoch": 0.6557377049180327,
      "loss_control": 0.0010824203491210938,
      "loss_data": 0.0,
      "loss_total": 0.0010824203491210938,
      "step": 800
    },
    {
      "epoch": 0.6565573770491804,
      "loss_control": 0.0018148422241210938,
      "loss_data": 0.998291015625,
      "loss_total": 0.20147304236888885,
      "step": 801
    },
    {
      "epoch": 0.6573770491803279,
      "loss_control": 0.0004978179931640625,
      "loss_data": 0.499755859375,
      "loss_total": 0.10044898837804794,
      "step": 802
    },
    {
      "epoch": 0.6581967213114754,
      "loss_control": 0.0019683837890625,
      "loss_data": 0.0,
      "loss_total": 0.0019683837890625,
      "step": 803
    },
    {
      "epoch": 0.659016393442623,
      "loss_control": 0.0007100105285644531,
      "loss_data": 0.0,
      "loss_total": 0.0007100105285644531,
      "step": 804
    },
    {
      "epoch": 0.6598360655737705,
      "grad_norm": 0.007327524945139885,
      "learning_rate": 3.901639344262295e-05,
      "loss": 0.0611,
      "step": 805
    },
    {
      "epoch": 0.6598360655737705,
      "loss_control": 0.00728607177734375,
      "loss_data": 0.486572265625,
      "loss_total": 0.10460052639245987,
      "step": 805
    },
    {
      "epoch": 0.660655737704918,
      "loss_control": 0.0016946792602539062,
      "loss_data": 0.0,
      "loss_total": 0.0016946792602539062,
      "step": 806
    },
    {
      "epoch": 0.6614754098360656,
      "loss_control": 0.0007886886596679688,
      "loss_data": 0.0,
      "loss_total": 0.0007886886596679688,
      "step": 807
    },
    {
      "epoch": 0.6622950819672131,
      "loss_control": 0.001007080078125,
      "loss_data": 0.499267578125,
      "loss_total": 0.100860595703125,
      "step": 808
    },
    {
      "epoch": 0.6631147540983606,
      "loss_control": 0.0008058547973632812,
      "loss_data": 0.471923828125,
      "loss_total": 0.0951906219124794,
      "step": 809
    },
    {
      "epoch": 0.6639344262295082,
      "grad_norm": 0.03485821187496185,
      "learning_rate": 3.894808743169399e-05,
      "loss": 0.0606,
      "step": 810
    },
    {
      "epoch": 0.6639344262295082,
      "loss_control": 0.0006198883056640625,
      "loss_data": 0.0,
      "loss_total": 0.0006198883056640625,
      "step": 810
    },
    {
      "epoch": 0.6647540983606557,
      "loss_control": 0.004978179931640625,
      "loss_data": 0.498779296875,
      "loss_total": 0.10473404079675674,
      "step": 811
    },
    {
      "epoch": 0.6655737704918033,
      "loss_control": 0.0034160614013671875,
      "loss_data": 0.45849609375,
      "loss_total": 0.0951152816414833,
      "step": 812
    },
    {
      "epoch": 0.6663934426229509,
      "loss_control": 0.0029277801513671875,
      "loss_data": 0.0,
      "loss_total": 0.0029277801513671875,
      "step": 813
    },
    {
      "epoch": 0.6672131147540984,
      "loss_control": 0.0002894401550292969,
      "loss_data": 0.982666015625,
      "loss_total": 0.1968226432800293,
      "step": 814
    },
    {
      "epoch": 0.6680327868852459,
      "grad_norm": 0.043015118688344955,
      "learning_rate": 3.887978142076503e-05,
      "loss": 0.08,
      "step": 815
    },
    {
      "epoch": 0.6680327868852459,
      "loss_control": 0.003116607666015625,
      "loss_data": 0.465576171875,
      "loss_total": 0.0962318405508995,
      "step": 815
    },
    {
      "epoch": 0.6688524590163935,
      "loss_control": 0.003505706787109375,
      "loss_data": 0.489990234375,
      "loss_total": 0.10150375217199326,
      "step": 816
    },
    {
      "epoch": 0.669672131147541,
      "loss_control": 0.0009851455688476562,
      "loss_data": 0.0,
      "loss_total": 0.0009851455688476562,
      "step": 817
    },
    {
      "epoch": 0.6704918032786885,
      "loss_control": 0.00021731853485107422,
      "loss_data": 0.499755859375,
      "loss_total": 0.10016848891973495,
      "step": 818
    },
    {
      "epoch": 0.671311475409836,
      "loss_control": 0.00439453125,
      "loss_data": 0.498291015625,
      "loss_total": 0.10405273735523224,
      "step": 819
    },
    {
      "epoch": 0.6721311475409836,
      "grad_norm": 0.07395146042108536,
      "learning_rate": 3.881147540983607e-05,
      "loss": 0.0806,
      "step": 820
    },
    {
      "epoch": 0.6721311475409836,
      "loss_control": 0.000640869140625,
      "loss_data": 0.0,
      "loss_total": 0.000640869140625,
      "step": 820
    },
    {
      "epoch": 0.6729508196721311,
      "loss_control": 0.0014896392822265625,
      "loss_data": 0.455810546875,
      "loss_total": 0.09265174716711044,
      "step": 821
    },
    {
      "epoch": 0.6737704918032786,
      "loss_control": 0.00441741943359375,
      "loss_data": 0.0,
      "loss_total": 0.00441741943359375,
      "step": 822
    },
    {
      "epoch": 0.6745901639344263,
      "loss_control": 0.0002777576446533203,
      "loss_data": 0.96875,
      "loss_total": 0.19402776658535004,
      "step": 823
    },
    {
      "epoch": 0.6754098360655738,
      "loss_control": 0.0013065338134765625,
      "loss_data": 0.0,
      "loss_total": 0.0013065338134765625,
      "step": 824
    },
    {
      "epoch": 0.6762295081967213,
      "grad_norm": 0.012445840053260326,
      "learning_rate": 3.8743169398907104e-05,
      "loss": 0.0586,
      "step": 825
    },
    {
      "epoch": 0.6762295081967213,
      "loss_control": 0.0009918212890625,
      "loss_data": 0.499267578125,
      "loss_total": 0.1008453369140625,
      "step": 825
    },
    {
      "epoch": 0.6770491803278689,
      "loss_control": 0.0010538101196289062,
      "loss_data": 0.478271484375,
      "loss_total": 0.09670811146497726,
      "step": 826
    },
    {
      "epoch": 0.6778688524590164,
      "loss_control": 0.0024318695068359375,
      "loss_data": 0.0,
      "loss_total": 0.0024318695068359375,
      "step": 827
    },
    {
      "epoch": 0.6786885245901639,
      "loss_control": 0.0027561187744140625,
      "loss_data": 0.0,
      "loss_total": 0.0027561187744140625,
      "step": 828
    },
    {
      "epoch": 0.6795081967213115,
      "loss_control": 0.00084686279296875,
      "loss_data": 0.97216796875,
      "loss_total": 0.19528046250343323,
      "step": 829
    },
    {
      "epoch": 0.680327868852459,
      "grad_norm": 0.09497078508138657,
      "learning_rate": 3.8674863387978146e-05,
      "loss": 0.0796,
      "step": 830
    },
    {
      "epoch": 0.680327868852459,
      "loss_control": 0.00514984130859375,
      "loss_data": 0.0,
      "loss_total": 0.00514984130859375,
      "step": 830
    },
    {
      "epoch": 0.6811475409836065,
      "loss_control": 0.0023288726806640625,
      "loss_data": 0.0,
      "loss_total": 0.0023288726806640625,
      "step": 831
    },
    {
      "epoch": 0.6819672131147541,
      "loss_control": 0.0018930435180664062,
      "loss_data": 0.498291015625,
      "loss_total": 0.10155124962329865,
      "step": 832
    },
    {
      "epoch": 0.6827868852459016,
      "loss_control": 0.0018987655639648438,
      "loss_data": 0.49951171875,
      "loss_total": 0.10180111229419708,
      "step": 833
    },
    {
      "epoch": 0.6836065573770492,
      "loss_control": 0.0018978118896484375,
      "loss_data": 0.0,
      "loss_total": 0.0018978118896484375,
      "step": 834
    },
    {
      "epoch": 0.6844262295081968,
      "grad_norm": 0.02638198621571064,
      "learning_rate": 3.860655737704918e-05,
      "loss": 0.0425,
      "step": 835
    },
    {
      "epoch": 0.6844262295081968,
      "loss_control": 0.0020275115966796875,
      "loss_data": 0.474609375,
      "loss_total": 0.09694939106702805,
      "step": 835
    },
    {
      "epoch": 0.6852459016393443,
      "loss_control": 0.00164031982421875,
      "loss_data": 0.0,
      "loss_total": 0.00164031982421875,
      "step": 836
    },
    {
      "epoch": 0.6860655737704918,
      "loss_control": 0.0021953582763671875,
      "loss_data": 0.0,
      "loss_total": 0.0021953582763671875,
      "step": 837
    },
    {
      "epoch": 0.6868852459016394,
      "loss_control": 0.0007920265197753906,
      "loss_data": 0.0,
      "loss_total": 0.0007920265197753906,
      "step": 838
    },
    {
      "epoch": 0.6877049180327869,
      "loss_control": 0.0006737709045410156,
      "loss_data": 0.458740234375,
      "loss_total": 0.09242182224988937,
      "step": 839
    },
    {
      "epoch": 0.6885245901639344,
      "grad_norm": 0.062449295073747635,
      "learning_rate": 3.853825136612022e-05,
      "loss": 0.0388,
      "step": 840
    },
    {
      "epoch": 0.6885245901639344,
      "loss_control": 0.00010460615158081055,
      "loss_data": 0.0,
      "loss_total": 0.00010460615158081055,
      "step": 840
    },
    {
      "epoch": 0.6893442622950819,
      "loss_control": 0.0038204193115234375,
      "loss_data": 0.46240234375,
      "loss_total": 0.0963008925318718,
      "step": 841
    },
    {
      "epoch": 0.6901639344262295,
      "loss_control": 0.0028820037841796875,
      "loss_data": 0.497802734375,
      "loss_total": 0.10244255512952805,
      "step": 842
    },
    {
      "epoch": 0.690983606557377,
      "loss_control": 0.008575439453125,
      "loss_data": 0.492919921875,
      "loss_total": 0.10715942829847336,
      "step": 843
    },
    {
      "epoch": 0.6918032786885245,
      "loss_control": 0.0008492469787597656,
      "loss_data": 0.0,
      "loss_total": 0.0008492469787597656,
      "step": 844
    },
    {
      "epoch": 0.6926229508196722,
      "grad_norm": 0.012714214622974396,
      "learning_rate": 3.8469945355191264e-05,
      "loss": 0.0614,
      "step": 845
    },
    {
      "epoch": 0.6926229508196722,
      "loss_control": 0.0009350776672363281,
      "loss_data": 0.499267578125,
      "loss_total": 0.10078859329223633,
      "step": 845
    },
    {
      "epoch": 0.6934426229508197,
      "loss_control": 0.0013437271118164062,
      "loss_data": 0.499755859375,
      "loss_total": 0.10129489749670029,
      "step": 846
    },
    {
      "epoch": 0.6942622950819672,
      "loss_control": 0.000713348388671875,
      "loss_data": 0.45654296875,
      "loss_total": 0.09202194213867188,
      "step": 847
    },
    {
      "epoch": 0.6950819672131148,
      "loss_control": 0.0003294944763183594,
      "loss_data": 0.0,
      "loss_total": 0.0003294944763183594,
      "step": 848
    },
    {
      "epoch": 0.6959016393442623,
      "loss_control": 0.006500244140625,
      "loss_data": 0.0,
      "loss_total": 0.006500244140625,
      "step": 849
    },
    {
      "epoch": 0.6967213114754098,
      "grad_norm": 0.33420124650001526,
      "learning_rate": 3.84016393442623e-05,
      "loss": 0.0602,
      "step": 850
    },
    {
      "epoch": 0.6967213114754098,
      "loss_control": 0.00347900390625,
      "loss_data": 0.970458984375,
      "loss_total": 0.19757080078125,
      "step": 850
    },
    {
      "epoch": 0.6975409836065574,
      "loss_control": 0.000553131103515625,
      "loss_data": 0.0,
      "loss_total": 0.000553131103515625,
      "step": 851
    },
    {
      "epoch": 0.6983606557377049,
      "loss_control": 0.001880645751953125,
      "loss_data": 0.968017578125,
      "loss_total": 0.19548416137695312,
      "step": 852
    },
    {
      "epoch": 0.6991803278688524,
      "loss_control": 0.032806396484375,
      "loss_data": 0.44677734375,
      "loss_total": 0.122161865234375,
      "step": 853
    },
    {
      "epoch": 0.7,
      "loss_control": 0.0015516281127929688,
      "loss_data": 0.9697265625,
      "loss_total": 0.19549694657325745,
      "step": 854
    },
    {
      "epoch": 0.7008196721311475,
      "grad_norm": 0.02731635794043541,
      "learning_rate": 3.8333333333333334e-05,
      "loss": 0.1423,
      "step": 855
    },
    {
      "epoch": 0.7008196721311475,
      "loss_control": 0.0018291473388671875,
      "loss_data": 0.44189453125,
      "loss_total": 0.09020805358886719,
      "step": 855
    },
    {
      "epoch": 0.7016393442622951,
      "loss_control": 0.00640106201171875,
      "loss_data": 0.49560546875,
      "loss_total": 0.10552215576171875,
      "step": 856
    },
    {
      "epoch": 0.7024590163934427,
      "loss_control": 0.0022640228271484375,
      "loss_data": 0.94482421875,
      "loss_total": 0.19122886657714844,
      "step": 857
    },
    {
      "epoch": 0.7032786885245902,
      "loss_control": 0.001983642578125,
      "loss_data": 0.46728515625,
      "loss_total": 0.09544067829847336,
      "step": 858
    },
    {
      "epoch": 0.7040983606557377,
      "loss_control": 0.0003173351287841797,
      "loss_data": 0.5,
      "loss_total": 0.1003173366189003,
      "step": 859
    },
    {
      "epoch": 0.7049180327868853,
      "grad_norm": 0.0014827416744083166,
      "learning_rate": 3.8265027322404376e-05,
      "loss": 0.1165,
      "step": 860
    },
    {
      "epoch": 0.7049180327868853,
      "loss_control": 0.00301361083984375,
      "loss_data": 0.49951171875,
      "loss_total": 0.10291595757007599,
      "step": 860
    },
    {
      "epoch": 0.7057377049180328,
      "loss_control": 0.00267791748046875,
      "loss_data": 0.980224609375,
      "loss_total": 0.19872283935546875,
      "step": 861
    },
    {
      "epoch": 0.7065573770491803,
      "loss_control": 0.0017824172973632812,
      "loss_data": 0.0,
      "loss_total": 0.0017824172973632812,
      "step": 862
    },
    {
      "epoch": 0.7073770491803278,
      "loss_control": 0.0113525390625,
      "loss_data": 0.446533203125,
      "loss_total": 0.10065918415784836,
      "step": 863
    },
    {
      "epoch": 0.7081967213114754,
      "loss_control": 0.001953125,
      "loss_data": 0.48046875,
      "loss_total": 0.09804687649011612,
      "step": 864
    },
    {
      "epoch": 0.7090163934426229,
      "grad_norm": 0.07637779414653778,
      "learning_rate": 3.819672131147541e-05,
      "loss": 0.1004,
      "step": 865
    },
    {
      "epoch": 0.7090163934426229,
      "loss_control": 0.005565643310546875,
      "loss_data": 0.96435546875,
      "loss_total": 0.19843673706054688,
      "step": 865
    },
    {
      "epoch": 0.7098360655737705,
      "loss_control": 0.001018524169921875,
      "loss_data": 0.0,
      "loss_total": 0.001018524169921875,
      "step": 866
    },
    {
      "epoch": 0.7106557377049181,
      "loss_control": 0.00272369384765625,
      "loss_data": 0.499267578125,
      "loss_total": 0.10257720947265625,
      "step": 867
    },
    {
      "epoch": 0.7114754098360656,
      "loss_control": 0.0021514892578125,
      "loss_data": 0.0,
      "loss_total": 0.0021514892578125,
      "step": 868
    },
    {
      "epoch": 0.7122950819672131,
      "loss_control": 0.0004343986511230469,
      "loss_data": 0.0,
      "loss_total": 0.0004343986511230469,
      "step": 869
    },
    {
      "epoch": 0.7131147540983607,
      "grad_norm": 0.004273607861250639,
      "learning_rate": 3.8128415300546446e-05,
      "loss": 0.0609,
      "step": 870
    },
    {
      "epoch": 0.7131147540983607,
      "loss_control": 0.0006556510925292969,
      "loss_data": 0.49951171875,
      "loss_total": 0.10055799782276154,
      "step": 870
    },
    {
      "epoch": 0.7139344262295082,
      "loss_control": 0.0006914138793945312,
      "loss_data": 0.0,
      "loss_total": 0.0006914138793945312,
      "step": 871
    },
    {
      "epoch": 0.7147540983606557,
      "loss_control": 0.0016307830810546875,
      "loss_data": 0.499267578125,
      "loss_total": 0.10148429870605469,
      "step": 872
    },
    {
      "epoch": 0.7155737704918033,
      "loss_control": 0.01105499267578125,
      "loss_data": 0.939208984375,
      "loss_total": 0.19889679551124573,
      "step": 873
    },
    {
      "epoch": 0.7163934426229508,
      "loss_control": 0.00646209716796875,
      "loss_data": 0.494384765625,
      "loss_total": 0.10533905029296875,
      "step": 874
    },
    {
      "epoch": 0.7172131147540983,
      "grad_norm": 0.14033527672290802,
      "learning_rate": 3.806010928961749e-05,
      "loss": 0.1014,
      "step": 875
    },
    {
      "epoch": 0.7172131147540983,
      "loss_control": 0.0037212371826171875,
      "loss_data": 0.0,
      "loss_total": 0.0037212371826171875,
      "step": 875
    },
    {
      "epoch": 0.7180327868852459,
      "loss_control": 0.004657745361328125,
      "loss_data": 0.0,
      "loss_total": 0.004657745361328125,
      "step": 876
    },
    {
      "epoch": 0.7188524590163935,
      "loss_control": 0.0010042190551757812,
      "loss_data": 0.499267578125,
      "loss_total": 0.10085773468017578,
      "step": 877
    },
    {
      "epoch": 0.719672131147541,
      "loss_control": 0.0003006458282470703,
      "loss_data": 0.0,
      "loss_total": 0.0003006458282470703,
      "step": 878
    },
    {
      "epoch": 0.7204918032786886,
      "loss_control": 0.03515625,
      "loss_data": 0.0,
      "loss_total": 0.03515625,
      "step": 879
    },
    {
      "epoch": 0.7213114754098361,
      "grad_norm": 1.9173163175582886,
      "learning_rate": 3.799180327868852e-05,
      "loss": 0.0289,
      "step": 880
    },
    {
      "epoch": 0.7213114754098361,
      "loss_control": 0.0017871856689453125,
      "loss_data": 0.953125,
      "loss_total": 0.19241218268871307,
      "step": 880
    },
    {
      "epoch": 0.7221311475409836,
      "loss_control": 0.0036525726318359375,
      "loss_data": 0.442626953125,
      "loss_total": 0.09217796474695206,
      "step": 881
    },
    {
      "epoch": 0.7229508196721312,
      "loss_control": 0.002017974853515625,
      "loss_data": 0.0,
      "loss_total": 0.002017974853515625,
      "step": 882
    },
    {
      "epoch": 0.7237704918032787,
      "loss_control": 0.0023555755615234375,
      "loss_data": 0.0,
      "loss_total": 0.0023555755615234375,
      "step": 883
    },
    {
      "epoch": 0.7245901639344262,
      "loss_control": 0.0012502670288085938,
      "loss_data": 0.499755859375,
      "loss_total": 0.10120143741369247,
      "step": 884
    },
    {
      "epoch": 0.7254098360655737,
      "grad_norm": 0.02909662015736103,
      "learning_rate": 3.7923497267759565e-05,
      "loss": 0.078,
      "step": 885
    },
    {
      "epoch": 0.7254098360655737,
      "loss_control": 0.003276824951171875,
      "loss_data": 0.49755859375,
      "loss_total": 0.102788545191288,
      "step": 885
    },
    {
      "epoch": 0.7262295081967213,
      "loss_control": 0.0035915374755859375,
      "loss_data": 0.493896484375,
      "loss_total": 0.10237083584070206,
      "step": 886
    },
    {
      "epoch": 0.7270491803278688,
      "loss_control": 0.0004563331604003906,
      "loss_data": 0.5,
      "loss_total": 0.10045633465051651,
      "step": 887
    },
    {
      "epoch": 0.7278688524590164,
      "loss_control": 0.0007028579711914062,
      "loss_data": 0.46923828125,
      "loss_total": 0.09455051273107529,
      "step": 888
    },
    {
      "epoch": 0.728688524590164,
      "loss_control": 0.0011081695556640625,
      "loss_data": 0.0,
      "loss_total": 0.0011081695556640625,
      "step": 889
    },
    {
      "epoch": 0.7295081967213115,
      "grad_norm": 0.027703551575541496,
      "learning_rate": 3.78551912568306e-05,
      "loss": 0.0803,
      "step": 890
    },
    {
      "epoch": 0.7295081967213115,
      "loss_control": 0.0006756782531738281,
      "loss_data": 0.475341796875,
      "loss_total": 0.09574403613805771,
      "step": 890
    },
    {
      "epoch": 0.730327868852459,
      "loss_control": 0.0005278587341308594,
      "loss_data": 0.979736328125,
      "loss_total": 0.19647513329982758,
      "step": 891
    },
    {
      "epoch": 0.7311475409836066,
      "loss_control": 0.0009937286376953125,
      "loss_data": 0.0,
      "loss_total": 0.0009937286376953125,
      "step": 892
    },
    {
      "epoch": 0.7319672131147541,
      "loss_control": 0.0006513595581054688,
      "loss_data": 0.0,
      "loss_total": 0.0006513595581054688,
      "step": 893
    },
    {
      "epoch": 0.7327868852459016,
      "loss_control": 0.0031337738037109375,
      "loss_data": 0.49853515625,
      "loss_total": 0.10284080356359482,
      "step": 894
    },
    {
      "epoch": 0.7336065573770492,
      "grad_norm": 0.02032790146768093,
      "learning_rate": 3.778688524590164e-05,
      "loss": 0.0793,
      "step": 895
    },
    {
      "epoch": 0.7336065573770492,
      "loss_control": 0.0002696514129638672,
      "loss_data": 0.5,
      "loss_total": 0.10026965290307999,
      "step": 895
    },
    {
      "epoch": 0.7344262295081967,
      "loss_control": 0.00479888916015625,
      "loss_data": 0.0,
      "loss_total": 0.00479888916015625,
      "step": 896
    },
    {
      "epoch": 0.7352459016393442,
      "loss_control": 0.0022430419921875,
      "loss_data": 0.0,
      "loss_total": 0.0022430419921875,
      "step": 897
    },
    {
      "epoch": 0.7360655737704918,
      "loss_control": 0.006595611572265625,
      "loss_data": 0.476318359375,
      "loss_total": 0.10185928642749786,
      "step": 898
    },
    {
      "epoch": 0.7368852459016394,
      "loss_control": 0.0006427764892578125,
      "loss_data": 0.4853515625,
      "loss_total": 0.09771309047937393,
      "step": 899
    },
    {
      "epoch": 0.7377049180327869,
      "grad_norm": 0.15453800559043884,
      "learning_rate": 3.7718579234972677e-05,
      "loss": 0.0614,
      "step": 900
    },
    {
      "epoch": 0.7377049180327869,
      "loss_control": 0.002288818359375,
      "loss_data": 0.4677734375,
      "loss_total": 0.09584350883960724,
      "step": 900
    },
    {
      "epoch": 0.7385245901639345,
      "loss_control": 0.0014352798461914062,
      "loss_data": 0.4990234375,
      "loss_total": 0.10123997181653976,
      "step": 901
    },
    {
      "epoch": 0.739344262295082,
      "loss_control": 0.001018524169921875,
      "loss_data": 0.98779296875,
      "loss_total": 0.1985771209001541,
      "step": 902
    },
    {
      "epoch": 0.7401639344262295,
      "loss_control": 0.00041961669921875,
      "loss_data": 0.470947265625,
      "loss_total": 0.09460907429456711,
      "step": 903
    },
    {
      "epoch": 0.740983606557377,
      "loss_control": 0.0009975433349609375,
      "loss_data": 0.489501953125,
      "loss_total": 0.09889793395996094,
      "step": 904
    },
    {
      "epoch": 0.7418032786885246,
      "grad_norm": 0.05210241675376892,
      "learning_rate": 3.765027322404372e-05,
      "loss": 0.1178,
      "step": 905
    },
    {
      "epoch": 0.7418032786885246,
      "loss_control": 0.00015532970428466797,
      "loss_data": 0.5,
      "loss_total": 0.10015533119440079,
      "step": 905
    },
    {
      "epoch": 0.7426229508196721,
      "loss_control": 0.0010700225830078125,
      "loss_data": 0.0,
      "loss_total": 0.0010700225830078125,
      "step": 906
    },
    {
      "epoch": 0.7434426229508196,
      "loss_control": 0.00170135498046875,
      "loss_data": 0.0,
      "loss_total": 0.00170135498046875,
      "step": 907
    },
    {
      "epoch": 0.7442622950819672,
      "loss_control": 0.00897216796875,
      "loss_data": 0.0,
      "loss_total": 0.00897216796875,
      "step": 908
    },
    {
      "epoch": 0.7450819672131147,
      "loss_control": 0.0006437301635742188,
      "loss_data": 0.0,
      "loss_total": 0.0006437301635742188,
      "step": 909
    },
    {
      "epoch": 0.7459016393442623,
      "grad_norm": 0.005011900793761015,
      "learning_rate": 3.758196721311475e-05,
      "loss": 0.0225,
      "step": 910
    },
    {
      "epoch": 0.7459016393442623,
      "loss_control": 0.0002999305725097656,
      "loss_data": 0.476806640625,
      "loss_total": 0.09566126018762589,
      "step": 910
    },
    {
      "epoch": 0.7467213114754099,
      "loss_control": 0.0017948150634765625,
      "loss_data": 0.499755859375,
      "loss_total": 0.10174598544836044,
      "step": 911
    },
    {
      "epoch": 0.7475409836065574,
      "loss_control": 0.0009374618530273438,
      "loss_data": 0.0,
      "loss_total": 0.0009374618530273438,
      "step": 912
    },
    {
      "epoch": 0.7483606557377049,
      "loss_control": 0.00047516822814941406,
      "loss_data": 0.99951171875,
      "loss_total": 0.20037750899791718,
      "step": 913
    },
    {
      "epoch": 0.7491803278688525,
      "loss_control": 0.0009927749633789062,
      "loss_data": 0.0,
      "loss_total": 0.0009927749633789062,
      "step": 914
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.010210183449089527,
      "learning_rate": 3.7513661202185795e-05,
      "loss": 0.0799,
      "step": 915
    },
    {
      "epoch": 0.75,
      "loss_control": 0.0022068023681640625,
      "loss_data": 0.465087890625,
      "loss_total": 0.09522438049316406,
      "step": 915
    },
    {
      "epoch": 0.7508196721311475,
      "loss_control": 0.001049041748046875,
      "loss_data": 0.4990234375,
      "loss_total": 0.10085373371839523,
      "step": 916
    },
    {
      "epoch": 0.7516393442622951,
      "loss_control": 0.00200653076171875,
      "loss_data": 0.498291015625,
      "loss_total": 0.10166473686695099,
      "step": 917
    },
    {
      "epoch": 0.7524590163934426,
      "loss_control": 0.0004487037658691406,
      "loss_data": 0.0,
      "loss_total": 0.0004487037658691406,
      "step": 918
    },
    {
      "epoch": 0.7532786885245901,
      "loss_control": 0.0006976127624511719,
      "loss_data": 0.0,
      "loss_total": 0.0006976127624511719,
      "step": 919
    },
    {
      "epoch": 0.7540983606557377,
      "grad_norm": 0.011058231815695763,
      "learning_rate": 3.744535519125683e-05,
      "loss": 0.0598,
      "step": 920
    },
    {
      "epoch": 0.7540983606557377,
      "loss_control": 0.00029206275939941406,
      "loss_data": 0.0,
      "loss_total": 0.00029206275939941406,
      "step": 920
    },
    {
      "epoch": 0.7549180327868853,
      "loss_control": 0.007686614990234375,
      "loss_data": 0.945068359375,
      "loss_total": 0.1967002898454666,
      "step": 921
    },
    {
      "epoch": 0.7557377049180328,
      "loss_control": 0.0016613006591796875,
      "loss_data": 0.0,
      "loss_total": 0.0016613006591796875,
      "step": 922
    },
    {
      "epoch": 0.7565573770491804,
      "loss_control": 0.0028896331787109375,
      "loss_data": 0.0,
      "loss_total": 0.0028896331787109375,
      "step": 923
    },
    {
      "epoch": 0.7573770491803279,
      "loss_control": 0.0025844573974609375,
      "loss_data": 0.0,
      "loss_total": 0.0025844573974609375,
      "step": 924
    },
    {
      "epoch": 0.7581967213114754,
      "grad_norm": 0.027135828509926796,
      "learning_rate": 3.737704918032787e-05,
      "loss": 0.0408,
      "step": 925
    },
    {
      "epoch": 0.7581967213114754,
      "loss_control": 0.0014352798461914062,
      "loss_data": 0.0,
      "loss_total": 0.0014352798461914062,
      "step": 925
    },
    {
      "epoch": 0.759016393442623,
      "loss_control": 0.0015096664428710938,
      "loss_data": 0.498779296875,
      "loss_total": 0.10126552730798721,
      "step": 926
    },
    {
      "epoch": 0.7598360655737705,
      "loss_control": 0.00725555419921875,
      "loss_data": 0.493408203125,
      "loss_total": 0.10593719780445099,
      "step": 927
    },
    {
      "epoch": 0.760655737704918,
      "loss_control": 0.0080718994140625,
      "loss_data": 0.498779296875,
      "loss_total": 0.10782776027917862,
      "step": 928
    },
    {
      "epoch": 0.7614754098360655,
      "loss_control": 0.00116729736328125,
      "loss_data": 0.968505859375,
      "loss_total": 0.19486847519874573,
      "step": 929
    },
    {
      "epoch": 0.7622950819672131,
      "grad_norm": 0.02021719142794609,
      "learning_rate": 3.730874316939891e-05,
      "loss": 0.1023,
      "step": 930
    },
    {
      "epoch": 0.7622950819672131,
      "loss_control": 0.0007929801940917969,
      "loss_data": 0.0,
      "loss_total": 0.0007929801940917969,
      "step": 930
    },
    {
      "epoch": 0.7631147540983606,
      "loss_control": 0.0003376007080078125,
      "loss_data": 0.499755859375,
      "loss_total": 0.1002887710928917,
      "step": 931
    },
    {
      "epoch": 0.7639344262295082,
      "loss_control": 0.0035190582275390625,
      "loss_data": 0.953857421875,
      "loss_total": 0.19429054856300354,
      "step": 932
    },
    {
      "epoch": 0.7647540983606558,
      "loss_control": 0.0011720657348632812,
      "loss_data": 0.499267578125,
      "loss_total": 0.10102558135986328,
      "step": 933
    },
    {
      "epoch": 0.7655737704918033,
      "loss_control": 0.000453948974609375,
      "loss_data": 0.97216796875,
      "loss_total": 0.19488754868507385,
      "step": 934
    },
    {
      "epoch": 0.7663934426229508,
      "grad_norm": 0.029328739270567894,
      "learning_rate": 3.724043715846995e-05,
      "loss": 0.1183,
      "step": 935
    },
    {
      "epoch": 0.7663934426229508,
      "loss_control": 0.00482177734375,
      "loss_data": 0.0,
      "loss_total": 0.00482177734375,
      "step": 935
    },
    {
      "epoch": 0.7672131147540984,
      "loss_control": 0.0036525726318359375,
      "loss_data": 0.0,
      "loss_total": 0.0036525726318359375,
      "step": 936
    },
    {
      "epoch": 0.7680327868852459,
      "loss_control": 0.004673004150390625,
      "loss_data": 0.0,
      "loss_total": 0.004673004150390625,
      "step": 937
    },
    {
      "epoch": 0.7688524590163934,
      "loss_control": 0.00254058837890625,
      "loss_data": 0.0,
      "loss_total": 0.00254058837890625,
      "step": 938
    },
    {
      "epoch": 0.769672131147541,
      "loss_control": 0.0029144287109375,
      "loss_data": 0.0,
      "loss_total": 0.0029144287109375,
      "step": 939
    },
    {
      "epoch": 0.7704918032786885,
      "grad_norm": 0.032799944281578064,
      "learning_rate": 3.7172131147540984e-05,
      "loss": 0.0037,
      "step": 940
    },
    {
      "epoch": 0.7704918032786885,
      "loss_control": 0.0007638931274414062,
      "loss_data": 0.49951171875,
      "loss_total": 0.10066623985767365,
      "step": 940
    },
    {
      "epoch": 0.771311475409836,
      "loss_control": 0.0008325576782226562,
      "loss_data": 0.5,
      "loss_total": 0.10083255916833878,
      "step": 941
    },
    {
      "epoch": 0.7721311475409836,
      "loss_control": 0.0004482269287109375,
      "loss_data": 0.0,
      "loss_total": 0.0004482269287109375,
      "step": 942
    },
    {
      "epoch": 0.7729508196721312,
      "loss_control": 0.002506256103515625,
      "loss_data": 0.966064453125,
      "loss_total": 0.1957191526889801,
      "step": 943
    },
    {
      "epoch": 0.7737704918032787,
      "loss_control": 0.0007557868957519531,
      "loss_data": 0.0,
      "loss_total": 0.0007557868957519531,
      "step": 944
    },
    {
      "epoch": 0.7745901639344263,
      "grad_norm": 0.006026116199791431,
      "learning_rate": 3.7103825136612025e-05,
      "loss": 0.0797,
      "step": 945
    },
    {
      "epoch": 0.7745901639344263,
      "loss_control": 0.004253387451171875,
      "loss_data": 0.49609375,
      "loss_total": 0.10347213596105576,
      "step": 945
    },
    {
      "epoch": 0.7754098360655738,
      "loss_control": 0.00286102294921875,
      "loss_data": 0.974365234375,
      "loss_total": 0.197734072804451,
      "step": 946
    },
    {
      "epoch": 0.7762295081967213,
      "loss_control": 0.0007100105285644531,
      "loss_data": 0.0,
      "loss_total": 0.0007100105285644531,
      "step": 947
    },
    {
      "epoch": 0.7770491803278688,
      "loss_control": 0.00047659873962402344,
      "loss_data": 0.499755859375,
      "loss_total": 0.1004277691245079,
      "step": 948
    },
    {
      "epoch": 0.7778688524590164,
      "loss_control": 0.0006651878356933594,
      "loss_data": 0.0,
      "loss_total": 0.0006651878356933594,
      "step": 949
    },
    {
      "epoch": 0.7786885245901639,
      "grad_norm": 0.003712614066898823,
      "learning_rate": 3.703551912568306e-05,
      "loss": 0.0806,
      "step": 950
    },
    {
      "epoch": 0.7786885245901639,
      "loss_control": 0.00301361083984375,
      "loss_data": 0.474609375,
      "loss_total": 0.09793549031019211,
      "step": 950
    },
    {
      "epoch": 0.7795081967213114,
      "loss_control": 0.00115203857421875,
      "loss_data": 0.0,
      "loss_total": 0.00115203857421875,
      "step": 951
    },
    {
      "epoch": 0.780327868852459,
      "loss_control": 0.0009059906005859375,
      "loss_data": 0.0,
      "loss_total": 0.0009059906005859375,
      "step": 952
    },
    {
      "epoch": 0.7811475409836065,
      "loss_control": 0.0016775131225585938,
      "loss_data": 0.4990234375,
      "loss_total": 0.10148220509290695,
      "step": 953
    },
    {
      "epoch": 0.7819672131147541,
      "loss_control": 0.015960693359375,
      "loss_data": 0.4873046875,
      "loss_total": 0.11342163383960724,
      "step": 954
    },
    {
      "epoch": 0.7827868852459017,
      "grad_norm": 0.24424508213996887,
      "learning_rate": 3.69672131147541e-05,
      "loss": 0.063,
      "step": 955
    },
    {
      "epoch": 0.7827868852459017,
      "loss_control": 0.0015430450439453125,
      "loss_data": 0.0,
      "loss_total": 0.0015430450439453125,
      "step": 955
    },
    {
      "epoch": 0.7836065573770492,
      "loss_control": 0.0003955364227294922,
      "loss_data": 0.0,
      "loss_total": 0.0003955364227294922,
      "step": 956
    },
    {
      "epoch": 0.7844262295081967,
      "loss_control": 0.0009217262268066406,
      "loss_data": 0.999267578125,
      "loss_total": 0.20077525079250336,
      "step": 957
    },
    {
      "epoch": 0.7852459016393443,
      "loss_control": 0.0021877288818359375,
      "loss_data": 0.972900390625,
      "loss_total": 0.19676780700683594,
      "step": 958
    },
    {
      "epoch": 0.7860655737704918,
      "loss_control": 0.00025272369384765625,
      "loss_data": 0.0,
      "loss_total": 0.00025272369384765625,
      "step": 959
    },
    {
      "epoch": 0.7868852459016393,
      "grad_norm": 0.0021067699417471886,
      "learning_rate": 3.689890710382514e-05,
      "loss": 0.0799,
      "step": 960
    },
    {
      "epoch": 0.7868852459016393,
      "loss_control": 0.004283905029296875,
      "loss_data": 0.0,
      "loss_total": 0.004283905029296875,
      "step": 960
    },
    {
      "epoch": 0.7877049180327869,
      "loss_control": 0.001682281494140625,
      "loss_data": 0.499755859375,
      "loss_total": 0.1016334518790245,
      "step": 961
    },
    {
      "epoch": 0.7885245901639344,
      "loss_control": 0.0029621124267578125,
      "loss_data": 0.464599609375,
      "loss_total": 0.09588203579187393,
      "step": 962
    },
    {
      "epoch": 0.7893442622950819,
      "loss_control": 0.0007281303405761719,
      "loss_data": 0.9755859375,
      "loss_total": 0.1958453208208084,
      "step": 963
    },
    {
      "epoch": 0.7901639344262295,
      "loss_control": 0.0007109642028808594,
      "loss_data": 0.49951171875,
      "loss_total": 0.1006133109331131,
      "step": 964
    },
    {
      "epoch": 0.7909836065573771,
      "grad_norm": 0.006072127725929022,
      "learning_rate": 3.683060109289618e-05,
      "loss": 0.0997,
      "step": 965
    },
    {
      "epoch": 0.7909836065573771,
      "loss_control": 0.0023174285888671875,
      "loss_data": 0.969482421875,
      "loss_total": 0.19621391594409943,
      "step": 965
    },
    {
      "epoch": 0.7918032786885246,
      "loss_control": 0.0012989044189453125,
      "loss_data": 0.5,
      "loss_total": 0.10129890590906143,
      "step": 966
    },
    {
      "epoch": 0.7926229508196722,
      "loss_control": 0.0011243820190429688,
      "loss_data": 0.0,
      "loss_total": 0.0011243820190429688,
      "step": 967
    },
    {
      "epoch": 0.7934426229508197,
      "loss_control": 0.001201629638671875,
      "loss_data": 0.0,
      "loss_total": 0.001201629638671875,
      "step": 968
    },
    {
      "epoch": 0.7942622950819672,
      "loss_control": 0.0004982948303222656,
      "loss_data": 0.49951171875,
      "loss_total": 0.1004006415605545,
      "step": 969
    },
    {
      "epoch": 0.7950819672131147,
      "grad_norm": 0.003770975861698389,
      "learning_rate": 3.6762295081967214e-05,
      "loss": 0.08,
      "step": 970
    },
    {
      "epoch": 0.7950819672131147,
      "loss_control": 0.002361297607421875,
      "loss_data": 0.0,
      "loss_total": 0.002361297607421875,
      "step": 970
    },
    {
      "epoch": 0.7959016393442623,
      "loss_control": 0.004222869873046875,
      "loss_data": 0.0,
      "loss_total": 0.004222869873046875,
      "step": 971
    },
    {
      "epoch": 0.7967213114754098,
      "loss_control": 0.00952911376953125,
      "loss_data": 0.474853515625,
      "loss_total": 0.10449981689453125,
      "step": 972
    },
    {
      "epoch": 0.7975409836065573,
      "loss_control": 0.0028553009033203125,
      "loss_data": 0.498291015625,
      "loss_total": 0.10251350700855255,
      "step": 973
    },
    {
      "epoch": 0.7983606557377049,
      "loss_control": 0.0005002021789550781,
      "loss_data": 0.453857421875,
      "loss_total": 0.09127169102430344,
      "step": 974
    },
    {
      "epoch": 0.7991803278688525,
      "grad_norm": 0.1030387207865715,
      "learning_rate": 3.6693989071038256e-05,
      "loss": 0.061,
      "step": 975
    },
    {
      "epoch": 0.7991803278688525,
      "loss_control": 0.0004589557647705078,
      "loss_data": 0.499755859375,
      "loss_total": 0.10041012614965439,
      "step": 975
    },
    {
      "epoch": 0.8,
      "loss_control": 0.004222869873046875,
      "loss_data": 0.0,
      "loss_total": 0.004222869873046875,
      "step": 976
    },
    {
      "epoch": 0.8008196721311476,
      "loss_control": 0.0005984306335449219,
      "loss_data": 0.0,
      "loss_total": 0.0005984306335449219,
      "step": 977
    },
    {
      "epoch": 0.8016393442622951,
      "loss_control": 0.0007462501525878906,
      "loss_data": 0.49951171875,
      "loss_total": 0.10064859688282013,
      "step": 978
    },
    {
      "epoch": 0.8024590163934426,
      "loss_control": 0.00347137451171875,
      "loss_data": 0.499267578125,
      "loss_total": 0.10332489013671875,
      "step": 979
    },
    {
      "epoch": 0.8032786885245902,
      "grad_norm": 0.04155389592051506,
      "learning_rate": 3.662568306010929e-05,
      "loss": 0.0618,
      "step": 980
    },
    {
      "epoch": 0.8032786885245902,
      "loss_control": 0.0026340484619140625,
      "loss_data": 0.0,
      "loss_total": 0.0026340484619140625,
      "step": 980
    },
    {
      "epoch": 0.8040983606557377,
      "loss_control": 0.0006966590881347656,
      "loss_data": 0.0,
      "loss_total": 0.0006966590881347656,
      "step": 981
    },
    {
      "epoch": 0.8049180327868852,
      "loss_control": 0.0012807846069335938,
      "loss_data": 0.0,
      "loss_total": 0.0012807846069335938,
      "step": 982
    },
    {
      "epoch": 0.8057377049180328,
      "loss_control": 0.009063720703125,
      "loss_data": 0.457275390625,
      "loss_total": 0.10051880031824112,
      "step": 983
    },
    {
      "epoch": 0.8065573770491803,
      "loss_control": 0.0005283355712890625,
      "loss_data": 0.5,
      "loss_total": 0.10052833706140518,
      "step": 984
    },
    {
      "epoch": 0.8073770491803278,
      "grad_norm": 0.002989479573443532,
      "learning_rate": 3.655737704918033e-05,
      "loss": 0.0411,
      "step": 985
    },
    {
      "epoch": 0.8073770491803278,
      "loss_control": 0.00299072265625,
      "loss_data": 0.0,
      "loss_total": 0.00299072265625,
      "step": 985
    },
    {
      "epoch": 0.8081967213114755,
      "loss_control": 0.0009222030639648438,
      "loss_data": 0.0,
      "loss_total": 0.0009222030639648438,
      "step": 986
    },
    {
      "epoch": 0.809016393442623,
      "loss_control": 0.00362396240234375,
      "loss_data": 0.493408203125,
      "loss_total": 0.10230560600757599,
      "step": 987
    },
    {
      "epoch": 0.8098360655737705,
      "loss_control": 0.0037555694580078125,
      "loss_data": 0.49853515625,
      "loss_total": 0.1034625992178917,
      "step": 988
    },
    {
      "epoch": 0.8106557377049181,
      "loss_control": 0.0010089874267578125,
      "loss_data": 0.971435546875,
      "loss_total": 0.19529609382152557,
      "step": 989
    },
    {
      "epoch": 0.8114754098360656,
      "grad_norm": 0.04460804536938667,
      "learning_rate": 3.648907103825137e-05,
      "loss": 0.081,
      "step": 990
    },
    {
      "epoch": 0.8114754098360656,
      "loss_control": 0.0025844573974609375,
      "loss_data": 0.0,
      "loss_total": 0.0025844573974609375,
      "step": 990
    },
    {
      "epoch": 0.8122950819672131,
      "loss_control": 0.006591796875,
      "loss_data": 0.968994140625,
      "loss_total": 0.20039062201976776,
      "step": 991
    },
    {
      "epoch": 0.8131147540983606,
      "loss_control": 0.002689361572265625,
      "loss_data": 0.0,
      "loss_total": 0.002689361572265625,
      "step": 992
    },
    {
      "epoch": 0.8139344262295082,
      "loss_control": 0.0008072853088378906,
      "loss_data": 0.46875,
      "loss_total": 0.09455728530883789,
      "step": 993
    },
    {
      "epoch": 0.8147540983606557,
      "loss_control": 0.002323150634765625,
      "loss_data": 0.497802734375,
      "loss_total": 0.10188370198011398,
      "step": 994
    },
    {
      "epoch": 0.8155737704918032,
      "grad_norm": 0.04050765559077263,
      "learning_rate": 3.642076502732241e-05,
      "loss": 0.0804,
      "step": 995
    },
    {
      "epoch": 0.8155737704918032,
      "loss_control": 0.000701904296875,
      "loss_data": 0.5,
      "loss_total": 0.10070190578699112,
      "step": 995
    },
    {
      "epoch": 0.8163934426229508,
      "loss_control": 0.03387451171875,
      "loss_data": 0.4814453125,
      "loss_total": 0.13016358017921448,
      "step": 996
    },
    {
      "epoch": 0.8172131147540984,
      "loss_control": 0.0017147064208984375,
      "loss_data": 0.0,
      "loss_total": 0.0017147064208984375,
      "step": 997
    },
    {
      "epoch": 0.8180327868852459,
      "loss_control": 0.001796722412109375,
      "loss_data": 0.998291015625,
      "loss_total": 0.20145492255687714,
      "step": 998
    },
    {
      "epoch": 0.8188524590163935,
      "loss_control": 0.0069580078125,
      "loss_data": 0.0,
      "loss_total": 0.0069580078125,
      "step": 999
    },
    {
      "epoch": 0.819672131147541,
      "grad_norm": 0.12277275323867798,
      "learning_rate": 3.6352459016393444e-05,
      "loss": 0.0882,
      "step": 1000
    }
  ],
  "logging_steps": 5,
  "max_steps": 3660,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 272297382137856.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
